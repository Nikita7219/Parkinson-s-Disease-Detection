{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "B1Doo0hHKEk5",
   "metadata": {
    "id": "B1Doo0hHKEk5"
   },
   "source": [
    "# Ensembling vgg16-Resnet50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d197f0",
   "metadata": {
    "id": "b3d197f0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P6-JEH9zM1G9",
   "metadata": {
    "id": "P6-JEH9zM1G9"
   },
   "source": [
    "**Load images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7b5675",
   "metadata": {
    "id": "4a7b5675"
   },
   "outputs": [],
   "source": [
    "# jpg image path\n",
    "images = r\"D:\\Final Year Project\\JPG Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26895b69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26895b69",
    "outputId": "23054db8-f8a4-4383-a633-bdf00b9b54d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Control', 'PD']\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(images)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcbc7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "im = cv2.imread(r\"D:\\Final Year Project\\JPG Dataset\\Control\\2.jpg\")\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deddbc84",
   "metadata": {
    "id": "deddbc84"
   },
   "outputs": [],
   "source": [
    "image_data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8113a687",
   "metadata": {
    "id": "8113a687"
   },
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'Control':0,\n",
    "    'PD':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4306ba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for processing one image.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "try :\n",
    "\n",
    "    for ix in folders:\n",
    "        try :\n",
    "            \n",
    "            path = os.path.join(images,ix)\n",
    "            for im in os.listdir(path):\n",
    "                try :\n",
    "                        \n",
    "                    img = image.load_img(os.path.join(path,im),target_size = ((64,64)))\n",
    "                    img_array = image.img_to_array(img)\n",
    "                    image_data.append(img_array)\n",
    "                    labels.append(label_dict[ix])\n",
    "                except :\n",
    "                  print(\"Error for processing one image.\")\n",
    "\n",
    "        except:\n",
    "          print(\"Error in folder.\")\n",
    "\n",
    "except :\n",
    "  print(\"Done processing images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66cf0d25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66cf0d25",
    "outputId": "b479fe61-783a-43db-ce72-800ad94d8a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31435 31435\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data),len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a264ab",
   "metadata": {
    "id": "10a264ab"
   },
   "outputs": [],
   "source": [
    "combined = list(zip(image_data,labels))\n",
    "image_data[:],labels[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dfdc4d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dfdc4d6",
    "outputId": "079396d9-0efc-462e-a3a7-268184e6e9cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20c7dcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d20c7dcf",
    "outputId": "92d61dbc-e0b2-4f7a-ea33-adfb527974c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31435, 64, 64, 3) (31435,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(image_data)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6555eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a6555eb",
    "outputId": "1f252011-f31c-45ec-e20e-531eeb3ab724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31435, 64, 64, 3) (31435, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "YUpLVIRqfNBG",
   "metadata": {
    "id": "YUpLVIRqfNBG"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zx919sbKNFFB",
   "metadata": {
    "id": "zx919sbKNFFB"
   },
   "source": [
    "**Data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Z_JTSbpNdtFW",
   "metadata": {
    "id": "Z_JTSbpNdtFW"
   },
   "outputs": [],
   "source": [
    "augment = ImageDataGenerator( \n",
    "    \n",
    "                             rotation_range=20,\n",
    "                              width_shift_range=0.01, \n",
    "                              height_shift_range=0.01, \n",
    "                              horizontal_flip=False, \n",
    "                              vertical_flip=False,\n",
    "                            )\n",
    "augment.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad27c22e",
   "metadata": {
    "id": "ad27c22e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t3xCxQ3jNWIV",
   "metadata": {
    "id": "t3xCxQ3jNWIV"
   },
   "source": [
    "**Deep Ensemble CNN**\n",
    "\n",
    "VGG16 and Resnet50-Average Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda6ae56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fda6ae56",
    "outputId": "aee8effd-06e6-4462-fb67-63a902044521"
   },
   "outputs": [],
   "source": [
    "model = VGG16(include_top = False,weights = 'imagenet',input_shape = (64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27acae2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27acae2c",
    "outputId": "b200bdf6-a8bc-440e-d1ef-8125ca100e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c_qomjB8fNh0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_qomjB8fNh0",
    "outputId": "9a946a84-4703-430b-c8d0-96b07bbf1528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.src.engine.input_layer.InputLayer object at 0x000001A8502097D0>\n",
      "1 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B3858850>\n",
      "2 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B3835BD0>\n",
      "3 <keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A8B38B7ED0>\n",
      "4 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B38B5710>\n",
      "5 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B38EFFD0>\n",
      "6 <keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A8B38B6A10>\n",
      "7 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910A805D0>\n",
      "8 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910A81DD0>\n",
      "9 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910A82BD0>\n",
      "10 <keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A910A88E50>\n",
      "11 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A851D6B110>\n",
      "12 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910A8AD10>\n",
      "13 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B38ED490>\n",
      "14 <keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A8B385A390>\n",
      "15 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B38EF5D0>\n",
      "16 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B3817250>\n",
      "17 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B38ED2D0>\n",
      "18 <keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A8B385AE10>\n"
     ]
    }
   ],
   "source": [
    "for ix in range(len(model.layers)):\n",
    "    print(ix,model.layers[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6OcGPL5tNxAu",
   "metadata": {
    "id": "6OcGPL5tNxAu"
   },
   "source": [
    "**Fine-Tuninng**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceNT4jtmfTHa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceNT4jtmfTHa",
    "outputId": "b59b0137-279a-44bb-e0fe-968080930b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:16]:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb12teAefZu5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb12teAefZu5",
    "outputId": "c3bb0f5a-371b-4028-c820-8f68b83fe022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15272386 (58.26 MB)\n",
      "Trainable params: 5277314 (20.13 MB)\n",
      "Non-trainable params: 9995072 (38.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "av1 = Flatten()(model.output)\n",
    "fc1 = Dense(256,activation='relu',kernel_regularizer= l2(0.01),input_dim=256)(av1)\n",
    "d1 = Dropout(0.5)(fc1)\n",
    "fc2 = Dense(128,activation='relu',kernel_regularizer= l2(0.01),input_dim=128)(d1)\n",
    "d2 = Dropout(0.5)(fc2)\n",
    "fc3 = Dense(2,activation = 'sigmoid')(d2)\n",
    "\n",
    "\n",
    "model_vgg = Model(model.input,fc3)\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2Y6x0NixhifZ",
   "metadata": {
    "id": "2Y6x0NixhifZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hWxUYK3MhM5i",
   "metadata": {
    "id": "hWxUYK3MhM5i"
   },
   "outputs": [],
   "source": [
    "model1 = ResNet50(include_top=False, input_shape=(64,64,3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "qIONBBICiD-P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIONBBICiD-P",
    "outputId": "22de7c35-9e67-4bd3-b55c-e1867238f82b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 70, 70, 3)            0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 32, 32, 64)           9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 32, 32, 64)           256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 32, 32, 64)           0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 34, 34, 64)           0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 16, 16, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 16, 16, 64)           4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 16, 16, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 16, 16, 256)          16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 16, 16, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 16, 16, 256)          0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 16, 16, 64)           16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 16, 16, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 16, 16, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 16, 16, 256)          0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 16, 16, 64)           16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 16, 16, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 16, 16, 256)          0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 16, 16, 256)          0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 8, 8, 128)            32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 8, 8, 512)            131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 8, 8, 512)            0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 8, 8, 512)            0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 8, 8, 128)            65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 8, 8, 512)            0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 8, 8, 512)            0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 8, 8, 128)            65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 8, 8, 512)            0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 8, 8, 512)            0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 8, 8, 128)            65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 8, 8, 512)            0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 8, 8, 512)            0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 4, 4, 256)            131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 4, 4, 1024)           525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 2, 2, 512)            524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 2, 2, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 2, 2, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 2, 2, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23587712 (89.98 MB)\n",
      "Trainable params: 23534592 (89.78 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "AJVa8HrZiVj5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJVa8HrZiVj5",
    "outputId": "6d675957-2e84-433f-f305-c67d1f88ae10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.src.engine.input_layer.InputLayer object at 0x000001A8B38D1E50>\n",
      "1 <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000001A910A81C90>\n",
      "2 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910AF0410>\n",
      "3 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B3873D90>\n",
      "4 <keras.src.layers.core.activation.Activation object at 0x000001A8B38D26D0>\n",
      "5 <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000001A84F6D7E50>\n",
      "6 <keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A910ABED90>\n",
      "7 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B23750>\n",
      "8 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B21FD0>\n",
      "9 <keras.src.layers.core.activation.Activation object at 0x000001A910B203D0>\n",
      "10 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910AF13D0>\n",
      "11 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910AD9A90>\n",
      "12 <keras.src.layers.core.activation.Activation object at 0x000001A830F4F410>\n",
      "13 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B13490>\n",
      "14 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910A83350>\n",
      "15 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B3834050>\n",
      "16 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B38997D0>\n",
      "17 <keras.src.layers.merging.add.Add object at 0x000001A910B00390>\n",
      "18 <keras.src.layers.core.activation.Activation object at 0x000001A910AF03D0>\n",
      "19 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B2FAD0>\n",
      "20 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B21410>\n",
      "21 <keras.src.layers.core.activation.Activation object at 0x000001A910B0BAD0>\n",
      "22 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B3F710>\n",
      "23 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B38153D0>\n",
      "24 <keras.src.layers.core.activation.Activation object at 0x000001A8B38EE350>\n",
      "25 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910AA8150>\n",
      "26 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B3817490>\n",
      "27 <keras.src.layers.merging.add.Add object at 0x000001A910B00090>\n",
      "28 <keras.src.layers.core.activation.Activation object at 0x000001A910B08890>\n",
      "29 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B0AED0>\n",
      "30 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910ADAE50>\n",
      "31 <keras.src.layers.core.activation.Activation object at 0x000001A8B38B5C50>\n",
      "32 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B638D0>\n",
      "33 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910ABF650>\n",
      "34 <keras.src.layers.core.activation.Activation object at 0x000001A910B63950>\n",
      "35 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B6FD90>\n",
      "36 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B62A90>\n",
      "37 <keras.src.layers.merging.add.Add object at 0x000001A910B4BA50>\n",
      "38 <keras.src.layers.core.activation.Activation object at 0x000001A8B38F6F50>\n",
      "39 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B880D0>\n",
      "40 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910AAAC90>\n",
      "41 <keras.src.layers.core.activation.Activation object at 0x000001A8B38F5C10>\n",
      "42 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B9EE10>\n",
      "43 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B63050>\n",
      "44 <keras.src.layers.core.activation.Activation object at 0x000001A910AAB090>\n",
      "45 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B80090>\n",
      "46 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BAB590>\n",
      "47 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B3872850>\n",
      "48 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910BA9E50>\n",
      "49 <keras.src.layers.merging.add.Add object at 0x000001A910BA8850>\n",
      "50 <keras.src.layers.core.activation.Activation object at 0x000001A910BA95D0>\n",
      "51 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B80A10>\n",
      "52 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B89310>\n",
      "53 <keras.src.layers.core.activation.Activation object at 0x000001A910B8A7D0>\n",
      "54 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910B6C310>\n",
      "55 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B6C210>\n",
      "56 <keras.src.layers.core.activation.Activation object at 0x000001A910B8E350>\n",
      "57 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A8B385A350>\n",
      "58 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B38F5850>\n",
      "59 <keras.src.layers.merging.add.Add object at 0x000001A8B3836A90>\n",
      "60 <keras.src.layers.core.activation.Activation object at 0x000001A910B8ABD0>\n",
      "61 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BB3B50>\n",
      "62 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B38B6590>\n",
      "63 <keras.src.layers.core.activation.Activation object at 0x000001A910B49890>\n",
      "64 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BB1910>\n",
      "65 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B0AE50>\n",
      "66 <keras.src.layers.core.activation.Activation object at 0x000001A910BC57D0>\n",
      "67 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BD3E10>\n",
      "68 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B38EF690>\n",
      "69 <keras.src.layers.merging.add.Add object at 0x000001A910BC4C10>\n",
      "70 <keras.src.layers.core.activation.Activation object at 0x000001A910B6CD90>\n",
      "71 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BE2190>\n",
      "72 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B48F50>\n",
      "73 <keras.src.layers.core.activation.Activation object at 0x000001A910B9E9D0>\n",
      "74 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BEDD10>\n",
      "75 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910BD4C90>\n",
      "76 <keras.src.layers.core.activation.Activation object at 0x000001A910BE2B50>\n",
      "77 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A830F4E210>\n",
      "78 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910BC4C50>\n",
      "79 <keras.src.layers.merging.add.Add object at 0x000001A910BD7250>\n",
      "80 <keras.src.layers.core.activation.Activation object at 0x000001A910B02190>\n",
      "81 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BEE550>\n",
      "82 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B8EC10>\n",
      "83 <keras.src.layers.core.activation.Activation object at 0x000001A910AF0F10>\n",
      "84 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C12110>\n",
      "85 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C133D0>\n",
      "86 <keras.src.layers.core.activation.Activation object at 0x000001A910C112D0>\n",
      "87 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C05290>\n",
      "88 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C120D0>\n",
      "89 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B38F5210>\n",
      "90 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C07C50>\n",
      "91 <keras.src.layers.merging.add.Add object at 0x000001A910C044D0>\n",
      "92 <keras.src.layers.core.activation.Activation object at 0x000001A910BF28D0>\n",
      "93 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BC7090>\n",
      "94 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910BC62D0>\n",
      "95 <keras.src.layers.core.activation.Activation object at 0x000001A910BC4150>\n",
      "96 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BB1210>\n",
      "97 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B0A550>\n",
      "98 <keras.src.layers.core.activation.Activation object at 0x000001A910BE2D10>\n",
      "99 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C22F90>\n",
      "100 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910B2F650>\n",
      "101 <keras.src.layers.merging.add.Add object at 0x000001A910ADB750>\n",
      "102 <keras.src.layers.core.activation.Activation object at 0x000001A910BED210>\n",
      "103 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BD0290>\n",
      "104 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B3858350>\n",
      "105 <keras.src.layers.core.activation.Activation object at 0x000001A910BEE9D0>\n",
      "106 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C22C50>\n",
      "107 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C3ACD0>\n",
      "108 <keras.src.layers.core.activation.Activation object at 0x000001A910C3A850>\n",
      "109 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C51A50>\n",
      "110 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C43B10>\n",
      "111 <keras.src.layers.merging.add.Add object at 0x000001A910C33190>\n",
      "112 <keras.src.layers.core.activation.Activation object at 0x000001A910ABE290>\n",
      "113 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C57F90>\n",
      "114 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910AA8D50>\n",
      "115 <keras.src.layers.core.activation.Activation object at 0x000001A910C56B90>\n",
      "116 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910EE3F50>\n",
      "117 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C539D0>\n",
      "118 <keras.src.layers.core.activation.Activation object at 0x000001A910B6D550>\n",
      "119 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910EEE910>\n",
      "120 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C06990>\n",
      "121 <keras.src.layers.merging.add.Add object at 0x000001A910B0BE10>\n",
      "122 <keras.src.layers.core.activation.Activation object at 0x000001A910B09650>\n",
      "123 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F034D0>\n",
      "124 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910BE0F10>\n",
      "125 <keras.src.layers.core.activation.Activation object at 0x000001A910C53A10>\n",
      "126 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F0B150>\n",
      "127 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910F09590>\n",
      "128 <keras.src.layers.core.activation.Activation object at 0x000001A910F08490>\n",
      "129 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F00950>\n",
      "130 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910EECE50>\n",
      "131 <keras.src.layers.merging.add.Add object at 0x000001A910EE2A10>\n",
      "132 <keras.src.layers.core.activation.Activation object at 0x000001A910EFBC10>\n",
      "133 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910C38F90>\n",
      "134 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C39490>\n",
      "135 <keras.src.layers.core.activation.Activation object at 0x000001A910C39150>\n",
      "136 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910BB1690>\n",
      "137 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C00B50>\n",
      "138 <keras.src.layers.core.activation.Activation object at 0x000001A910BC7210>\n",
      "139 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F0E5D0>\n",
      "140 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A8B3834B10>\n",
      "141 <keras.src.layers.merging.add.Add object at 0x000001A8B3873A50>\n",
      "142 <keras.src.layers.core.activation.Activation object at 0x000001A910C107D0>\n",
      "143 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F0EE10>\n",
      "144 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910F29B90>\n",
      "145 <keras.src.layers.core.activation.Activation object at 0x000001A910F27410>\n",
      "146 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F37A10>\n",
      "147 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910F377D0>\n",
      "148 <keras.src.layers.core.activation.Activation object at 0x000001A910F25250>\n",
      "149 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F28FD0>\n",
      "150 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F3FED0>\n",
      "151 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C12B10>\n",
      "152 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910EE2A50>\n",
      "153 <keras.src.layers.merging.add.Add object at 0x000001A910EFA950>\n",
      "154 <keras.src.layers.core.activation.Activation object at 0x000001A910F487D0>\n",
      "155 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F57BD0>\n",
      "156 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C54A10>\n",
      "157 <keras.src.layers.core.activation.Activation object at 0x000001A910F56010>\n",
      "158 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F4B390>\n",
      "159 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910F55D10>\n",
      "160 <keras.src.layers.core.activation.Activation object at 0x000001A910F09950>\n",
      "161 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F60050>\n",
      "162 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910F4A7D0>\n",
      "163 <keras.src.layers.merging.add.Add object at 0x000001A910B01010>\n",
      "164 <keras.src.layers.core.activation.Activation object at 0x000001A910F6EAD0>\n",
      "165 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F7BDD0>\n",
      "166 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910C55310>\n",
      "167 <keras.src.layers.core.activation.Activation object at 0x000001A910F7E490>\n",
      "168 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F7AA50>\n",
      "169 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910F7B1D0>\n",
      "170 <keras.src.layers.core.activation.Activation object at 0x000001A910F6F890>\n",
      "171 <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A910F635D0>\n",
      "172 <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001A910F56150>\n",
      "173 <keras.src.layers.merging.add.Add object at 0x000001A910F60090>\n",
      "174 <keras.src.layers.core.activation.Activation object at 0x000001A910F480D0>\n"
     ]
    }
   ],
   "source": [
    "for ix in range(len(model1.layers)):\n",
    "    print(ix,model1.layers[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0tVkzE5aOGir",
   "metadata": {
    "id": "0tVkzE5aOGir"
   },
   "source": [
    "**Fine-Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "U3GvhrlAiQPk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3GvhrlAiQPk",
    "outputId": "494d0185-d53c-4064-8a2f-6866dcec8b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 conv1_pad False\n",
      "2 conv1_conv False\n",
      "3 conv1_bn False\n",
      "4 conv1_relu False\n",
      "5 pool1_pad False\n",
      "6 pool1_pool False\n",
      "7 conv2_block1_1_conv False\n",
      "8 conv2_block1_1_bn False\n",
      "9 conv2_block1_1_relu False\n",
      "10 conv2_block1_2_conv False\n",
      "11 conv2_block1_2_bn False\n",
      "12 conv2_block1_2_relu False\n",
      "13 conv2_block1_0_conv False\n",
      "14 conv2_block1_3_conv False\n",
      "15 conv2_block1_0_bn False\n",
      "16 conv2_block1_3_bn False\n",
      "17 conv2_block1_add False\n",
      "18 conv2_block1_out False\n",
      "19 conv2_block2_1_conv False\n",
      "20 conv2_block2_1_bn False\n",
      "21 conv2_block2_1_relu False\n",
      "22 conv2_block2_2_conv False\n",
      "23 conv2_block2_2_bn False\n",
      "24 conv2_block2_2_relu False\n",
      "25 conv2_block2_3_conv False\n",
      "26 conv2_block2_3_bn False\n",
      "27 conv2_block2_add False\n",
      "28 conv2_block2_out False\n",
      "29 conv2_block3_1_conv False\n",
      "30 conv2_block3_1_bn False\n",
      "31 conv2_block3_1_relu False\n",
      "32 conv2_block3_2_conv False\n",
      "33 conv2_block3_2_bn False\n",
      "34 conv2_block3_2_relu False\n",
      "35 conv2_block3_3_conv False\n",
      "36 conv2_block3_3_bn False\n",
      "37 conv2_block3_add False\n",
      "38 conv2_block3_out False\n",
      "39 conv3_block1_1_conv False\n",
      "40 conv3_block1_1_bn False\n",
      "41 conv3_block1_1_relu False\n",
      "42 conv3_block1_2_conv False\n",
      "43 conv3_block1_2_bn False\n",
      "44 conv3_block1_2_relu False\n",
      "45 conv3_block1_0_conv False\n",
      "46 conv3_block1_3_conv False\n",
      "47 conv3_block1_0_bn False\n",
      "48 conv3_block1_3_bn False\n",
      "49 conv3_block1_add False\n",
      "50 conv3_block1_out False\n",
      "51 conv3_block2_1_conv False\n",
      "52 conv3_block2_1_bn False\n",
      "53 conv3_block2_1_relu False\n",
      "54 conv3_block2_2_conv False\n",
      "55 conv3_block2_2_bn False\n",
      "56 conv3_block2_2_relu False\n",
      "57 conv3_block2_3_conv False\n",
      "58 conv3_block2_3_bn False\n",
      "59 conv3_block2_add False\n",
      "60 conv3_block2_out False\n",
      "61 conv3_block3_1_conv False\n",
      "62 conv3_block3_1_bn False\n",
      "63 conv3_block3_1_relu False\n",
      "64 conv3_block3_2_conv False\n",
      "65 conv3_block3_2_bn False\n",
      "66 conv3_block3_2_relu False\n",
      "67 conv3_block3_3_conv False\n",
      "68 conv3_block3_3_bn False\n",
      "69 conv3_block3_add False\n",
      "70 conv3_block3_out False\n",
      "71 conv3_block4_1_conv False\n",
      "72 conv3_block4_1_bn False\n",
      "73 conv3_block4_1_relu False\n",
      "74 conv3_block4_2_conv False\n",
      "75 conv3_block4_2_bn False\n",
      "76 conv3_block4_2_relu False\n",
      "77 conv3_block4_3_conv False\n",
      "78 conv3_block4_3_bn False\n",
      "79 conv3_block4_add False\n",
      "80 conv3_block4_out False\n",
      "81 conv4_block1_1_conv False\n",
      "82 conv4_block1_1_bn False\n",
      "83 conv4_block1_1_relu False\n",
      "84 conv4_block1_2_conv False\n",
      "85 conv4_block1_2_bn False\n",
      "86 conv4_block1_2_relu False\n",
      "87 conv4_block1_0_conv False\n",
      "88 conv4_block1_3_conv False\n",
      "89 conv4_block1_0_bn False\n",
      "90 conv4_block1_3_bn False\n",
      "91 conv4_block1_add False\n",
      "92 conv4_block1_out False\n",
      "93 conv4_block2_1_conv False\n",
      "94 conv4_block2_1_bn False\n",
      "95 conv4_block2_1_relu False\n",
      "96 conv4_block2_2_conv False\n",
      "97 conv4_block2_2_bn False\n",
      "98 conv4_block2_2_relu False\n",
      "99 conv4_block2_3_conv False\n",
      "100 conv4_block2_3_bn False\n",
      "101 conv4_block2_add False\n",
      "102 conv4_block2_out False\n",
      "103 conv4_block3_1_conv False\n",
      "104 conv4_block3_1_bn False\n",
      "105 conv4_block3_1_relu False\n",
      "106 conv4_block3_2_conv False\n",
      "107 conv4_block3_2_bn False\n",
      "108 conv4_block3_2_relu False\n",
      "109 conv4_block3_3_conv False\n",
      "110 conv4_block3_3_bn False\n",
      "111 conv4_block3_add False\n",
      "112 conv4_block3_out False\n",
      "113 conv4_block4_1_conv False\n",
      "114 conv4_block4_1_bn False\n",
      "115 conv4_block4_1_relu False\n",
      "116 conv4_block4_2_conv False\n",
      "117 conv4_block4_2_bn False\n",
      "118 conv4_block4_2_relu False\n",
      "119 conv4_block4_3_conv False\n",
      "120 conv4_block4_3_bn False\n",
      "121 conv4_block4_add False\n",
      "122 conv4_block4_out False\n",
      "123 conv4_block5_1_conv False\n",
      "124 conv4_block5_1_bn False\n",
      "125 conv4_block5_1_relu False\n",
      "126 conv4_block5_2_conv False\n",
      "127 conv4_block5_2_bn False\n",
      "128 conv4_block5_2_relu False\n",
      "129 conv4_block5_3_conv False\n",
      "130 conv4_block5_3_bn False\n",
      "131 conv4_block5_add False\n",
      "132 conv4_block5_out False\n",
      "133 conv4_block6_1_conv False\n",
      "134 conv4_block6_1_bn False\n",
      "135 conv4_block6_1_relu False\n",
      "136 conv4_block6_2_conv False\n",
      "137 conv4_block6_2_bn False\n",
      "138 conv4_block6_2_relu False\n",
      "139 conv4_block6_3_conv False\n",
      "140 conv4_block6_3_bn False\n",
      "141 conv4_block6_add False\n",
      "142 conv4_block6_out False\n",
      "143 conv5_block1_1_conv False\n",
      "144 conv5_block1_1_bn False\n",
      "145 conv5_block1_1_relu False\n",
      "146 conv5_block1_2_conv False\n",
      "147 conv5_block1_2_bn False\n",
      "148 conv5_block1_2_relu False\n",
      "149 conv5_block1_0_conv False\n",
      "150 conv5_block1_3_conv False\n",
      "151 conv5_block1_0_bn False\n",
      "152 conv5_block1_3_bn False\n",
      "153 conv5_block1_add False\n",
      "154 conv5_block1_out False\n",
      "155 conv5_block2_1_conv False\n",
      "156 conv5_block2_1_bn False\n",
      "157 conv5_block2_1_relu False\n",
      "158 conv5_block2_2_conv False\n",
      "159 conv5_block2_2_bn False\n",
      "160 conv5_block2_2_relu False\n",
      "161 conv5_block2_3_conv False\n",
      "162 conv5_block2_3_bn False\n",
      "163 conv5_block2_add False\n",
      "164 conv5_block2_out False\n",
      "165 conv5_block3_1_conv False\n",
      "166 conv5_block3_1_bn False\n",
      "167 conv5_block3_1_relu False\n",
      "168 conv5_block3_2_conv False\n",
      "169 conv5_block3_2_bn True\n",
      "170 conv5_block3_2_relu True\n",
      "171 conv5_block3_3_conv True\n",
      "172 conv5_block3_3_bn True\n",
      "173 conv5_block3_add True\n",
      "174 conv5_block3_out True\n"
     ]
    }
   ],
   "source": [
    "for layer in model1.layers[:169]:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(model1.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "o4hM2x6CjX1w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4hM2x6CjX1w",
    "outputId": "31227037-e115-4ab6-99ea-cef9606a7c95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 70, 70, 3)            0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 32, 32, 64)           9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 32, 32, 64)           256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 32, 32, 64)           0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 34, 34, 64)           0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 16, 16, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 16, 16, 64)           4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 16, 16, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 16, 16, 256)          16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 16, 16, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 16, 16, 256)          0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 16, 16, 64)           16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 16, 16, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 16, 16, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 16, 16, 256)          0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 16, 16, 64)           16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 16, 16, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 16, 16, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 16, 16, 256)          0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 16, 16, 256)          0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 8, 8, 128)            32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 8, 8, 512)            131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 8, 8, 512)            0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 8, 8, 512)            0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 8, 8, 128)            65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 8, 8, 512)            0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 8, 8, 512)            0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 8, 8, 128)            65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 8, 8, 512)            0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 8, 8, 512)            0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 8, 8, 128)            65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 8, 8, 128)            147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 8, 8, 512)            2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 8, 8, 512)            0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 8, 8, 512)            0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 4, 4, 256)            131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 4, 4, 1024)           525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 4, 4, 256)            262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 4, 4, 256)            590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 4, 4, 1024)           4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 4, 4, 1024)           0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 4, 4, 1024)           0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 2, 2, 512)            524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 2, 2, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 2, 2, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 2, 2, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 8192)                 0         ['conv5_block3_out[0][0]']    \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  2097408   ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 256)                  0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  32896     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 128)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 2)                    258       ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25718274 (98.11 MB)\n",
      "Trainable params: 3186306 (12.15 MB)\n",
      "Non-trainable params: 22531968 (85.95 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "av1 = Flatten()(model1.output)\n",
    "fc1 = Dense(256,activation='relu',kernel_regularizer= l2(0.01),input_dim=256)(av1)\n",
    "d1 = Dropout(0.5)(fc1)\n",
    "fc2 = Dense(128,activation='relu',kernel_regularizer= l2(0.01),input_dim=128)(d1)\n",
    "d2 = Dropout(0.5)(fc2)\n",
    "fc3 = Dense(2,activation = 'sigmoid')(d2)\n",
    "\n",
    "\n",
    "model_R = Model(model1.input,fc3)\n",
    "model_R.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cMxtQH6aOPDp",
   "metadata": {
    "id": "cMxtQH6aOPDp"
   },
   "source": [
    "**Average-Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6I_rhTgujkW7",
   "metadata": {
    "id": "6I_rhTgujkW7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "models = [model_R,model_vgg]\n",
    "model_input = tf.keras.Input(shape=(64,64, 3))\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
    "ensemble_model = tf.keras.models.Model(inputs=model_input, outputs=ensemble_output, name='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "FuWBS_8HkFQv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuWBS_8HkFQv",
    "outputId": "abcdc4c5-b58a-4777-cf42-828131233fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ensemble\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " model_1 (Functional)        (None, 2)                    2571827   ['input_3[0][0]']             \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 2)                    1527238   ['input_3[0][0]']             \n",
      "                                                          6                                       \n",
      "                                                                                                  \n",
      " average (Average)           (None, 2)                    0         ['model_1[0][0]',             \n",
      "                                                                     'model[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40990660 (156.37 MB)\n",
      "Trainable params: 8463620 (32.29 MB)\n",
      "Non-trainable params: 32527040 (124.08 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ensemble_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea9b07a5",
   "metadata": {
    "id": "ea9b07a5"
   },
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.0001)\n",
    "ensemble_model.compile(loss='categorical_crossentropy',optimizer = adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pxGH0aDkleTT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "pxGH0aDkleTT",
    "outputId": "b09697d5-36db-4056-8dda-afe5d48f6aee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(ensemble_model, 'model1.png', show_shapes= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "-w2DDD4ilrwy",
   "metadata": {
    "id": "-w2DDD4ilrwy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc101c81",
   "metadata": {
    "id": "cc101c81"
   },
   "outputs": [],
   "source": [
    "filepath=r\"D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min',patience=5)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q-1Wq4rdOZd0",
   "metadata": {
    "id": "Q-1Wq4rdOZd0"
   },
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lD4MiJ9BkN9g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lD4MiJ9BkN9g",
    "outputId": "7c5acab8-a760-41cf-f791-ff48e3cc85d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 6.1200 - accuracy: 0.6038\n",
      "Epoch 1: val_loss improved from inf to 3.34717, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANU\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885/885 [==============================] - 462s 519ms/step - loss: 6.1200 - accuracy: 0.6038 - val_loss: 3.3472 - val_accuracy: 0.7996\n",
      "Epoch 2/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 2.6205 - accuracy: 0.7212\n",
      "Epoch 2: val_loss improved from 3.34717 to 1.98150, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 460s 520ms/step - loss: 2.6205 - accuracy: 0.7212 - val_loss: 1.9815 - val_accuracy: 0.9192\n",
      "Epoch 3/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.7302 - accuracy: 0.7111\n",
      "Epoch 3: val_loss improved from 1.98150 to 1.12428, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 457s 516ms/step - loss: 1.7302 - accuracy: 0.7111 - val_loss: 1.1243 - val_accuracy: 1.0000\n",
      "Epoch 4/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 1.2253 - accuracy: 0.7676\n",
      "Epoch 4: val_loss improved from 1.12428 to 1.01115, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 461s 521ms/step - loss: 1.2253 - accuracy: 0.7676 - val_loss: 1.0111 - val_accuracy: 0.8947\n",
      "Epoch 5/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.9365 - accuracy: 0.8236\n",
      "Epoch 5: val_loss improved from 1.01115 to 0.86067, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 464s 525ms/step - loss: 0.9365 - accuracy: 0.8236 - val_loss: 0.8607 - val_accuracy: 0.8718\n",
      "Epoch 6/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.8275\n",
      "Epoch 6: val_loss improved from 0.86067 to 0.67647, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 458s 518ms/step - loss: 0.7696 - accuracy: 0.8275 - val_loss: 0.6765 - val_accuracy: 0.9100\n",
      "Epoch 7/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.6245 - accuracy: 0.8737\n",
      "Epoch 7: val_loss did not improve from 0.67647\n",
      "885/885 [==============================] - 457s 517ms/step - loss: 0.6245 - accuracy: 0.8737 - val_loss: 0.6932 - val_accuracy: 0.8527\n",
      "Epoch 8/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8747\n",
      "Epoch 8: val_loss improved from 0.67647 to 0.53402, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 453s 512ms/step - loss: 0.5449 - accuracy: 0.8747 - val_loss: 0.5340 - val_accuracy: 0.9055\n",
      "Epoch 9/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.8986\n",
      "Epoch 9: val_loss improved from 0.53402 to 0.48094, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 450s 509ms/step - loss: 0.4648 - accuracy: 0.8986 - val_loss: 0.4809 - val_accuracy: 0.8954\n",
      "Epoch 10/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.9103\n",
      "Epoch 10: val_loss did not improve from 0.48094\n",
      "885/885 [==============================] - 448s 507ms/step - loss: 0.4001 - accuracy: 0.9103 - val_loss: 0.6624 - val_accuracy: 0.8123\n",
      "Epoch 11/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.9208\n",
      "Epoch 11: val_loss improved from 0.48094 to 0.42078, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 478s 540ms/step - loss: 0.3527 - accuracy: 0.9208 - val_loss: 0.4208 - val_accuracy: 0.9084\n",
      "Epoch 12/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.9287\n",
      "Epoch 12: val_loss improved from 0.42078 to 0.35620, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 580s 655ms/step - loss: 0.3140 - accuracy: 0.9287 - val_loss: 0.3562 - val_accuracy: 0.9303\n",
      "Epoch 13/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.9337\n",
      "Epoch 13: val_loss improved from 0.35620 to 0.32238, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 582s 657ms/step - loss: 0.2823 - accuracy: 0.9337 - val_loss: 0.3224 - val_accuracy: 0.9307\n",
      "Epoch 14/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.9392\n",
      "Epoch 14: val_loss did not improve from 0.32238\n",
      "885/885 [==============================] - 580s 655ms/step - loss: 0.2590 - accuracy: 0.9392 - val_loss: 0.4545 - val_accuracy: 0.8839\n",
      "Epoch 15/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9431\n",
      "Epoch 15: val_loss improved from 0.32238 to 0.31808, saving model to D:\\Final Year Project\\parkinsons_detection_ensemble1.hdf5\n",
      "885/885 [==============================] - 582s 658ms/step - loss: 0.2385 - accuracy: 0.9431 - val_loss: 0.3181 - val_accuracy: 0.9262\n",
      "Epoch 16/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.9470\n",
      "Epoch 16: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 568s 642ms/step - loss: 0.2210 - accuracy: 0.9470 - val_loss: 0.6823 - val_accuracy: 0.8009\n",
      "Epoch 17/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9549\n",
      "Epoch 17: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 434s 490ms/step - loss: 0.2014 - accuracy: 0.9549 - val_loss: 0.4498 - val_accuracy: 0.8871\n",
      "Epoch 18/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9548\n",
      "Epoch 18: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 418s 472ms/step - loss: 0.1983 - accuracy: 0.9548 - val_loss: 0.4598 - val_accuracy: 0.8731\n",
      "Epoch 19/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9555\n",
      "Epoch 19: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 434s 490ms/step - loss: 0.1910 - accuracy: 0.9555 - val_loss: 0.3798 - val_accuracy: 0.9039\n",
      "Epoch 20/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9594\n",
      "Epoch 20: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 446s 504ms/step - loss: 0.1806 - accuracy: 0.9594 - val_loss: 0.3754 - val_accuracy: 0.8928\n",
      "Epoch 21/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9609\n",
      "Epoch 21: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 430s 486ms/step - loss: 0.1755 - accuracy: 0.9609 - val_loss: 0.4278 - val_accuracy: 0.8760\n",
      "Epoch 22/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9625\n",
      "Epoch 22: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 447s 505ms/step - loss: 0.1689 - accuracy: 0.9625 - val_loss: 0.4251 - val_accuracy: 0.8836\n",
      "Epoch 23/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9638\n",
      "Epoch 23: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 451s 510ms/step - loss: 0.1690 - accuracy: 0.9638 - val_loss: 0.6060 - val_accuracy: 0.8432\n",
      "Epoch 24/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9659\n",
      "Epoch 24: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 596s 674ms/step - loss: 0.1607 - accuracy: 0.9659 - val_loss: 0.4613 - val_accuracy: 0.8836\n",
      "Epoch 25/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9674\n",
      "Epoch 25: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 598s 676ms/step - loss: 0.1533 - accuracy: 0.9674 - val_loss: 0.3723 - val_accuracy: 0.9097\n",
      "Epoch 26/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9702\n",
      "Epoch 26: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 596s 673ms/step - loss: 0.1462 - accuracy: 0.9702 - val_loss: 0.4595 - val_accuracy: 0.8804\n",
      "Epoch 27/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9717\n",
      "Epoch 27: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 597s 675ms/step - loss: 0.1434 - accuracy: 0.9717 - val_loss: 0.6617 - val_accuracy: 0.8241\n",
      "Epoch 28/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9737\n",
      "Epoch 28: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 595s 672ms/step - loss: 0.1342 - accuracy: 0.9737 - val_loss: 0.5779 - val_accuracy: 0.8655\n",
      "Epoch 29/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9711\n",
      "Epoch 29: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 595s 673ms/step - loss: 0.1411 - accuracy: 0.9711 - val_loss: 0.4220 - val_accuracy: 0.8884\n",
      "Epoch 30/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9752\n",
      "Epoch 30: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 591s 668ms/step - loss: 0.1310 - accuracy: 0.9752 - val_loss: 0.8884 - val_accuracy: 0.7942\n",
      "Epoch 31/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.9733\n",
      "Epoch 31: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 475s 536ms/step - loss: 0.1372 - accuracy: 0.9733 - val_loss: 0.3779 - val_accuracy: 0.9113\n",
      "Epoch 32/32\n",
      "885/885 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9754\n",
      "Epoch 32: val_loss did not improve from 0.31808\n",
      "885/885 [==============================] - 468s 529ms/step - loss: 0.1312 - accuracy: 0.9754 - val_loss: 0.6588 - val_accuracy: 0.8438\n"
     ]
    }
   ],
   "source": [
    "hist = ensemble_model.fit(x_train,y_train,\n",
    "                    shuffle = True,\n",
    "                    batch_size=32,\n",
    "                    epochs = 32,\n",
    "                    validation_split = 0.10,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2d16b5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "b2d16b5a",
    "outputId": "b2acd7ca-881d-49b6-ce59-059c85a8e205"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a910f7b290>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMQAAAHACAYAAABNmbRLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3zTdf7A8VdW96alLaVl770FFRdDUFTc6AlyCqcnLs5TcaN3cnqKuH56LnAeODnvQAFRxMHee0OhdO/dNMnvj0+StnQladKk7fv5ePSRb5JvPvn003Tk3ff7/dFYLBYLQgghhBBCCCGEEEK0EVpvT0AIIYQQQgghhBBCiOYkATEhhBBCCCGEEEII0aZIQEwIIYQQQgghhBBCtCkSEBNCCCGEEEIIIYQQbYoExIQQQgghhBBCCCFEmyIBMSGEEEIIIYQQQgjRpkhATAghhBBCCCGEEEK0KRIQE0IIIYQQQgghhBBtit7bE2gKs9nM2bNnCQ0NRaPReHs6QgghhGghLBYLhYWFdOjQAa1W/j/oi+TvPCGEEEK4wtG/81p0QOzs2bMkJiZ6expCCCGEaKFOnz5Nx44dvT0NUQf5O08IIYQQTdHY33ktOiAWGhoKqE8yLCzM7eMbjUZWr17NhAkTMBgMbh+/tZJ1c56smWtk3Zwna+YaWTfn+fqaFRQUkJiYaP9bQvge+TvPN8m6OU/WzDWybs6TNXONrJvzfH3NHP07r0UHxGzp82FhYR77QykoKIiwsDCf/CL7Klk358mauUbWzXmyZq6RdXNeS1kzKcXzXfJ3nm+SdXOerJlrZN2cJ2vmGlk357WUNWvs7zxpmiGEEEIIIYQQQggh2hQJiAkhhBBCCCGEEEKINkUCYkIIIYQQQgghhBCiTWnRPcSEEEK0bBaLhcrKSkwmk7en0iCj0Yher6esrMzn5+orvL1mOp0OvV4vPcKEEEIIIUSdJCAmhBDCKyoqKkhNTaWkpMTbU2mUxWIhLi6O06dPS4DFQb6wZkFBQcTHx+Pn5+eV5xdCCCGEEL5LAmJCCCGandls5sSJE+h0Ojp06ICfn59PB5rMZjNFRUWEhISg1Uq3AUd4c80sFgsVFRVkZmZy4sQJevToIV83IYQQQghRgwTEhBBCNLuKigrMZjOJiYkEBQV5ezqNMpvNVFRUEBAQIIEVB3l7zQIDAzEYDJw6dco+DyGEEEIIIWzkr3ohhBBeI8El4Uny+hJCCCGEEPWRvxSFEEIIIYQQQgghRJsiATEhhBDCyzp37syiRYscPn/dunVoNBry8vI8NichhBBCCCFaMwmICSGEEA7S6XRoNJp6P5555hmXxt2yZQuzZ892+PwxY8aQmppKeHi4S8/nKAm8tQ3r169nypQpdOjQAY1Gw/Llyxt9zLp16xg6dCj+/v50796dJUuW1DrnzTffpHPnzgQEBDBq1Cg2b97s/skLIYQQQrhIAmJCCCGEg1JSUkhNTSU1NZVFixYRFhZmv56amspDDz1kP9disVBZWenQuDExMU5tLuDn50dcXJxP78wpWo7i4mIGDRrEm2++6dD5J06c4IorruCSSy5h586dPPDAA9x5552sWrXKfs6yZcuYO3cuTz/9NNu3b2fQoEFMnDiRjIwMT30aQgghhBBOkYCYEEII4aC4uDj7R3h4OBqNxn794MGDhIaG8t133zFs2DD8/f359ddfOXbsGFdffTWxsbGEhIQwYsQIfvjhhxrjnlsyqdFoeO+995g6dSpBQUH06NGDb7/91n7/uZlbS5YsISIiglWrVtGnTx9CQkK4/PLLSU1NtT+msrKS++67j4iICNq1a8cjjzzCjBkzuOaaa1xej9zcXKZPn05kZCRBQUFMmjSJI0eO2O9PTk7mqquuIjIykuDgYPr168fKlSvtj7311luJiYkhMDCQHj16sHjxYpfnIlw3adIk/va3vzF16lSHzn/77bfp0qULL7/8Mn369GHOnDlcf/31vPLKK/ZzFi5cyKxZs5g5cyZ9+/bl7bffJigoiA8++MBTn4YQQgghhFP03p6AL7vjo20cOK2jz8hiesZHeHs6QgjRqlksFkqNpmZ/3kCDzq2ZVo8++igvvfQSXbt2JTIyktOnTzN58mT+/ve/4+/vz0cffcSUKVM4dOgQSUlJ9Y4zf/58XnzxRf75z3/y+uuvc+utt3Lq1CmioqLqPL+kpISXXnqJjz/+GK1Wyx/+8AceeughPv30UwBeeOEFPv30UxYvXkyfPn149dVXWb58OZdcconLn+vtt9/OkSNH+PbbbwkLC+ORRx5h8uTJ7N+/H51Ox1//+lfMZjPr168nODiY/fv3ExISAsCTTz7J/v37+e6774iOjubo0aOUlpa6PBfRfDZs2MC4ceNq3DZx4kQeeOABACoqKti2bRvz5s2z36/Vahk3bhwbNmyod9zy8nLKy8vt1wsKCgAwGo0YjUY3fgbYx61+2Zw0+75Ce2glpitfA7/gZn/+pvDmurVUsmaukXVznqyZa2TdnOfra+bovCQg1oBT2aVklmnIKqqgp7cnI4QQrVyp0UTfp1Y1fqKb7X92IkF+7vt1+OyzzzJ+/Hj79aioKAYNGmS//txzz/HNN9/w7bffMmfOnHrHuf3225k2bRoAzz//PK+99hqbN2/m8ssvr/N8o9HI22+/Tbdu3QCYM2cOzz77rP3+119/nXnz5tmzgN544w17tpYrbIGw3377jTFjxgDw6aefkpiYyPLly7nuuus4c+YMN9xwAwMGDACga9eu9scnJyczZMgQhg8fDqgsOdEypKWlERsbW+O22NhYCgoKKC0tJTc3F5PJVOc5Bw8erHfcBQsWMH/+/Fq3r1692qmSYmetWbPGY2PXZ/y+xwmqyGJHSTxnosY0+/O7gzfWraWTNXONrJvzZM1cI+vmPF9ds5KSEofOk4BYAyKDDZzKgbwS34x6CiGE8D22AI9NUVERzzzzDCtWrCA1NZXKykpKS0tJTk5ucJyBAwfaj4ODgwkLC2uw/1JQUJA9GAYQHx9vPz8/P5/09HRGjhxpv1+n0zFs2DDMZrNTn5/NgQMH0Ov1jBo1yn5bu3bt6NWrFwcOHADgT3/6E3/5y19Ys2YN48aN47rrrrN/XnfffTfXXXcd27dvZ8KECVxzzTX2wJpom+bNm8fcuXPt1wsKCkhMTGTChAmEhYW5/fmMRiNr1qxh/PjxGAwGt49fr8I0DDuyABicEMDASyY333O7gdfWrQWTNXONrJvzZM1cI+vmPF9fM1uWeWMkINaAiED1hc0tqfDyTIQQovULNOjY/+xErzyvOwUH1yx/euihh1izZg0vvfQS3bt3JzAwkOuvv56KioZ/t5z7x4VGo2kweFXX+RaLxcnZu9f06dO5+uqr+e6771i9ejULFizg5Zdf5t5772XSpEmcOnWKlStXsmbNGi677DLuueceXnrpJa/OWTQuLi6O9PT0Grelp6cTFhZGYGAgOp0OnU5X5zlxcXH1juvv74+/v3+t2w0Gg0f/2Pb0+LWk77If6rKPoPPBNxKOaPZ1awVkzVwj6+Y8WTPXyLo5z1fXzNE5eb2pfkpKCn/4wx9o164dgYGBDBgwgK1bt3p7WgBEBtkCYpIhJoQQnqbRaAjy0zf7h6d3avztt9+4/fbbmTp1KgMGDCAuLo6TJ0969DnPFR4eTmxsLFu2bLHfZjKZ2L59u8tj9unTh8rKSjZt2mS/LTs7m0OHDtG3b1/7bYmJidx11118/fXX/OUvf+Hdd9+13xcTE8OMGTP45JNPWLRoEe+8847L8xHNZ/To0axdu7bGbWvWrGH06NGA2gV12LBhNc4xm82sXbvWfk6bllLt79zMA96bhxBCCNHGeTVDLDc3l/PPP59LLrmE7777jpiYGI4cOUJkZKQ3p2UXGeQHQF6pBMSEEEK4pkePHnz99ddMmTIFjUbDk08+6XKZYlPce++9LFiwgO7du9O7d29ef/11cnNzHQoI7tmzh9DQUPt1jUbDoEGDuPrqq5k1axb/+te/CA0N5dFHHyUhIYGrr74aUCVwV111Fb179yY3N5effvqJPn36APDUU08xbNgw+vXrR3l5Of/73//s94nmVVRUxNGjR+3XT5w4wc6dO4mKiiIpKYl58+aRkpLCRx99BMBdd93FG2+8wcMPP8wf//hHfvzxRz7//HNWrFhhH2Pu3LnMmDGD4cOHM3LkSBYtWkRxcTEzZ85s9s/P55ypFhDLOQHGUjAEem8+QgghRBvl1YDYCy+8QGJiYo1t1rt06eLFGdUUESQlk0IIIZpm4cKF/PGPf2TMmDFER0fzyCOPONzXwJ0eeeQR0tLSmD59OjqdjtmzZzNx4kR0usZLRseOHVvjuk6no7KyksWLF3P//fdz5ZVXUlFRwdixY1m5ciUGgwGz2YzJZOLee+/lzJkzhIWFcfnll/PKK68AKoto3rx5nDx5ksDAQC688EKWLl3qkc9dNGzr1q01dhu19fGaMWMGS5YsITU1tUbPuy5durBixQoefPBBXn31VTp27Mh7773HxIlVJc833XQTmZmZPPXUU6SlpTF48GC+//77Wo322xyzCVKsmZkaLVjMkHUE4gc2/DghhBBCuJ1XA2LffvstEydO5IYbbuDnn38mISGBP//5z8yaNavO85t7O+4wf/UmIaeowme3E/VFvr4Fqy+SNXONrJvzfGXNjEYjFosFs9nslWwpZ9l6cdnmDKo/1vTp0+3Xx44di8lkAqjxOSUlJfHDDz/UGO/uu++ucd7x48drXK9rnJycHPtt5z7XuXMBuOqqqzCZTPbbtFotr776Kq+++qr9cf369eOGG26o92tQ/XnOZTabCQ8PZ8mSJXXeZ7FYePHFFwkNDa2VhWY2m3nsscd47LHH6nysu9jmYTQaawX+vP094EsuvvjiBvvN1fU1vvjii9mxY0eD486ZM6fBnVTbpIwDYCwGvxCI7QenN0HmQQmICSGEEF7g1YDY8ePHeeutt5g7dy6PPfYYW7Zs4b777sPPz48ZM2bUOr+5t+M+la0BdJxMzWzS1vRtla9uwerLZM1cI+vmPG+vmV6vJy4ujqKiokaby/uSwsJCb0/BZcnJyfz000+cf/75lJeX8+6773LixAmmTJni0Yw1b65ZRUUFpaWlrF+/nsrKyhr3ObodtxBudcbaxy9hKLTrrgJiGdJHTAghhPAGrwbEzGYzw4cP5/nnnwdgyJAh7N27l7fffrvOgFhzb8cdfiSDxYd3gl8wkydf4PbxWytf34LVF8mauUbWzXm+smZlZWWcPn2akJAQAgICvDYPR1ksFgoLC+vMdmopwsPD+fzzz3nqqaewWCz079+f1atXM2LECI88ny+sWVlZGYGBgYwdO7bW68wbZatC2BvqJwyHUOuOm5mHvDcfIYQQog3zakAsPj6+xk5UoHat+uqrr+o8v7m3444JUw1O80qN8mbbBb66BasvkzVzjayb87y9ZiaTCY1Gg1arRav1+obHjbKV8dnm3BJ16tSJ3377rdmezxfWTKvVotFo6ny9y88M4RW2hvodR4BfsDqWnSaFEEIIr/BqQOz888/n0KGa/xU7fPgwnTp18tKMaoqw7jKZX2rEbLag1bbMrAAhhBBCCOFlZflV2WAdh1fdLjtNCiGEEF7h1X9zP/jgg2zcuJHnn3+eo0eP8tlnn/HOO+9wzz33eHNadhGB6r/HZgsUlEnzXSGEEEII4aKU7YAFIpIgpD0Ex0BgpLot64i3ZyeEEEK0OV4NiI0YMYJvvvmGf//73/Tv35/nnnuORYsWceutt3pzWnZ+ei3+OrXrUk5xy2n6LIQQQgghfEz1/mEAGg3E9FHHmQe9MychhBCiDfNqySTAlVdeyZVXXuntadQrWA/lJsgtkQwxIYQQQgjhour9w2za94bk3yUgJoQQQnhBy+wM3IyCrSHDvBLJEBNCCCGEEC6wWODMFnVcPSAW01tdZkhATAghhGhuEhBrRLBeSiaFEEIIIUQT5J6EkmzQGiBuQNXttoCY7DQphBBCNDsJiDUi2Lore56UTAohhHCTiy++mAceeMB+vXPnzixatKjBx2g0GpYvX97k53bXOEIIJ9jKJeMHgiGg6vb21h5iuSfVTpNCCCGEaDYSEGuErWQyR0omhRCizbvqqqu4/PLL67zvl19+QaPRsHv3bqfH3bJlC7Nnz27q9Gp45plnGDx4cK3bU1NTmTRpkluf61xLliwhKirKo88hRItybkN9G9tOkxaz7DQphBBCNDMJiDXCVjIpPcSEEEL88Y9/ZM2aNZw5c6bWfYsXL2b48OEMHDjQ6XFjYmIICgpyxxQbFRcXh7+/f7M8lxDCqq7+YSA7TQohhBBeJAGxRthKJnOLpWRSCCHauiuvvJKYmBiWLFlS4/aioiK++OIL7rjjDrKzs5k2bRoJCQkEBQUxYMAA/v3vfzc47rklk0eOHGHs2LEEBATQt29f1qxZU+sxjzzyCD179iQoKIiuXbvy5JNPYjSq31VLlixh/vz57Nq1C41Gg0ajsc/53JLJPXv2cOmllxIYGEi7du2YPXs2RUVF9vtvv/12rrnmGl566SXi4+Np164d99xzj/25XJGcnMzVV19NSEgIYWFh3HjjjaSnp9vv37VrF5dccgmhoaGEhYUxbNgwtm5VGTanTp1iypQpREZGEhwcTL9+/Vi5cqXLcxHC4yrLIW2POu44vPb97W19xCQgJoQQQjQnvbcn4OukZFIIIZqJxQLGkuZ/XkOQytJwgF6vZ/r06SxZsoTHH38cjfVxX3zxBSaTiWnTplFUVMSwYcN45JFHCAsLY8WKFdx2221069aNkSNHNvocZrOZa6+9ltjYWDZt2kR+fn6NfmM2oaGhLFmyhA4dOrBnzx5mzZpFaGgoDz/8MDfddBN79+7l+++/54cffgAgPDy81hjFxcVMnDiR0aNHs2XLFjIyMrjzzjuZM2dOjaDfTz/9RHx8PD/99BNHjx7lpptuYvDgwcyaNcuhdTv387MFw37++WcqKyu55557uOmmm1i3bh0At956K0OGDOGtt95Cp9Oxc+dODAb1H6p77rmHiooK1q9fT3BwMPv37yckJMTpeQjRbFJ3g6kCgtpBZOfa98tOk0IIIdoQk9lCekEZFiAhItCrc5GAWCOqmupLQEwIITzKWALPd2j+533sLPgFO3z6H//4R/75z3/y888/c/HFFwOqXPK6664jPDyc8PBwHnroIfv59957L6tWreLzzz93KCD2ww8/cPDgQVatWkWHDmo9nn/++Vp9v5544gn7cefOnXnooYdYunQpDz/8MIGBgYSEhKDX64mLi6v3uT777DPKysr46KOPCA5Wa/DGG28wZcoUXnjhBWJjYwGIjIzkjTfeQKfT0bt3b6644grWrl3rUkBs7dq17NmzhxMnTpCYmAjARx99RL9+/diyZQsjRowgOTmZv/71r/TurQIFPXr0sD8+OTmZ6667jgED1E59Xbt2dXoOQjSr6uWSdQXfZadJIYQQzaC80sTelHy2nMxl68lc9qbkE+SnIzYsgLhw60dYzcvoEH90Wsf+cWxTUlHJ2bxSzuSWcjavjJS8EnWZW0pKXilpBWWYzBauHZLAwpsGe+aTdZAExBph6yGWIyWTQgghgN69ezNmzBg++OADLr74Yo4ePcovv/zCs88+C4DJZOL555/n888/JyUlhYqKCsrLyx3uEXbgwAESExPtwTCA0aNH1zpv2bJlvPbaaxw7doyioiIqKysJCwtz6nM5cOAAgwYNsgfDAM4//3zMZjOHDh2yB8T69euHTqeznxMfH8+ePXuceq7qz5mYmGgPhgH07duXiIgIDhw4wIgRI5g7dy533nknH3/8MePGjeOGG26gW7duANx3333cfffdrF69mnHjxnHddde51LdNiGZTX0N9m3N3mjR497/lQgghPKPMaCI1v4yzeSowdDavlIzCcqKD/egSE0yX6BC6RAcTHmhwy/PllxjZlpzDlpO5bDuZy84zeVRUmmuddzyruN4xdFoN7UP9iQ0LID48wB48iwk2sDdbQ9pvJ0ktqKjxOeWWNB470Ws1lJtqz6W5SUCsEbaSybySCiwWi708RgghhJsZglS2ljee10l33HEH9957L2+++SaLFy+mW7duXHTRRQD885//5NVXX2XRokUMGDCA4OBgHnjgASoq3JdpvGHDBm699Vbmz5/PxIkTCQ8PZ+nSpbz88stue47qbOWKNhqNBrPZc3/EPPPMM9xyyy2sWLGC7777jqeffpqlS5cydepU7rzzTiZOnMiKFStYvXo1CxYs4OWXX+bee+/12HyEaBJ7hlg9ATHbTpOluWqnyXgJ8AohREtjNlvIKi7nbJ4KeKkP63G+up5V5NjfgtEhfnSJDrZ+qCBZt5hgktoF4a/X1fkYi8XCmdxStp7KYas1A+xQemGdYw/rFMmIzlEMTozAaFLli2kFZaTlWz+sxxmFKpMrNb+M1Pwydp4+dzQdHD5c53xCA/QkRATSISKw6jIykISIABIigogJdT7zzBMkINYIW0Cs0myhqLyS0AD3RGuFEEKcQ6NxqnTRm2688Ubuv/9+PvvsMz766CPuvvtu+z9MfvvtN66++mr+8Ic/AKpn1uHDh+nbt69DY/fp04fTp0+TmppKfHw8ABs3bqxxzu+//06nTp14/PHH7bedOnWqxjl+fn6YTKZGn2vJkiUUFxfbs8R+++03tFotvXr1cmi+zrJ9fqdPn7Znie3fv5+8vLwaa9SzZ0969uzJgw8+yLRp01i8eDFTp04FIDExkbvuuou77rqLefPm8e6770pATPimogzISwY0kDC07nNsO00m/64a60tATAghfEJFpZnckgqyiyrIKa4gu7hcXRZVkF1cQY71ekZhOal5ZVQ4kPEUaNCREGkLFAUQE+JPZlE5xzOLOZFVTEZhOVlFFWQVVbDlZG6Nx2o1kBAZSJfoELpaA2YWi4Wtp1QALK2grNbzdY0OZnjnSIZ3jmJE5yg6twtyOMnHZLaQVVROqjVQll6gAmPpBWWk5pWQnpVD387xdIwKomO1oFeHiEDCWkjcRAJijfDTQYBBS5nRTG6xUQJiQgghCAkJ4aabbmLevHkUFBRw++232+/r0aMHX375Jb///juRkZEsXLiQ9PR0hwNi48aNo2fPnsyYMYN//vOfFBQU1Ah82Z4jOTmZpUuXMmLECFasWME333xT45zOnTtz4sQJdu7cSceOHQkNDcXf37/GObfeeitPP/00M2bM4JlnniEzM5N7772X2267zV4u6SqTycSePXsIDg5Gq1WbWvv7+zNu3DgGDBjArbfeyqJFi6isrOTPf/4zF110EcOHD6e0tJS//vWvXH/99XTp0oUzZ86wZcsWrrvuOgAeeOABJk2aRM+ePcnNzeWnn36iT58+TZqrEB5zxlouGdMLAmpvbGHXvndVQEwIIYTHFZdXcjyzmKOZhRxNL2T7MS3//XQHuaWV1qBXOQVllU6NqdVgLy2snhmlPgJIiAgkPNDQYECqqLySk1nFHMss4kRWsf3jeGYxReWVnM4p5XROKesPZ9Z6rF6roX9COCOsAbBhnSKJDvGv41kco9NqiA1TZZIk1rzPaDSycuVKJk8eWKuSoCWRgJgDIoP8SM0vI7ekgqR2zpfWCCGEaH3uuOMO3n//fSZPnlyj39cTTzzB8ePHmThxIkFBQcyePZtrrrmG/Px8h8bVarV888033HHHHYwcOZLOnTvz2muvcfnll9vPueqqq3jwwQeZM2cO5eXlXHHFFTz55JM888wz9nOuu+46vv76ay655BLy8vJYvHhxjcAdQFBQEKtWreL+++9nxIgRBAUFcd1117Fw4cImrQ1AUVERY8eOrXFbt27dOHr0KP/5z3+49957GTt2LFqtlssvv5zXX38dAJ1OR3Z2NtOnTyc9PZ3o6GiuvfZa5s+fD6hA2z333MOZM2cICwvj8ssv55VXXmnyfIXwCFv/sPrKJW1kp0khhHA7i8VCdnEFRzOKOJpRxLFM62VGEWfzz82m0kJG7SCTVgNRwX72j3Yh/rSzHQf7ERXsT3SIHwmRgcSGBWDQaZs05xB/Pf0TwumfUPOfKBaLhayiCmtwTAXLjmUWYzKbGZqkAmCDEyMI9Ku7pFLUTQJiDogINJCaX0aO7DQphBDCavTo0Vgsllq3R0VFsXz58gYfu27duhrXT548WeN6z549+eWXX2rcdu5zvfjii7z44os1bnvggQfsx/7+/nz55Ze1nvvccQYMGMCPP/5Y71yXLFlS67ZFixbVez7A7bffzvTp0ykoKCAsLMyeIWaTlJTEf/7znzof6+fnx7///e96x7YFzoRoEWz9w+prqG8jO00KIYTLKk1mzuaVcTSzkGMZxSoAlqkCYHkNNHiPDvGjW0wIndsFUZh+ilGD+9M+LJB2If72gFd4oAGtD/S60mg0xIT6ExPqz8guUd6eTqshATEHRAapFMA8CYgJIYQQQghHmE2Qsl0ddxzR8Lm2gJjsNCmEEAAYTWayiyrIKions6icLGtvrczCcrKKqn+o/l710WigY2Qg3WNC6N5efXSzHkcE+annMhpZufIkk0cmtujyP+E8CYg5INL6jZJb3Pj2oUIIIYQQQpB5CCqKwBAM7RvpcxfSXnaaFEK0CRaLhYKyymo7MZaSkldGan4pGQVVga7cBjK76uKn09IlOlgFvKyBr+4xIXSNCSbAIGWEom4SEHNAhDVDLFcyxIQQQgghhCPs5ZJDQdvImzHZaVII0UoYTWbS8stUsCu/lLN5ZaRUC36dzSujqNyxZvU6rYaoYD+iQ1SfrphQf2JC/NX1UHV7TKi6Hhnkh84HShtFyyIBMQdESkBMCCGEEEI4w9GG+jYxvWSnSSGEzykzmsgtUWWJucVGcksq1Ee145xidZlVWEF6YRl1tFitJSrYr8ZujPHhajdDW7Arxhrk8oX+XaL1koCYA+wZYlIyKYQQQgghHHHGGhBrrKG+ja2sUnaaFEJ4UJnRRFZRub0/l60Pl+0yt9gW8Kogt8RIqdHk9HP46bR0iFDBLttHQvXr4YGyG6LwCRIQc4Ct2Z5kiAkhhHvVtUujEO4iry/hNeWFkGHdMdLhDDHZaVII4TxbT67sonLS80vYla0hd/NpcksqyS4uJ6tQBbuyiyvIKiyn0MFyxer0Wg0RQX5EBRuIDPJTH8F+RAYZiAq2XTfQLtifDhGBtAuWzC7RMkhAzAFR9pJJyRATQgh3sO3gU1JSQmCg7KYmPKOkpARAdowSzS9lO2CB8EQIjXPsMbLTpBACFeAqqTCpDK7icnKKKlRgy7qbYrY1uJVtvT2nuAKjqfo/gHRwuOHAukGnsfbl8qddiJ/9ODrEr1qAy4+oID8igg2E+uvRaCTAJVofCYg5oKpkUjLEhBDCHXQ6HREREWRkZAAQFBTk039omc1mKioqKCsrQ6vVens6LYI318xisVBSUkJGRgYRERHodFKWIZqZraG+o9lhIDtNCtFG5RRXsCM5l+3JuWw/lceelHyHm85XF+qvJyrYD01FMT0SY4kJCyA62I9oa9P5dtWOwwIkwCUESEDMIdV3mbRYLPLDQwgh3CAuTmVN2IJivsxisVBaWkpgYKD8DnCQL6xZRESE/XUmRLNK2aYuHe0fBrLTpBBtQKXJzMG0QnaczmPHKRUEO5ldUue5AQYt7YJV1la7EH+igv1UNldwtWNrhldkkB8BBh1Go5GVK1cyefJgyY4WwgESEHNApLWHWHmlmVKjiSA/WTYhhGgqjUZDfHw87du3x2j07ZJ0o9HI+vXrGTt2rPyB6SBvr5nBYJDMMOEdFku1DLERzj1WdpoUolXJLipne3KePQNs95l8SipqN6nvFhPM0KRIhiRFMiQpgk7tguQ9pxDNQL7LHBDsp8Og02A0WcgtMcoPJyGEcCOdTufzgQudTkdlZSUBAQESEHOQrJlos/KSoTgTtAbns7xkp0kh3MadlT0VlWZKKiopqTBVuzznuLySEqOJknITKXmlbE/O5VQd2V+h/noGJ0XYg19DEiPsm7gJIZqXRHYcoNFoiAzyI6OwnNziChIipMmpEEIIIYSogy07LK6/843x7TtNSkBMCFdUmsys3JvG+78cZ9eZfAC0GtBpNWg0GnQaDVoNaLUadFoNWo3tg6rrWtBqNJQbzRRXVFJaYaLS7Pquxd3bhzA0KcKeAda9fQg62YFRCJ8gATEH2QNiJdJYXwghhBCtz5tvvsk///lP0tLSGDRoEK+//jojR46s81yj0ciCBQv48MMPSUlJoVevXrzwwgtcfvnl9nOeeeYZ5s+fX+NxvXr14uDBVh7ssfUPc7ZcEqrtNHkCjGVgCHDfvIRoxQrLjCzbcprFv50kJa+0xn1mC5hNFsD1oJaNn05LoJ+OIPuHnkA/HcHWY9vtUcH+DE6KYHDHCMKDJEtaCF8lATEHVTXW9+0+N0IIIYQQzlq2bBlz587l7bffZtSoUSxatIiJEydy6NAh2rdvX+v8J554gk8++YR3332X3r17s2rVKqZOncrvv//OkCFD7Of169ePH374wX5dr28Df3raMsScaahvU2OnycPSWF+IRqTml7Lkt5N8timZQuvOjO2C/ZgxpjPXDk3AX6/DYrFgslhUYMxswWyxYDJbr1uqXTer6yaLBYvFgr9eZw126e1BMINOdpoWojVpA3+VuEdUsKrrzi2WDDEhhBBCtC4LFy5k1qxZzJw5E4C3336bFStW8MEHH/Doo4/WOv/jjz/m8ccfZ/LkyQDcfffd/PDDD7z88st88skn9vP0en3b2umzshxSd6njji4ExGrsNHlIAmJC1GPf2Xze++UE/9111l7O2C0mmFkXduWaIQkEGHy7N6kQwjdIQMxBtkaHUjIphBBCiNakoqKCbdu2MW/ePPttWq2WcePGsWHDhjofU15eTkBAzXK+wMBAfv311xq3HTlyhA4dOhAQEMDo0aNZsGABSUlJ9Y5ZXl5uv15QUACo8kxP7ERrG9OdY2tSdqI3VWAJjKIyNBFcGFvbrge65N8xpe3D3Ocat83NXTyxbq2drJlrzl03i8XC+iNZfPDbKX4/nmM/b1SXSO44vzMX9YhGq9UAZoxGszem7HXyWnONrJvzfH3NHJ2XBMQcFBWsSibzpGRSCCGEEK1IVlYWJpOJ2NjYGrfHxsbW2+9r4sSJLFy4kLFjx9KtWzfWrl3L119/jclksp8zatQolixZQq9evUhNTWX+/PlceOGF7N27l9DQ0FpjLliwoFbPMYDVq1cTFBTUxM+yfmvWrHHbWF0zVjMASDcksum771wao0umiYFAxr6f2Vw6pNHzvcWd69ZWyJq55rtVa9iapeGns1rSSlUzei0WBrezcGkHM4khmZQey+T7Y16eqA+R15prZN2c56trVlJSe4fXukhAzEGR1gyxHCmZFEIIIUQb9+qrrzJr1ix69+6NRqOhW7duzJw5kw8++MB+zqRJk+zHAwcOZNSoUXTq1InPP/+cO+64o9aY8+bNY+7cufbrBQUFJCYmMmHCBMLCwtz+ORiNRtasWcP48eMxGNzT9Fq3/D+QAjGDJzH5wskujaE5EQKffUKcLs9ekupLPLFurZ2smWsy80v4+7Kf2ZQbSFaReg8W7K/jpmEdmTE6iQ4RTu7i2gbIa801sm7O8/U1s2WZN0YCYg6SkkkhhBBCtEbR0dHodDrS09Nr3J6enl5v/6+YmBiWL19OWVkZ2dnZdOjQgUcffZSuXbvW+zwRERH07NmTo0eP1nm/v78//v7+tW43GAwe/WPbreOfVTtM6pJGonN1zPj+AGhyT2LA5LM7TXr669IayZo1LKOgjO3JuWw7pT72pORjNOmACuLDA5h5fmduHplEWICsYWPkteYaWTfn+eqaOTonCYg5yFYyKQExIYQQQrQmfn5+DBs2jLVr13LNNdcAYDabWbt2LXPmzGnwsQEBASQkJGA0Gvnqq6+48cYb6z23qKiIY8eOcdttt7lz+r6jOAtyT6rjhGGujyM7TYo2oNJk5mBaYY0A2Jnc0lrnJQRZeHDyQK4e0lF2eBRCuJ0ExBxkzxArlh5iQgghhGhd5s6dy4wZMxg+fDgjR45k0aJFFBcX23ednD59OgkJCSxYsACATZs2kZKSwuDBg0lJSeGZZ57BbDbz8MMP28d86KGHmDJlCp06deLs2bM8/fTT6HQ6pk2b5pXP0ePObFWX0T0hMML1cTQaiOkNyRtkp0nRauSVVLAjOc8e/Np1Jo+SClONczQa6BUbyrBOkQzrFMnADqHs3biOKwbFSzBMCOEREhBzUJQ1IJYnGWJCCCGEaGVuuukmMjMzeeqpp0hLS2Pw4MF8//339kb7ycnJaLVVb0jLysp44oknOH78OCEhIUyePJmPP/6YiIgI+zlnzpxh2rRpZGdnExMTwwUXXMDGjRuJiYlp7k+veZzZoi47jmj6WPaA2IGmjyVEMzObLRzNLGL7qVx7BtixzOJa54X66xnSKZJhSSoANigxnNBq5ZBGo5F9muacuRCirZGAmINsTfWLK0yUV5rw1+u8PCMhhBBCCPeZM2dOvSWS69atq3H9oosuYv/+/Q2Ot3TpUndNrWVIsWaIdRze9LHa91GXGXXv8imEL8kvMbLjdC7bk/PYkZzLzuQ8Cssra53XNTqYodbsr6FJkfRoH4JWKxEvIYT3SEDMQaEBerQaMFsgr8RIbJgExIQQQgghBGA2Q8p2dZzghoBYTC91mSkBMeFbzGYLRzKK2J6ca88Aqyv7K9CgY2DHcBUAS4pkSFIE7UJqb5ohhBDeJAExB2m1GiKD/MguriCnuILYMN/c8UcIIYQQQjSzrMNQXgCGIGjft+njxVgzxHJPgLHMZ3eaFK1ffomR7adz2XFKZYDtOl139lendkEMTYpkaFIEQ5Ii6R0Xil76fgkhfJwExJwQEWQgu7hCdpoUQgghhBBVbP3DOgwBnRv+vJadJoUXJWeXsHp/Gqv3p7P1ZA5mS837g/x0DOoYwZCkCIZK9pcQogWTgJgTooL9OJZZTF6J7DQphBBCCCGs3Nk/DGSnSdGsLBYL+84WsHqfCoIdTCuscX+X6GCGWDO/hiZF0CtWsr+EEK2DBMScEGFtrJ9TLBliQgghhBDC6owtIOaGHSZtZKdJ4UFGk5ktJ3JYvT+d1fvSOJtfZr9Pp9UwqksUE/rGMq5vLB0jg7w4UyGE8BwJiDkhMkhtA5wnJZNCCCGEEAKgvAgyrDtuuqOhvo3sNCncrKSikvWHM1m9L521BzPIL62qegk06LioZwwT+sVyae/29kQAIYRozSQg5oTIYFuGmJRMCiGEEEII4OwOsJghrCOExbtvXNlpUrhBZmE5Px3MYPX+NH45kkV5pdl+X1SwH+P6tGdC3zgu6BFNgEHnxZkKIUTzk4CYEyKt/ymRDDEhhBBCCAFUNdTvOMy948pOk8IFJrOFnadzWXcok3WHMtmTkl/j/qSoICb0jWVCvziGdYpEp9V4aaZCCOF9EhBzQpQ1ICa7TAohhBBCCABStqlLd/YPA9lpUjgsq6icnw9lsu5wJusPZ9YohQQYkBBuD4L1jA1Bo5EgmBBCgATEnBJh7SGWI7tMCiGEEEIIi6UqQ8yd/cNAdpoUVdL3Q+5JMFeC2YjZVElyZj5HUnM5mpZHel4RekwkYOI2TIQEWOgc5U+XSD8Sww0EtUuE0XNAKztDCiFEdV4NiD3zzDPMnz+/xm29evXi4EHf7JVg6yEmJZNCCCGEEIL8M1CUDlo9xA9y//iy06TY/C6sfKjGTVqgs/VjPIChjsflWD9sIhKh31SPTFEIIVoqr2eI9evXjx9++MF+Xa/3+pTqZeshllMsATEhhBBCiDbPlh0W2x/8gtw/vuw02aYZj/+K7rtH0QIHzEkUEUClRU8lWtAZCA8OJCo0iOjwYAL8/EFnUMFZrb7qOH0vHF8HOz+TgJgQQpzD69EnvV5PXFyct6fhkEhryWRhWSWVJjN6naQdCyGEEEK0WWe2qsuObi6XtJGdJtuk/FIj367fwhUbbiGKSv5rOo97jffSNz6cS3rHcHGv9gxJjHDsvUj2MXh9KBz9AQrTILRlvO8SQojm4PWA2JEjR+jQoQMBAQGMHj2aBQsWkJSU5O1p1Sk80IBGo9pF5JUaiQ7x9/aUhBBCCCGEt6TYAmJubqhvIztNtimnc0pY/NtJvtlylMU8Q5Q2n8N04uxFL7FpZA9iw1z4+rfrBonnwemNsHsZnH+/+ydenxPrVdD4ggdVTzwhhPAxXg2IjRo1iiVLltCrVy9SU1OZP38+F154IXv37iU0NLTW+eXl5ZSXl9uvFxQUAGA0GjEa3d/o3jZm9bHDAvTkl1aSkV9CuL9kiNWlrnUTDZM1c42sm/NkzVwj6+Y8X18zX52XaEEqK+DsTnXs7ob6NiHtISACyvJkp8lWbPeZPN5Zf5zv9qZhMpt5Qf8+g/XHqDCE0Wn2N/wpplvTnmDwLSogtvMzGHNf8wSnKkpg2W3qtdtxBHS50PPPKYQQTvJqQGzSpEn244EDBzJq1Cg6derE559/zh133FHr/AULFtRqwg+wevVqgoI80LfBas2aNfZjg0UHaPj+x/UcCfPYU7YK1ddNOEbWzDWybs6TNXONrJvzfHXNSkpKvD0F0dKl7wVTuQpYtWtiwKI+Go3qIyY7TbY6ZrOFHw9m8M4vx9l8oqr7/TNxG7gpbx0WjRa/mz+EpgbDAPpdA989okpvz26HhGFNH7Mx+75WwTBQwVwJiAkhfJDXSyari4iIoGfPnhw9erTO++fNm8fcuXPt1wsKCkhMTGTChAmEhbk/OmU0GlmzZg3jx4/HYFD9wxaf2UTW6Xx6DxzO+L7t3f6crUFd6yYaJmvmGlk358mauUbWzXm+vma2LHMhXHamWrmkJzNuZKfJVqXMaOLr7Sm89+txjmcWA6DXarhqUAfu7ZFFl/+9DYDmsqeh26XuedKAcOgzBfZ8rrLEmiMgtuW9quOc455/PiGEcIFPBcSKioo4duwYt912W533+/v74+9fu2+XwWDw6B/b1cePClbPX1Bu8sk/8H2Jp78urZGsmWtk3Zwna+YaWTfn+eqa+eKcRAuT4uGG+jYxvdVl5iHPPo/wqCIjvP7jMT7dfJps6471oQF6bhmVxO1jOhNPDrxzA5gr1W6Q7u71NfgWFRDb8yVM+Ltn+9GlbIOzO6qu55703HMJIUQTeDUg9tBDDzFlyhQ6derE2bNnefrpp9HpdEybNs2b02pQZJAfALkl0ntECCGEEKLNOrNFXXo6INbeGhDLkAyxlqigzMgrqw/xyTYdRssxABIiAvnjBV24aUQiIf56tWHCktugOAPa94Or33R/1mGXsRDWEQrOwOHvVNDNU7a8ry7DEyH/tGSICSF8llcDYmfOnGHatGlkZ2cTExPDBRdcwMaNG4mJifHmtBoUGaT+o5xbUuHlmQghhBBCCK8ozq56k+/p8jPZabJFMpstfL0jhX98d4CsogpAw4CEMGaP7cak/nHoddbNuSwWWPkXlVUVEAE3fwp+we6fkFYHg26GX16CHZ96LiBWkgN7v1LHlz0FX8+CnBNgNoNWNiQTQvgWrwbEli5d6s2nd0lksDVDrFgCYkIIIYQQbVKqtRysXXcIjPTsc1XfaTL7CMQN8OzziSbbm5LPU//Zy/bkPAC6RgcxIbqQubeMws/Pr+bJW9+HHZ+ARgvXfwBRXTw3scG3qIDYsbVQkAph8e5/jh2fQGUZxA1UQbfld0NlKRSlQVgH9z+fEEI0gYTpnSQlk0IIIYQQbVyWdQMoW38vT7LtNAmQcdDzzydclldSwRPL9zDljV/ZnpxHkJ+ORyf15r/3jKFPpAXNuWWQpzao3R9BZVN1v8yzE2zXDRLPA4sZdi9z//hmswrwAYy4E3QGiEhS16VsUgjhgyQg5iQpmRRCCCGEaONyVC8o2nVvnuezN9aXPmK+yGS28NmmZC55aR2fbEzGYoGrBnXgx79czF0XdcNPX8dbroKz8Pl01US/7zVw/gPNM9nBt6jLnZ+pck13OvajaqDvHw4Drle3RXVVlxIQE0L4IJ/aZbIlsJdMSkBMCCGEEKJtyrZmiDV7QEx2mvQ125Nzefo/+9iTkg9Ar9hQ5l/dj/O6tqv/QZXlsMzDTfTr0+8alZWWdQhStkNHN/bA2/Keuhxya1UftEhrCagExIQQPkgCYk6yl0xKDzEhhBBCiLbJHhDr1jzPJztN+pysonJe/P4gn289A0Cov54Hx/fkttGdMOgaKMKxWGDFXyBlq7WJ/ifgH9I8kwYICIc+U2DP57DzU/cFxHJPweHv1fHwP1bdbs8QO+Ge5xFCCDeSgJiTbCWT+aVGzGYLWm0z/TdHCCGEEEJ4X2U55J1Wx82WISY7TfqKSpOZTzae4uU1hyksqwTg+mEdeeTy3sSE+jc+wNYPYMfHgAauf78qYNScBt+iAmJ7v4SJz7vn9bRtCWCBrhdDdI+q26VkUgjhwyQg5qQIa4aY2QIFZUb7dSGEEEII0QbknAAs4BcKwTHN85yy06RP2HQ8m6e/3cfBtEIA+ieEMf+q/gzr5NhOo5rTm85poj/OU1NtWJexENYRCs7AoZXQ/9qmjVdZDts/Uscj7qx5X/UMMYul+UpDhRCelXOMqKJDwGRvz6RJpKm+k/z0WkL8VRwxR8omhRBCCCHaFntD/W7N9+bel3aazDiA3lTi3Tk0s6yich5YuoOb3tnIwbRCIoIM/H1qf/5zzwUOB8MCKnLQfTUTzEbVRP+CBz076YZodTDoZnW887Omj7f/P1CSBaEdoOekmvdFdgI0UFEIxVlNfy4hhE/Qf34rFxx5vsX3tpSAmAsig207TRq9PBMhhBBCCNGsmrt/mI0v7DR5dC2Gdy9k+Mn/894cmtmK3alMeGU9y3eeRaOBW0Yl8dNfLubWUZ3QOdo6pbKcESdeR1OcAe37Nm8T/frYdps8thYKUps2lq2Z/vCZoDunAEnvD+GJ6ljKJoUnmM2w7A+waADkp3h7Nm1DWQGa7KNosKA9/qO3Z9MkEhBzgTTWF0IIIYRoo7JtGWLN1D/Mxhd2mvzlZQDaF+yBkmzvzaMZZBeV8+dPt3HPZ9vJKa6gd1wo/7nnfJ6fOsC+67yjtD89S1TJMSwB4XDzp83bRL8+7bpB4nlgMcPuZa6Pk7obTm8CrR6GTq/7nKjO6lICYsITtr4PB/4Lecmw6jFvz6ZtsGVKA5qT6704kaaTgJgLbH3DckskICaEEEII0abYAmJRzZwh5u2dJk9vgVO/AaDBguboGu/Moxms2J3K+FfWs3JPGjqthvsu7c63cy5gYMcIl8bT7vsGANMVi7zTRL8+tiyxnZ+p/l6u2Pq+uuxzFYTG1X2O7XPOlZ0mhZtlH4M1T1Vd378cjv3ktem0GdnVAmLJv4Op5VbOSUDMBVHWnSbzpGRSCCGEEKJtyfFWhtg5O002t99fBcBiCAJAe/j75p/D6c0eLYnKLirnnk+318oKmzuhF356F982FWWgKc7AggZL10vdO+Gm6jcV9IGQdQhStjv/+LJ82P25Oj63mX51stOk8ASzGf5zDxhLoPOFMHK2un3lX6FSElc8KuuI/VBTUQxnd3hxMk0jATEX2DLEciRDTAghhBCi7SgvgkJrv6V2zZzpY9tp0mJWO002p+xjcOB/AJgmvQSA5vhPzRuYO7oW3h8Prw2BH/8GFcVuHd6WFbZiT2qNrLD+CeFNGzhtDwDF/u3BL9gNM3WjgDDoe5U63vmp84/ftVQFI2L6QKcx9Z8nATHhCZvehuQN4BcCV78Blzyudv7NPgIb206fQ6+w9dK0Of6zd+bhBhIQc0GUtW9AngTEhBBCCNFKvPnmm3Tu3JmAgABGjRrF5s2b6z3XaDTy7LPP0q1bNwICAhg0aBDff187Y8iZMVsEW3ZYUDsIdGx3Qbfx5k6Tv78OWKDn5Vj630CpIRKNsRhONGPvmF1L1aWpHNb/E14fDru/cL3Uzyq7qJx7PnNzVlh16fsAyA9MavpYnmArm9z7pXMBToulqpn+iDsa3iSgrQXEvnsE3hwF+5Y3+fUp6pF1FNbOV8cTnoPIzhAYAeOfU7f9/KI02Pcka0AsPXSAun5CAmJtSqS1ZDJHmuoLIYQQohVYtmwZc+fO5emnn2b79u0MGjSIiRMnkpGRUef5TzzxBP/61794/fXX2b9/P3fddRdTp05lx44dLo/ZInirob5NTC912Zw7TRZlqB5TAOffDxoNaeFD1PVDK5tnDsYyOPSdOr54HkQkQeFZ+PpO+OByl8t1Vu5RO0iu2O3mrLDq0vcCUOCrAbHOYyGsoyp/dObreWI9ZB1W2TkDb2r43MjO6rI0F0pyXJ5qi3D8Z5W5lHkQvpgBS2+B/DPenlXrYjbB8ruhsgy6XgzDZlbdN+hmtVmEsRhWP+61KbZqFos9IHYy2loGfnozGEu9OCnXSUDMBVVN9aWHmBBCCCFavoULFzJr1ixmzpxJ3759efvttwkKCuKDDz6o8/yPP/6Yxx57jMmTJ9O1a1fuvvtuJk+ezMsvv+zymC2Ctxrq29j6iDXnTpOb31FZWR1HQNJoAFLDh6r7Dn2n+vh42rEfoaIQwhJg7MNwz2a49AkwBMHpjfDOJfCfOSp45wBbVtifP91OtieywqpLUwExn80Q02ph8DR1bAt8OsKWHTbwJlV62RC/YAixNtxvzY31zaaqXQ7jB4HWoIKMb46CTe+o+0XTbXgTzmwGv1C46o2a2YkaDVzxEmi0sO8bOL7Oa9NstYrSoaIIi0ZLetggLKHx6ndE8kZvz8wlEhBzgZRMCiGEEKK1qKioYNu2bYwbN85+m1arZdy4cWzYsKHOx5SXlxMQEFDjtsDAQH799VeXx2wR7A31vRQQa+6dJsuLYPO76njMffY3ntkhfbD4hUBRGqQ2QzPl/cvVZd+rVQDHEAhj/wpztsKAGwAL7PgYXh+myjsbaKh9blbYvZ7ICrOpLFcN64GCwET3j+8ug6wBsWNroSC18fMLzsLBFeq4oWb61dnLJltxQGzHJyojMCAc/vAN3PULdBwJFUXw3V/h/Qn2ElrhosxDqocgwOXPQ0Qd31dxA2DELHUsDfbdz9ZQP6ITFq0eS+ex6npzltC7kd7bE2iJIuwlk5IhJoQQQoiWLSsrC5PJRGxsbI3bY2NjOXiw7l5VEydOZOHChYwdO5Zu3bqxdu1avv76a0wmk8tjlpeXU15ebr9eUFAAqH5lRqP7/+ayjenM2LqsI2iByojOWDwwp0ZFdMMAWHJPUFlaCPqARh/SFNqtS9CV5WGJ6kpltwlg/VqYtQZMXS5Bf+i/mPb/D3P7gZ6bRGUZ+oMr0ACVva6sue5B7eGqt9AMuR3t6sfQpu2C1U9g2boY0/i/Yek+3n5qTnEF8/93gJV70wHoFRvCC9f2p1+HMLCYMBo9kL2Tvh+DuRKLfzilhnYeeR27RVgSusTz0J7eiGnHZ5jH3Nfg6dotH6CzmDAnjcYU1QMc+Lx0EZ3RJv+OKesoZgfXwZXvUa8pL0T/43NoANMFD2H2CwO/MJj+P7Tbl6D98Vk0KVux/Gss5vPuxXzhXzzy/dui1sxZ5kp0X/8Jrakcc9fLMPW/uf7X3oUPo9/3NZqsw5h+fwPz6HsbHLpVr5ubaTIOoQfMkV0AMCaOwX/PMszH12EyPubdyVXj6NdSAmIuqJ4hZrFY0DTURFIIIYQQopV59dVXmTVrFr1790aj0dCtWzdmzpzZpHLIBQsWMH/+/Fq3r169mqCgoKZMt0Fr1qxx+NzL0w7iD/yyL5WCE83UP6s6i4VJumD8TMX8unwJBUGeK8PTWCoZt28hQcCu4Is49f2qGvfvKuvAMKBo2xesKxnssXnE5W9nVEURpYZIVu/KgN31rHvcgyT5/UKfs18QkHMM/bJppIUNYl/CLeQY4lm4R0dqqQYtFsYlWJjYMY9TO3/l1E6PTZ3E7F8ZCmQb4kCjceq11tySNP0YwkZKfn+XH3O71dskX2OpZMLed9EB27RDOLvSse+DHpkV9AVS9vzCjoI+Ts3Nl9fNps/Zz+lZnEmRfyw/ZiZgqbEucQT0+BsDz3xMfP42dL+/Qum2z9iVOJOs0L4emU9LWDNn9Uj7L31Td2DUBfFj4BTKvvuuwfMT213D0OJ3saz7Bz+mR1LmF9Xoc7TGdXO3fik/0B04WWiAcFh3ysJEQHN2B6v/+yWVOs/9vnZGSUmJQ+dJQMwFkdYeYpVmC4XllYQFGLw8IyGEEEII10RHR6PT6UhPT69xe3p6OnFxcXU+JiYmhuXLl1NWVkZ2djYdOnTg0UcfpWvXri6POW/ePObOnWu/XlBQQGJiIhMmTCAsrJEeRS4wGo2sWbOG8ePHYzA48LdcaS6GHUUAXHDVbaovkhfosgfA6Y1c2DsaS//JHnsezd4v0e/MxhIcQ79bnqOfNZvFtm59rrofyxvvEV52mslj+kFEJ4/MQ/ef/wLgN/hGJk+4spGzr4SyxzH99jLaze8QV7CL2KJ9/BJ1HUWl44kOieDdPwylf4L7X0910f6wAZIhvOcFYMHx15o3lF+IZdFnhJancsXgOCwJw+o8TXPgW/Q787AEt2fwzU8wWOfn0PCa/RXwzZd0DDISP9mx163T36PekncK/durAQi46iUm9ZxUz4l/oPLgCnSrHiGkKI3zj/4D88BbMI2b77Zda1vMmjkrYz/695cDoJn8Ty5tbCMHAMvlmD/ajf7MJsZb1mGa/F69p7badfMA3bJPIAMSB1/C3iy48IqbsKS+jibnGBN7BWOp9/XfvGxZ5o2RgJgLAgw6Agxayoxm8oqNEhATQgghRIvl5+fHsGHDWLt2Lddccw0AZrOZtWvXMmfOnAYfGxAQQEJCAkajka+++oobb7zR5TH9/f3x9/evdbvBYPDoGxSHx09PVpehHTAER3hsPo1q3xtOb0SfcwQ8tS4WC2x8EwDNqD9hCAytdYohrD2aTmPg5C8Yjq2B8+52/zwqy+GIykzTDbgOnSOfr6Gd6i00/I+w6jE0R1YxNmsZP/l/R86IJ+nZeXzjY7hLxn4ANHH9IdXzr+UmMURB36tg9zL0e5dB5/PqPm/7YgA0w2ZgCHAiKBzTAwBt7gm0Tq6BT68bwE/PgakCulyEvu+UerPrABhwDfS4BH6YD1vfR7v7M7TH1sDl/4D+1zX8WCf4/Jo5w2SE/90LZiP0nIR+6K2Or9OVL8O/xqLdvxzt8JlqV8oGtKp185Tc4wBoY3pCVhEGgwFN14sg5xj65N+g31VenqDi6NdRmuq7KMq+06Q06RNCCCFEyzZ37lzeffddPvzwQw4cOMDdd99NcXExM2eq7eynT5/OvHnz7Odv2rSJr7/+muPHj/PLL79w+eWXYzabefjhhx0es8WxbjPvtYb6NradJj3ZnPvYj5C+BwzBMPyO+s/rZc0EOOSh8tFjP0J5AYR2ULtcOiO6O6cnLeFu5nHMHE+0poCeG/4KZ7Z6Zq7nslhUg3WA2H7N85xNNfgWdbnnKzCW1b4/4yCc/EXt4DfsdufGjlL9hijOgPLCJk3Tp5z6XW36oNHCxOcdC9QEhMOVC+GPqyCmNxRnwld3wKc3QO4pj0+5xfn1FUjdBQERMGWRc0HDGg32H5YG+01lMkLuSQAs7bpX3d7lInXZAhvrS0DMRRHWgFiOBMSEEEII0cLddNNNvPTSSzz11FMMHjyYnTt38v3339ub4icnJ5OaWrX7XFlZGU888QR9+/Zl6tSpJCQk8OuvvxIREeHwmC1Otpd3mLSxBYYOr4IjP3jmOX5/TV0OnQ5BDfTdsQXETv4Gpbnun8e+5erStrukE4wmM/ct3cF3ZQOYF/s25q6Xqjua6w1bUTqUZINGiyXGuZ5ZXtN5LIR1hPJ8OLSi9v1b31eXvSZDeEfnxg4Ih6B26tj6hrrFM5vhe+s/CoZOh7j+zj0+6Tz403q45HHQ+cHRNfB/58GGN8FU6f75tkSpu+HnF9Tx5JcgtO6S+wZd8hgEx6gdXze95d75tTW5p8BcCYagml+LLtadJjP2Q1GGd+bmIgmIuah6Y30hhBBCiJZuzpw5nDp1ivLycjZt2sSoUaPs961bt44lS5bYr1900UXs37+fsrIysrKy+Oijj+jQoYNTY7Y49gyx7g2f52kdh6lyQCzw9SzIO+3e8c/uhOPrQKOD0X9u+NyoripjzWJyf3Cusrwq86zfNU4/fOGaw+xIziMsQM/L00ai7W4NiKVsc98cG5JmzQ5r1x0Mgc3znE2l1cLgaep452c17ysvgp3/Vscj7nRt/CjVY5Cc46493tfsXgqpO8EvFC55wrUx9P5w0cNw12+QNAaMJbDqMfjsBqhwrCl4q1VZAcv/rAIwva+EAde7Nk5gBIx/Vh2vewHyU9w2xTaneqa0plooKShKZeNBi8sSk4CYiyKCVE1qTrFszSqEEEII0erZ3ghEeTlDDGDiAogfDKU58MXt7i0DsmWH9b8OIhzYxbK3tUF6XRlFTXHsp2rlkiOdeugvRzJ5a53K6HvhuoEkRgWBrUl8cwXE0veoy5ZSLmkzyBoQO/YjFJytun3P51BRqAJ8tvIoZ7WmgFh5Eay1BlnGPgQhMU0bL6Yn3L4CprymSpWP/QifXt+6ykudtf6f6vsoMAqufKVp/dUG3gyJo8BYDKtdDF6Khv8xZC+b/Ln55uMGEhBzkW2nSckQE0IIIYRo5SyWqjfx3s4QAzAEwI0fqjK0lK3ue4OXe7KqTPH8+xx7TC9rQOzID+4NzO23zqPvVU6VS2YWlvPgsl0A3DoqiUkD4tUd8YNURkNhas1Aj6fYerzFOllG523tukHSaLCYYfcydZvFAlus5ZLD73C6fNWuNQXEfntVvZYiO7tvQwmtFobNgNu+Af8wOPUbfHQNlOa5Z/yW5OwO+OVldXzlQghp37TxtFpVcqnRwr6v4XjLCtr4jOwj6rKhgFgLW1sJiLkoMlia6gshhBBCtAlF6VBRpN5MRXb29myUyM4w9V/qePO/YO9XTR9zw/+p8sdul1aVvzSmw1AIiVXZQyd/afocQJVLHrSWS/a9xuGHmc0W5n6+k6yicnrFhvLklX2r7vQLhvbW682RJWYrmXR0HX2Jrbn+zs9UMOz0JrVBgD6wqqTSFfaA2Immz9Gb8k5XZVKOf1aVPbpT0iiY8S0ERqqA94dToDjbvc/hyyrL4Zu71c+iflPVhzvED6wq913519bRYN9YBiU5zfd89l6aPWrf12k0aPWQd6pF9QmUgJiLIq0lk7lSMimEEEII0brZ3gREJIHez7tzqa7XJLjgQXX87X2Qedj1sUpyYMfH6niMg9lhoDIvel6ujg995/rzV3d8nWrsHhqvypwc9M4vx/nlSBYBBi2v3zKEAIOu5gkJQ9WlpwNixjLIsn4tWlqGGKggpD5QfQ4p22Dzu+r2AderII2rIq07TTZHhpjFonbE84S186GyDDqdD32u8sxzdBgCM/6nmsGn7YYlV0Bhmmeey9es+wdkHlCf++SX3Tv2JY9DULS1wf7b7h27uZUVwDsXwSv9m++1kdVAhph/aFVpegvqIyYBMRfZSiYlQ0wIIYQQopXzpf5h57rkCeh8ocpg+3w6VBS7Ns6W91RD77iB0PVi5x5rK5s89J0KRDSVrWyzj+PlkjuSc3lp1SEAnpnSj56xobVPaq4+YpkHVXZLQASE1d5swucFhKlSVYBfX4H9/1HHrjbTt7FliBWkgLG0aWM1Zvnd8GI32PeNe8c9vQX2fAFoYOLzTetr1Zi4/nD7ShUYzjwAiydD/hnPPZ8vOLMNflukjq98BYLbuXf8Gg32/9E85dOeYLHAt3PUzxpjMSRv9PxzlhdCkTXwVt9uyy2wbFICYi6ylUzmFEtATAghhBCiVcuxlYn4QP+wc+n0cN37qmwx8wD870Hng1LG0qpsifPvd/5NfteLwBAEBWdUNktTVFZUNeh3cHfJ/FIj9/57B5VmC1cMjOemEYl1n2gPiO0As7lp82yIrX9Y3ADPBkw8yVY2efB/YDZCwnDoMLhpYwZFgX+4Os491bSxGmKqVIGw8ny16cQPz4DZ1PRxLRb4/lF1PPjWpq+HI2J6wszvVHZqzjH4YFLLLzmtj7EMlt+l+tcNuAH6TPHM8wya1vIb7G96uypQDZC2x/PPacuUDo5RgcW6dLU11l/vnn+ONAMJiLnIVjKZVyIlk0IIIYQQrVq2DwfEAEJj4frFoNGpRujbljj3+J2fQkm2etPtRM8uO0Og6jsGTS+bPL4OyvIhJA4Sz2v0dIvFwmPf7OFMbikdIwNZcO0ANPUFoWL6qFLAisKq5tCekG7tH9YSyyVtOo+F8GqBxZGzmj6mRgNRzVA2mXlQlTRqrCWzv76idmxsaq+lPV+qnl6GYLjsyabP01FRXVRQLKor5CfD4klNK4/2VT/9XZXphsTCpBc99zzVG+zv/apFlfcBcHpzVSCvwxB1afuZ40kN7TBp03GE+hlbnKG+D1sACYi5qHrJpKWFRD+FEEIIIYQL7AGxrt6dR0M6nw+XPaWOv3tY7dLmCLMJfn9DHY+eozLOXGErmzy4wrXH2zi5u+SyLadZsTsVvVbD69OGEBZgqP9knb4qq8eTZZO2bI24FhwQ02pVJg1AYJRrgdK6NMdOk7bXfqcxKntSHwjHfoR3Lq7a7MBZFSUq0wzgwgchNM4dM3VceEcVFIvprXa3XDLZ9c+lLtnH4LtHYGHfqp8HzSllO/z+ujqe8qrKJvSk6g32VzzkuX5z7lacpbIezZXQ71pVtgvNlCFmC4g10DpA7w9J1n9ktJBAowTEXGQrmSyvNFNqdEMKrhBCCCGE8D1mc9Wbd1/NELMZc58KTJkq4PMZUJrb+GMO/BdyT6hm6UP+4Ppz95yoMi7Sdrve56iyQpXogUMBmMPphTzzX1We+NDEXgxJcqDhu6f7iFks1TLE+nnmOZrLqD+p19Pkf4IhwD1jNmdArMMQtRHAnWsgopPa/e798SrTy1kb3lAlweGJKnDsDaFxqqdY3AAozoQPr1SBJFdZLCoj87Ob4fVhqgyvIAXWLVBZms3pt1cBC/S/Tm0W0hyqNdjXbvlX8zxnU5hN8NWd6mvUrgdc9VpVFmpBiud3IrUHxOrYYbK6LmPVZQvpIyYBMRcF++kw6FQ6dq6UTQohhBBCtE4FZ8BUDjq/miVkvkirhWv+r+rN/zd3N9wry2KxvhEFRswCv2DXnzs4umpHSFfLJk/8bC2XjK3KMqhHmdHEnM+2U2Y0c2GPaGZf6GD2nqcDYoWpKhCp0akSzZYsOBqm/VsFldylOUomqwfEQAWQZq+DrpeojSO+ugNWP6l6jTmiIFWVXQKMe0aVCHtLcDuY8V/V0600Fz66GpI3OTeGsRS2fQhvjVGPP/wdYIEeE9ROoBVFsONTj0y/TvlnVGAe4IK5zfe8gREwfj4A2l/+SUBFE0tqPe3nF+H4T6pf400fq10dA8IgsrO6P93DWWIN7TBZna2P2MlfHf8e8yIJiLlIo9FUlU1KY30hhBBCiNbJ9l/xyC6g1Xl3Lo4IjIQbPwKdv3qj+/tr9Z978lc4ux30ATBydtOf25bZcWila4+37QjY56pG1/q5/+3ncHoR0SH+LLxxMFqtg83rbQGxtL2qibe72crYonu4L6uqNfF0hlhlRVWGni0gBqoE7w9fwfkPqOu/vwafXudYX7G1z6pAWseRKoPJ2wIjYfpy6HQ+lBfAx1Mdy8YpOAs/zFdlkf+9DzL2q35oI2fDnG1w6xdw/n3q3M3/cs9GBI7Y/K7albXzhc1fZjzoFug4Ek1FMb3S3LwjqTsd/QF+fkEdX/kKtK8WbI8boC7dWUJ7LoulqnVAdCMZYvGD1eYZ5fmQtstzc3ITCYg1QfU+YkIIIYQQohWy9w9roG+Kr+kwGCZZ3zytfVYFvupiC5YNvhVCYpr+vL2uUJcnfnG+5Kp6uWQju0uu3JPKp5uSAXjlpkHEhPo7/jwRSapMymz0TN8dW5ZGS26o70m2gFj+afU1d7eMfapkOCCiKnPGRqtTGUHXL1ZZNsfXwTsXQWoDO6Oe3QG7PlPHl//Dd3YN9Q+FW7+0Zr0Vw2c3wpE1dZ97egt8+UdYNAB+XQilOer7YMLfYe5+VRIbbc36GXizWrvck3B4lec/j4qSqk1Azrvb8893Lq3W3nuxQ95W3+wlln8GvpoFWGDYTBh0c8374waqS0/2EStKV5uRaLS1v6/OpdVB5wvUcQsom5SAWBNEBqumnVIyKYQQQgjRSrXEgBjAsNvVm1uLSb0ZLkyveX/6PjiyGtDA6Hvc85zR3VV/GbMRjq517rG2csng9pA0ut7TTueU8MhXKoBx98XduLCHk4E8jcazZZNpraR/mKeExKpglMWsgmLuVr1csr7gVf9r4c4fVNZnXjK8PwF2f1H7PIsFvp+njgfeBB2HuX++TeEXBNOWQs9JalfNf09DY9vUwmRUvdLevQzeH6d2UzRXQqcL4KZP4L6dMGaOKhs8d8xhM9Txxv/z/OeweymU5aky756Xe/756tJpDJagaPxMxWhOb/TOHOpTWaGa6JfmQPwgFZQ9ly347smAmC1TOiJJNc5vjK1ssgU01peAWBNIyaQQQgghRCtneyMQ1cICYhoNXLlQ9bEqSld9k6r3c7Ht6Nb3KvcG++xlk072Edu3vGo+9ZRLGk1m7l+6g8KySoYkRTB3fE/X5ujJgFi6avJvL2MSNWk0ni2bPLd/WH1i+8Hsn6D7OKgsha/vhFWP1/we2f8fSN6gdqm87Gn3z9UdDAGqRLrvNWA2ovv6jww8vQT9m0PV93zKVtX/cPCt8KdfYOYK6DOl4ZLkEbNUD7yTv3i+DG+TtZn9qD95ryRdq8PSYyIAmsMu9j/0lDVPwZktEBCuvs51lWHbftZkHYLKcs/Mw9GG+ja2xvrJGz03JzeRgFgTREjJpBBCCCFE65ZjyxDz8R0m6+IXrJov+4WoN7c//V3dnp8Ce6wZMeff797n7G0tmzyyyvHyI5Oxwd0lzWYL+aVGXlp1iO3JeYQG6Hnt5iEYdC6+lfFUQMxYCtnWxtNSMlk/W8mVNwNioHpx3fI5XPgXdX3DG/DJVLVbn7EM1jypbj//fghPcP9c3UXvB9e9DwNvRmMx0SXrRzSFqSob7+LH4MF9arON+IGOjReRqIJmoHae9JTjP0HmQfXzqSk73LqBuacK5GsPrVSBOl+w7xvY9JY6nvqv+ksVwzuqMldzpVpPT3C0ob5NTG/1+qsshdObPTMnN9F7ewItWZStZFIyxIQQQgghWh+TEXJPqeOWGBAD1QD5qtfhy5mqf1DiKBUcs5VPJbi5DKzjCNWjqyRLZdfYMgVQO0PuScknv8RIYbmRwrJKCssqiU5bz01leRToIrn/Jz0F3/9OYVnV/UXlNXcq+8e1A0mMCnJ9jglD1WXOMdVUPSjK9bGqyzigSgGD2kFonHvGbI08lSFmLFVfA3AsIAYqK+myp1Q52jd3qxKvdy6GbhercsrQDlWN5n2ZTg/XvIUpuD05e9YQeem96Ade71h5W13Ouxv2L1eB83Hz1e6W7rbRGmwbfKvKgPIiS5eLqNT6oS84A2m71evBm7KOwH/mqOMLHqzKvK2LRqOyxE7+osomPTF3Z1sHaDTqZ/+eL9T3VJcL3T8nN5GAWBNUNdWXHmJCCCGEEK1O7inVg8sQ3LIDHP2vhdObVLbHN7Ordo9zd3YYqABDz8th5ydwcGWNgNjsj7ex/nBmrYe8oP8P6OE/5cP46XD9u/4FGLT8aWw3rhgY37Q5BkWp/lG5J1RGUffLmjaejW13w9j+vtN83Rd5KiCWvk8FeoNjVNaMM/peDdE9Yektal7bP1K3j3taZVq2BFot5kuf4vey4UweMBn0BtfHShyldgtM3QnbFsPYh9w1SyX7mMoiRaPKJb3NEEhG6AA65G+Dgyu8GxCrKIHPp0NFkfqnxSVPNP4Ye0DMQyWutpLJxnaYrM4eEPsZeNwj03IHCYg1gewyKYQQQgjRitn7pnRt+QGO8c/Bma2qpxBA+77QY7xnnqvXJBUQO7QSLl8AGg0nsopZfzgTjQYGJoQTGmAgNEBPuD9MObgdTNBu5E282GEgYQF6+/1Vl3r89W7sMdRxuAqIpWx3Y0DM2j9MyiUbZg+InXDvuI401G9I+z4w6yf4epbacCJhOAy40b1zbCk0GpUl9s2fYMt7Kniua0KA7Vy23mE9JvjMhiVp4cOsAbGVcMlj3pmExQIr5kLGflVyeP0HKvuvMbY+Yp5orG8yqp+V4FymdBdrY/2UbVBeqHZG9UESEGuCql0mJSAmhBBCCNHq2PqHtbSG+nXR+8ENS+BfY9WOZWPu81yQr9sloA+AvFPqjV1sP77cpnYUHNsjhg//OLLq3KM/wL4CCI5h8pXXNV9j7YRhKnvBnX3EbNkZcRIQa5AtIJZ7UmUruutr7kz/sPoERsC0ZXDqV5UhpW3DLbf7TYXVT0JhqtpgYMD17hm3LB92fqqOz7vLPWO6QVr4ICwaHZr0Peq1WV/PLk/a/iHs+jdotCoYFhrr2OOqB8QsFvf+bM9LVpmXhiBVQuyoyE5q99C8U3BqA/Sc4L45uVEb/g5vOntT/WIpmRRCCCGEaHXsGWIttH/YuSISYeZ3cPX/waCbPfc8fsHQ9WJ1fGglJrOFr7alAHDj8MSa59p2l2xs5zt3q95Y3x1NtC0WSLdmZ0iGWMPCEkDnD2Yj5J9x37juCIiBCoJ1GQsBYU2fU0um94cRd6jjjW+5b9wdn6hywJje0PUS943bREZ9KJak0erKwZXNP4GzO2Hlw+r4sqeg8wWOPza6F2gNUJ4P+afdO6/qOy07GyDuas0SO/Gze+fkRhIQa4IoKZkUQgghhGi97AGxVpAhZtO+Nwy51fMloL0mq8tD3/Hr0SzSCsqICDIwrm/7qnMa2V3So+IGgFYPxRnueQOZf0Zlvmj1ENOr6eO1Zlqtyh4B9/URqyiu2mEvfrB7xhQw/I+g81Ol1me2Nn08s6mqXHLUXT5Xim6x7jbJwRXN+8SluapvmKkcek6CMU72d9T7qQAjuL9s0r7DpAu/B7tIQKxVs/UQK6kwUV5p8vJshBBCCCGEW2Vb36y3lgyx5tTzcnWZso1VG1XmztWDOtTsA3ZivXojGBwDnc5v3vkZAiG2n32OTWbrHxbd0/Wd/doSdzfWT92tdvgMjYewJm66IKqEtIf+1lJJd2SJHf5eldAFRsLAm5o+npuZbQGx5N/VDrTNwWKB5X9W6xKRBFPfcq1U11N9xFxpqG9j21QlbQ8UZ7tvTm4kAbEmCA3Qo9OqqHae7DQphBBCCNF6VJRAgbWcqzX0EGtuobGqKTmgO7wKgBvOLZfcv1xd9pniWONod6teNtlUUi7pHHcHxNxVLilqs/X52r8cCs42bSxbUG3oDPALatpYnhCRpAJLFrMK3jWH319TG5Do/ODGj1Sw0BW23oWeCoi58o+hkPZqAxeAk+vdNyc3koBYE2i1GiICVWP9nGIpmxRCCCGEaDVsu2oFREBQlFen0mL1VmWTl2i20ic+jP4J4VX3mYxwwEvlkjb2gNj2po8lDfWdU72xvjtIQMxz4gdB0hjVWH3L+66Pk7YXTv4CGh2MnOW++blb7yvVZXOUTaZshx/mq+NJLzTt9evpDDFXM6VtWWInJCDWKkUEyU6TQgghhBCtTvU3AT7W56bFsPYRO1+7j1sGnxNUPPmL2u0yKLr5yyVtbAGxszvAVNm0sWwlk5Ih5pioLupSMsRaBluW2NYPwFjq2hibrNlhfaZAeEf3zMsTbP0Pj65VmcKe9NurYDGpfwoMm9m0sWw/e/JOQWleU2emlBepXUbB9V6atj5ix32zj5jPBMT+8Y9/oNFoeOCBB7w9FadEBctOk0IIIYQQrU72MXXZmhrqN7MDlR04aY7FX2PkmrBDNe+svrukN8olQfX78gsBYwlkHWr8/PpUlECO9fUiATHH2EsmT4DZ3LSxygog29r4Wxrqe0avKyA8UQWx93zh/OOLs2C39XHn/dm9c3O3uAEQngSVpXB8neeeJz8FDvxXHY/9a9P/8RIUBWHWQKMtQN9Utn8MBUW7XsrZaQxotOpnpDt3lXUTnwiIbdmyhX/9618MHDjQ21NxWoTsNCmEEEII0frYA2LSUN9VX2xL4QfzUABCT66pusNUWfVGsN81zT8xG62uKqOoKX3EMg6onkPBMap3mmhceKIqnasshaK0po2VuqtqzJCYps9N1KbTw8jZ6njj26oRvDO2LVY7KHYYAokj3T8/d9JooPcV6tiTZZPbFqvssE7nu6/U2lY2mb7XPeM1paG+TWBE1c9ZHyyb9HpArKioiFtvvZV3332XyEgXo45eFGUNiOVJQEwIIYQQovWwZfzYMlmEUyoqzSzfmcIak2qsz+HvwWzdlf3kemu5ZDvodIH3JgnuaawvDfWdpzOoBubQ9LJJKZdsHkNvA0MQZOxTJc+OMhmreo+NurtllKDbAmKHVja9nLouleWwbYk6tgUa3cHeR2y3e8ZzV6a0D5dNeik/uco999zDFVdcwbhx4/jb3/7W4Lnl5eWUl5fbrxcUFABgNBoxGt1fsmgbs6GxwwLU1tFZhWUemUNL5Mi6iZpkzVwj6+Y8WTPXyLo5z9fXzFfnJXxIUxsJt3E/Hkwnp7iC5JABWPQRaEpz4PQmVT7jC+WSNm4JiFnLk6ShvnOiuqrNK3KOQ+cmBEYlINY8AiNh0DTY+r7KErM1S2/M/v+oPlQhsdBvqmfn6C5Jo9Xna/u51dnNfQ73fQPFmRCWUNXE3x3cvdOkrRS5qb8Hu4yFXxeqDDGLxaeCol79DbR06VK2b9/Oli1bHDp/wYIFzJ8/v9btq1evJijIc9u2rlmzpt770lM0gI59R06ycqWbmkK2Eg2tm6ibrJlrZN2cJ2vmGlk35/nqmpWUeLhRrmjZyvLVmxWQHmIu+nyr6hVz9bBOaEonwu5lKtui40g46OXdJauzBcTS96teYH4uvKew7TApGWLOieoKx9aqPmJNIQGx5jPqLhUQO7RSfd1smyM0ZKO1mf7wO0Dv59n5uYtODz0vh13/VmWT7g6IbX5HXQ6f6d5/CtgyxDIOqsw8naFp49n/MdSEkkmApPNA5weFZ9WYTSnBdDOvBcROnz7N/fffz5o1awgICHDoMfPmzWPu3Ln26wUFBSQmJjJhwgTCwsLcPkej0ciaNWsYP348BkPdL6bibSl8m7yPoMj2TJ481O1zaIkcWTdRk6yZa2TdnCdr5hpZN+f5+prZssyFqJOtTCQkFvxDvTuXFiijoIx1hzIAuGF4R8iYrAJiB1dCt8ugJFuVS3a+0MszBcI6QEic6mOVtlu9cXOGxSI7TLrK3li/CUkFpbkqywygw+AmT0k0Iqan+h4+thY2vwuXP9/w+ae3QMpWFQwZ/sfmmaO79L5CBcQOrYCJf3dfVtOZbSojVecHQ293z5g2EZ3BLxQqCiHrCMT2dX0siwWy3JQpbQiExFGq1PbEzxIQA9i2bRsZGRkMHVoVRDKZTKxfv5433niD8vJydDpdjcf4+/vj7+9fayyDweDRP7YbGj86VAXz8soqffIPfm/y9NelNZI1c42sm/NkzVwj6+Y8X10zX5yT8CG2gFiUZIe54usdKZgtMKxTJN1iQiDsMvXmL+cYrH9JndT7Su+XS4J6k5swTL3pPbPV+YBYXjKU54PWoHatFI5zR0DMlh0W2cX1XfCEc867WwXEdnwMl8xr+J8Gm6zZYQNuaHkbHnS7FPQBkHsSMvZDbD/3jGvLDut3rfvXRKtVZZPJG1TZZFMCYkUZKrCm0TqWCdiYLhepgNjxn2HEnU0fz0281lT/sssuY8+ePezcudP+MXz4cG699VZ27txZKxjmq6KCpam+EEIIIUSrkuOmRsJtkMVi4fOtpwG4YVhHdaN/aFW/oVO/qktv7i55rgTrP+hd6SNmyw6L6d1yysF8he1Nds4J53cttJFyyebX7TKVMVReADs/q/+8grOqfxioUsuWxi8Yul6ijt2122RRJuz7Wh2PcmMz/epsmapNbaxvK5eMSAJ97aQkp3W1NtY/+QuYzU0fz028FhALDQ2lf//+NT6Cg4Np164d/fu3nHTjCOsukznFEhATQgghhGgVpKG+y7Yn53E8s5hAg44rBsZX3dFrUtVxYBR0drAhd3NoSmP9dFv/MDdlj7QlEZ0AjcpCKc5ybQwJiDU/rbYqwLXpX/UHN7a8B+ZK6HQ+xA9svvm5k223SVvfw6batgRMFZAwvOrnjrvZ+ojZfja5yl0N9W06DAG/EFXmnO6mpv9u4LWAWGsRGaRKLgrLKjGafCfSKYQQQgjhjDfffJPOnTsTEBDAqFGj2Lx5c4PnL1q0iF69ehEYGEhiYiIPPvggZWVl9vufeeYZNBpNjY/evXt7+tNwD3dtNd8GfblNZYdNGhBHaEC10uSe1QJifXykXNLGFkzJO+V8YMa2m5vsMOk8QwCEW7MIXS2bPLtTXUpArHkNmgb+4Sqb9mgdm+cYS2HrYnXcErPDbHpNUiWDqbsg/0zTxjIZYesH6nikh7LDoCoglrbH9cxLcP8/hnQGFRwFVTbpI3wqILZu3ToWLVrk7Wk4JTzQYO+vl1ciW7gLIYQQouVZtmwZc+fO5emnn2b79u0MGjSIiRMnkpGRUef5n332GY8++ihPP/00Bw4c4P3332fZsmU89thjNc7r168fqamp9o9ff/21OT6dprFYqgXEJEPMGSUVlfx3VyoANw5PrHlneELVm6GBNzfzzBoRGFG1i1rKducemy47TDaJrWwy14WdJosyIV8FYIkf5L45icb5h8DQ29SxbRfJ6vZ8AaU5qtzOlmXVEgVHQ6K1r+DBlU0b6+D/1C6LwTGeLRlv30cF8UqyoTDV9XE88XvQVjp/QgJirYZepyXM+t8v6SMmhBBCiJZo4cKFzJo1i5kzZ9K3b1/efvttgoKC+OCDD+o8//fff+f888/nlltuoXPnzkyYMIFp06bVyirT6/XExcXZP6Kjo5vj02makmzVJB2NatQtHPb93jSKyitJigpiVJeo2ifc+BHM+hE6n9/8k2uMK2WT5UWq/xVUZWUI5zSlsX7qTnXZrgcEhLltSsJBI2erwMvxnyDjQNXtFgtsfLvqHG3L6A1eL3eVTW5+V10Ou909PbnqYwis2uAjrQllk1luLpmEqj5ipzZApW/ETnwoV7nligr2I7/USK5kiAkhhBCihamoqGDbtm3MmzfPfptWq2XcuHFs2LChzseMGTOGTz75hM2bNzNy5EiOHz/OypUrue2222qcd+TIETp06EBAQACjR49mwYIFJCUl1TlmeXk55eXl9usFBQUAGI1GjEb3/41lG/PcsTXpB9EDlvCOVKIDDzx3S1bfugEs25IMwNTB8VRWVtZ+sF84tB/ok2uqjR+CbvdSzGe2YnJwfprUPeixYAluT6VfeL2fV0Nr1tZpwzuhA8xZR2ute2Prpj29VT02frDDX7PWrllfayEd0PWchPbQCkwb/g/z5IUAaE6uR5+xD4shmMoB03zy+/1cDa5b9wkYVj+O5eSvVBZkqoxSZ6Xvw3DqNyxaPZWDpnt8TXTt+6HNPIjp7E7MXS5xfgBzJfrcE2gAY0SXOufr0mstqif6oHZoSrKpTN6EJdHJXX2d4Oi8JCDmBhHWPmLSWF8IIYQQLU1WVhYmk4nY2Ngat8fGxnLw4ME6H3PLLbeQlZXFBRdcgMViobKykrvuuqtGyeSoUaNYsmQJvXr1IjU1lfnz53PhhReyd+9eQkNDa425YMEC5s+fX+v21atXExQU1MTPsn5r1tTsf5OY/QtDgUxzGBtWNrFEphU7d92yymDTCT0aLETkHWLlykNemplrIopLuQgwntzI9ytWYO+J0oBOWT8yGMjQxrLRgdfKuWsmID4vh5FA/okdrK9nDetbt5HHVxEP7Mv147h8r9bQXK+1dqZBXMAKLDuXsqbyPIz6EEYef4V44GT4eez+8bdmmYe71LdulwR0JKzsDLu/eokzUWOcHndQ8vt0Bs6GDWXrrzuAHU2aZ2O65+rpB6TtXMPW/F5OPz64PJ1x5koqNX6s/GUHaHbVe66zr7Xhft1IKMnmyOoPOByf4/TcHFVSUuLQeRIQc4NI606TUjIphBBCiLZg3bp1PP/88/zf//0fo0aN4ujRo9x///0899xzPPnkkwBMmlTVRH3gwIGMGjWKTp068fnnn3PHHXfUGnPevHnMnTvXfr2goIDExEQmTJhAWJj7y6GMRiNr1qxh/PjxGAxVzd+1P22HZGjXcxSTL5/s9udt6epbt1fXHgWOM6ZbNH+Y6qHd0zypshzLS8/jbypi8ph+ENm50Ydov/sJTkN0/4uZfGn9r5X61kwA6Z3gvdeJsOQyeXLNNWxs3fSvPgxAn8tuoXfiqGaZrq9r9teaZRKW9/+LPn0PE6PTMPeZgn7HTgA6Xv83Otp68/m4xtZNG7QLfnuZIYFnGTjZyd8LpbnoX/sTALFTnmRy0mh3TLlBmuOB8O9ldNBm1/q+cujxR1bDftDF9GDyFVfWeY6rrzXt9gz4bjO9/FLp7sLcHGXLMm+MBMTcwBYQy5GAmBBCCCFamOjoaHQ6Henp6TVuT09PJy4urs7HPPnkk9x2223ceeedAAwYMIDi4mJmz57N448/jlZbu01tREQEPXv25OjRo3WO6e/vj79/7b4qBoPBo2/sao2fq3oZ6aJ7oJPgRb2qr5vZbOGbndZm+iMSW2bQx2BQfcBStmFI3wXtHXgjn6n6JuniBzn0WvH0a7lFsq6zpjQXg7EQgmr3nqtz3QpSoSgNNFr0HYeor5+wa9bX2nl3w3/+jG7bB+iK0wALdB+PIa5v8zy/G9W7bv2mwG8voz22Fi0mtUOqozYvhcpSiB2AvuuFDmWfNlnCYAA0OccxmMvVJgjOyD+pHh/do9HXkdOvte6XAqA9sxWtpQL8gp2bm4McnZM01XeDyCBbU33fr48WQgghhKjOz8+PYcOGsXbtWvttZrOZtWvXMnp03f/JLikpqRX00ulU42RLPdu8FxUVcezYMeLj4900cw+xNfeWHSYd9vuxbFLySgkL0DOxX91B1BbBmcb6ZjOk71PHsf08N6fWzi8YQqyvGWd2mjxrLTmL6e2xN9TCQf2vg6BoKDgDm99Rt513l3fn5G7xgyEsAYzFzu2QaDbBlvfU8chZzRMMAwhpb/2+skDGfucf74mG+jZRXSGsI5iNkLzR/eM7SQJibhAZrDLEcqWHmBBCCCFaoLlz5/Luu+/y4YcfcuDAAe6++26Ki4uZOXMmANOnT6/RdH/KlCm89dZbLF26lBMnTrBmzRqefPJJpkyZYg+MPfTQQ/z888+cPHmS33//nalTp6LT6Zg2bZpXPkeHmM3Vtprv5t25tCBfbDsNwFWDOxBgaME7yjkTEMs7BRWFoPOD6JZRFuaz7DtNuhAQ6zDE/fMRzjEEwPA/Vl2P7gndLvPefDxBo4Fe1vI+Z3abPLJa/awIiIABN3hkavWK668u0/Y4/9hsaya3JwJiGg10GauOnQkueoiUTLqBrWQyV0omhRBCCNEC3XTTTWRmZvLUU0+RlpbG4MGD+f777+2N9pOTk2tkhD3xxBNoNBqeeOIJUlJSiImJYcqUKfz973+3n3PmzBmmTZtGdnY2MTExXHDBBWzcuJGYmJhm//wcVpiqSlu0eojo5O3ZtAj5pUa+35sGwA3DEr08myayBcRSd4HJCLoGSm7S96rLmN4NnycaF9UVkn+XgFhLNuIO+PUVlfUz6k/NlwnVnHpfAVvehUPfqcwvrQPB/03/UpdDp4Of5zaHqVPcADj6g4sBMes/hjwV7O96Eez6DE7+6pnxnSABMTewlUzmSsmkEEIIIVqoOXPmMGfOnDrvW7duXY3rer2ep59+mqeffrre8ZYuXerO6TUP23/FIzuDTv5MdsR/d52lvNJMr9hQBnYM9/Z0miaqG/iHQ3m+KjOKH1T/ubZyybgBzTO31iyqs7q0lSs3xmKRgJivCY2DSS9AynYYfKu3Z+MZnS9QPx+KM+HMVkhqZCOHzMNw/CdAowKGzc32s8nZgFh5ERSeVceeypTuPh5u+QI6eX6DgcZIyaQbSMmkEEIIIUQrkGP9r3iUlEs66outqlzyhuEd0bT0rBCtFhKsAZbGyiZtbzKlf1jT2UsmHQyI5Z+BkiyVySnr7ztG3AHXvAmGQG/PxDN0Bug5QR07Uja55V112WuSQ7vWul2sNSCWvk9ltDnK9nswKBoCI90/L4Dgdmot/UM9M74TJCDmBlIyKYQQQgjRCtj7h0lDfUccTi9k15l89FoN1wxJ8PZ03CNhuLpsLCBmK5mM7e/Z+bQFzgbEbNlh7fu03uCL8E29r1CXB1eoTMX6lBXAzs/U8cjZnp9XXdp1A32gagPg6PcWeLZ/mA+SgJgbRAarksn8UiMmcwPfGEIIIYQQwnfZA2JdvTuPFsKWHXZp7/ZEh/h7eTZuYm+sv73+c8oKIPekOpaSyaaL7KIuizOgvLDx8+3lkkM9Nych6tJ9nNpII+cYZB2u/7xdS6GiSG0w0PXiZpteDVpdVQZl2m7HH5clATHhpIhAlSFmtkBBqfQRE0IIIYRokdrYf8abwmgy882OFABuGN7Cm+lXl2ANsmQcqD84k3FAXYZ2gKCo5plXaxYYAUHt1LEt0NgQ6R8mvMU/tCrAVV/ZpNkMm99RxyNne3eDAVd2mrT9HoxuG78HJSDmBn56LSH+qvGqlE0KIYQQQrRApsqqN+PSQ6xRPx/OIquogugQfy7u5cM7hzorNA7COgIWtdtkXdKlf5jbOVo2KQ31hbf1mqwuD66o+/4T6yD7CPiFwqCbm21adbI31t/r+GOyj6jLNvKPIQmIuYmtbFICYkIIIYQQLVB+MpiNoA+AsFbSD8uDvtqussOuHZqAQdfK3lLYssTq6yNme3MZJ/3D3MZWNtlYQCz3JJTlqbK19n09PSshaus1GdConw8FqbXv32TNDht8i/ebxscNVJeOZohZLG2ul2Yr++3lPfbG+sVSMimEEEIIz+rcuTPPPvssycnJ3p5K65FdbYdJrfyJ3JCCCvjpcBYANwzr6OXZeIC9j1g9ATFpqO9+jmaI2bLDYvuD3s+zcxKiLqGx0HGEOj60suZ9uSfh8PfqeOSsZp1Wndr3BTRQlAZFmY2fX5wJ5QXqMVFto5em/LZ3E9lpUgghhBDN5YEHHuDrr7+ma9eujB8/nqVLl1JeXu7tabVs0lDfYVuzNJjMFgYnRtAj1ssZEJ5gC4idqSMgZjZD+n51LA313cceEDvR8HlnrZsdSLmk8Kbqu01Wt+U9wALdLoXoHs0+rVr8Q6q+t9IdyBLLspZLRiSBvpVslNIICYi5SWSQlEwKIYQQonk88MAD7Ny5k82bN9OnTx/uvfde4uPjmTNnDtu3N7A7nqifNNR3iMViYVOGegtxw/BWmB0G0GEwoIGCM1CYVvO+3BNgLAadv/SacyeHM8R2qksJiAlvsgXETqyHsnx1XFEC2z9WxyP/5J151cXeR8yBgFgb/D0oATE3ibBniEnJpBBCCCGax9ChQ3nttdc4e/YsTz/9NO+99x4jRoxg8ODBfPDBB1gsFm9PseXIqVYyKeq1O6WAtFIN/notUwZ18PZ0PMM/FGJ6q+OUcwLMtnLJ9n1Ap2/eebVmtoBYQQoYS+s+x2yWgJjwDdE9ILqn6jt5ZI26bc8Xqr9dRCfoMd6r06vBlYCYL2S3NRMJiLlJVLAKiOVJhpgQQgghmonRaOTzzz/nqquu4i9/+QvDhw/nvffe47rrruOxxx7j1ltv9fYUW442+J9xV9ia6U/sG0tYgMHLs/Gg+vqISUN9zwiKAv9wdZx7qu5zco5BRaHa+MIWsBTCW6qXTVossNnaTH/kLNDqvDevczmz02Qb/D0o/9ZwE1vJZE6xBMSEEEII4Vnbt29n8eLF/Pvf/0ar1TJ9+nReeeUVeveuepM4depURowY4cVZtiCV5ZB3Wh23kwyxupRXmtibUsD/9qgSwuuGttLsMJuOw2DnJ7UDYun71GWs9A9zK40GojpD6i5VNtm+joCXraF+3EDJzhPe1/tK+PUVlSF2fJ3KHtUHwpA/eHtmNdkCYlmHVfalIbD+cyUgJlwVGSwlk0IIIYRoHiNGjGD8+PG89dZbXHPNNRgMtTN1unTpws033+yF2bVAOScAC/iHQXCMt2fjEzIKy9h+KpftyXlsO5XLnjP5VJjMAET5WzivS5SXZ+hhtgyxs9tVqZ5t51FbY+rYft6ZV2sW1bUqIFYXW0BMyiWFL+gwFELi1A6O396nbht4IwRGende5wqNh6B2UJINGQcgYWjd55kqqza1kICYcJZ9l0nJEBNCCCGEhx0/fpxOnTo1eE5wcDCLFy9uphm1cPb+YV1VpkobU2kyczCtkB3JuWw7lcu25FxO59Tu4xQV7MfgjuH006ei1bbydWrfV5XmleWrAE10d3Wcl6zul5JJ92ussb4tIFbfG3ohmpNWC70mwbbFkG/9uTBytnfnVBeNBmL7w4mfVR+x+r5/8k6pnmj6QAhLaN45epEExNwkwr7LpGSICSGEEMKzMjIySEtLY9SoUTVu37RpEzqdjuHDh3tpZi1UGysTySupYEdyHtutAbCdp/MoqTDVOEejgV6xoQztFMmwpEiGdYqkU7sgKisrWbky1Uszb0Y6A8QPgtObVNlkdHdI36/uC+voe1kgrUFDATGzSWWPgWSICd/R+0oVEAPodL7vBsrjBqiAWHoDfcSyrf8YatetKiO2DZCAmJtUb6pvsVjQtMH/LgohhBCiedxzzz08/PDDtQJiKSkpvPDCC2zatMlLM2uh7G8EWn9A7IXvD/LWumO1bg/11zOkUyRDkyIY1imSwYkRhLbmpvmOSBhWFRAbdFPVm0lffdPb0tkCYrknat+XdRiMJeAX0ia+T0UL0eVCVWpfXuCb2WE2cQPVZUM7TWYfUZdtrI+mBMTcxFYyWWm2UFhe2bp33RFCCCGEV+3fv5+hQ2uXPQwZMoT9+/d7YUYtXPX/jLdiZUYTH/5+EoAu0cEM6xTJUGv2V4/2Ia2/DNJZ5+40mSb9wzwqsou6zEuGygqg2uvRVi4ZP8i3dvATbZveH657HzL2Q5+rvD2b+tmC+Gl7a/ZErK6NZUrbSEDMTQIMOgIMWsqMZvKKjRIQE0IIIYTH+Pv7k56eTteuXWvcnpqail4vf945zf5GoHUHxH49kkVJhYkO4QH8+JeLpKKhMbZeO2m71U6ktgyxWMkQ84jQONW/qLIU8k9DWFLVfSnb1aWUSwpf03OC+vBl0T1B5wcVhapXWFSX2ufYfw/2aN65eVnbKQ5tBlHWLLGcEmmsL4QQQgjPmTBhAvPmzSM/P99+W15eHo899hjjx4/34sxaoIoitUsYQFTrDoit3q8+zwn94iQY5ojILqpXmKkCUnerHdpA9eMR7qfR1N9HTHaYFMJ1OgO076OO6yubzGqbGWISEHOjCNtOkxIQE0IIIYQHvfTSS5w+fZpOnTpxySWXcMkll9ClSxfS0tJ4+eWXvT29lsX2xjsoGgIjvDoVTzKZLfxwIAOACX1jvTybFkKjqSqb3Pul6mGlD6wK2gj3s2WuVA+ImYxVb+IlICaEa2yB/LoCYuVFUHhWHbfyTOlzSU69G1VvrC+EEEII4SkJCQns3r2bTz/9lF27dhEYGMjMmTOZNm0aBoO0bXCGxvbGu5W/Cdh2Kpec4grCAw2M6BLl7em0HAnD4OgPsGuput6+j/Sw8qS6MsQyD4KpHPzDq/qMCSGcE2sNiNW106T9H0PtIKht/X6QgFh9zGZ0X9/BZcc2wEUjIKJDow+JCFJ/gOYUGz09OyGEEEK0ccHBwcye7cO7WrUQmpy2scPk6n2qXPKy3u0x6KRIxGEJw9VlWZ66lB0mPcseEKvaaVKTulMddBhUdzNwIUTjGsoQs+8w2bp/D9ZFAmL10WrRpO8lpCKDyrQ9DgXEbDtNSoaYEEIIIZrD/v37SU5OpqKi5t8eV13lw7td+Rh7hlgrLoOzWCyssvcPk3JJpyScs5trrPQP86g6SiarAmJSLimEy2zB/PzTUJJTMxPMvtNy22qoDxIQa5AlbiCanGNo0nZD74mNnh9pLZnMKZaAmBBCCCE85/jx40ydOpU9e/ag0WiwWCwA9kbpJpPJm9NrWdpAhtjBtEJO55Tir9cytmeMt6fTsgRHQ0QntTMbSIaYp9kC07knwax+jlUFxIbW+RAhhAMCwiEiCfKSVdlkl7FV92XZMsRad+uAuriUc3r69GnOnDljv75582YeeOAB3nnnHbdNzBdYrGmFmvR6dmI4R6S1ZDKvREomhRBCCOE5999/P126dCEjI4OgoCD27dvH+vXrGT58OOvWrfP29FqUqh5irTcgtnpfOgAX9oghyE/+H+40W2N9gPZ9vTePtiAsAXR+YDZCQQpasxFNxn51n2SICdE0cQPVZdo5fcSy2+YOk+BiQOyWW27hp59+AiAtLY3x48ezefNmHn/8cZ599lm3TtCbLHGDAFSGmANsTfVll0khhBBCeNKGDRt49tlniY6ORqvVotVqueCCC1iwYAH33Xeft6fXYhgqC9GU5qgrrbhkcrWUSzaNLSAWntSqdyL1CVodRHYGQJN7grCy02jMRgiMUtktQgjX1dVHzGKpKpmMbnslky4FxPbu3cvIkSMB+Pzzz+nfvz+///47n376KUuWLHHn/LzKYu0RoMk9AWX5jZ4fESQlk0IIIYTwPJPJRGhoKADR0dGcPau2S+/UqROHDh3y5tRalJBylTlFWAL4BXl3Mh5yJreEfWcL0GpUQ33hgj5T1GtkyK3enknbYA1Oa3KOE1FyUt3WYQhYS8KFEC6KtZZ8Vw+IFWdCeT6gaZO7uLqUM200GvH39wfghx9+sDdu7d27N6mpqe6bnbcFRVHiF01QRZZ60XS+oMHTpWRSCCGEEM2hf//+7Nq1iy5dujBq1ChefPFF/Pz8eOedd+jatfVmOrlbsC0g1pqzw6zlksM7R9EuxN/Ls2mhIjvB3P3enkXbYe8jdoKIYmtJs5RLCtF0tgyxzINQWQF6v6pyyYgkMAR4b25e4lKGWL9+/Xj77bf55ZdfWLNmDZdffjkAZ8+epV27dm6doLflB3ZSB6m7Gj3XtstkTkmFvbmtEEIIIYS7PfHEE5jNZgCeffZZTpw4wYUXXsjKlSt57bXXvDy7liOkzPqP3FbcN8VWLjmxX5yXZyKEg6xZKprck0SUnFC3SUBMiKaLSAL/cNWjL8uaTd6G+4eBixliL7zwAlOnTuWf//wnM2bMYNAg1Wvr22+/tZdSthZ5QZ2Iz9/mWEDM2kOsotJMqdEkTUuFEEII4RETJ1btft29e3cOHjxITk4OkZGR9p0mRePsGWKtdGet3OIKNp9QPdIm9JX+YaKFsJVMZuwntCxF3SYBMSGaTqNRO+We+k1VwMUNqLbDpATEHHbxxReTlZVFQUEBkZGR9ttnz55NUFDr6r+QH9hZHTgQEAv20+Gn01JhMpNbYpSAmBBCCCHczmg0EhgYyM6dO+nfv7/99qioKC/OqmUKKVfZU631jcDagxmYLdAnPozEqNb1N7poxaKsGWJ5J9EAluD2aMI6eHdOQrQWcQOsATHrTpNtuKE+uFgyWVpaSnl5uT0YdurUKRYtWsShQ4do3751NevMD7KWTGYdhoqSBs/VaDREWPuI5UpjfSGEEEJ4gMFgICkpCZPJ5O2ptGwWS1VT/ajWmSG2ap91d0nJDhMtSUQSaHT2q5b4QdJQXwh3se80uVtdZtsyxFrn78HGuBQQu/rqq/noo48AyMvLY9SoUbz88stcc801vPXWW26doLeV6SOwBLcHixnS9zV6vq2PWG6JBMSEEEII4RmPP/44jz32GDk5Od6eSstVlI7eXIZFo4XIzt6ejduVVpj45UgmABP6SUBMtCA6gwqKWVniB3tvLkK0NvaA2B4wVUKOtU9fK82UboxLAbHt27dz4YUXAvDll18SGxvLqVOn+Oijj1pfI1eNBkvcQHWcurPR0yODVYZYjmSICSGEEMJD3njjDdavX0+HDh3o1asXQ4cOrfHhijfffJPOnTsTEBDAqFGj2Lx5c4PnL1q0iF69ehEYGEhiYiIPPvggZWVlTRqzOWlyrbvXRXRSO221MuuPZFJmNNMxMpC+8WHeno4Qzqm286slXvqHCeE2Mb1Bq4eyPEjeoBrs6wMgrKO3Z+YVLjW5KikpITQ0FIDVq1dz7bXXotVqOe+88zh16pRbJ+gLLLED4NgPVWmFDbBliOWVGD09LSGEEEK0Uddcc41bx1u2bBlz587l7bffZtSoUSxatIiJEyfW2w7js88+49FHH+WDDz5gzJgxHD58mNtvvx2NRsPChQtdGrPZWfumWCK70hqLsVbvU+WgE/rGyUYLouWJ6gLW1kaW+EHenYsQrYneH6J7QcY+2Pe1ui2qG2hdypVq8VwKiHXv3p3ly5czdepUVq1axYMPPghARkYGYWGt7z9QlnhbhpjjO01KyaQQQgghPOXpp59263gLFy5k1qxZzJw5E4C3336bFStW8MEHH/Doo4/WOv/333/n/PPP55ZbbgGgc+fOTJs2jU2bNrk8ZnOzZYhZWmHflEqTmbUHrQExKZcULZE1Q6zUEIU+RF7DQrhV3AAVENv/rbreCn8POsqlgNhTTz3FLbfcwoMPPsill17K6NGjAZUtNmRI60tptZdMpu+HyooG0+ojpam+EEIIIVqQiooKtm3bxrx58+y3abVaxo0bx4YNG+p8zJgxY/jkk0/YvHkzI0eO5Pjx46xcuZLbbrvN5THLy8spLy+3Xy8oKADUrppGo/sz7zXWreZN4Z0we2B8b9p4PIe8EiORQQYGdQhx6/rZxvLE16S1kjVzQdKF6LUGUiJG0kHWzWHyWnNNW1s3bUwfdAAlWQCYIrs5/XvQ19fM0Xm5FBC7/vrrueCCC0hNTWXQoKoU1ssuu4ypU6e6MqRvC0+CgHAoy4fMg2DLGKtDVVN933xhCCGEEKLl02q1DZbBObMDZVZWFiaTidjYmlkYsbGxHDx4sM7H3HLLLWRlZXHBBRdgsViorKzkrrvu4rHHHnN5zAULFjB//vxat69evZqgoCCHPx9HXXJ6D2HA1hN5ZGavdPv43vTVCS2gpUdwOatXfe+R51izZo1Hxm3NZM2cox3wFmaNnn2ybk6T15pr2sq6RReWcH6167vOFHF6pWu/B311zUpKShw6z6WAGEBcXBxxcXGcOXMGgI4dOzJy5Einxnjrrbd46623OHnyJAD9+vXjqaeeYtKkSa5OyzM0GogbCCd/UWWTDgXEJENMCCGEEJ7xzTff1LhuNBrZsWMHH374YZ1BJXdbt24dzz//PP/3f//HqFGjOHr0KPfffz/PPfccTz75pEtjzps3j7lz59qvFxQUkJiYyIQJEzzSkqNySBKbf/qKwZNnYgjzgZ5mbmKxWHjh5V+AMmaOH8q4Pu793IxGI2vWrGH8+PEYDAa3jt1ayZq5RtbNebJmrmlz61YyCl55wX514KXXMSBhuFND+Pqa2bLMG+NSQMxsNvO3v/2Nl19+maKiIgBCQ0P5y1/+wuOPP47WwYZsHTt25B//+Ac9evTAYrHw4YcfcvXVV7Njxw769evnytQ8J35QVUCM2+o9zbbLpATEhBBCCOEpV199da3brr/+evr168eyZcu44447HB4rOjoanU5Henp6jdvT09OJi4ur8zFPPvkkt912G3feeScAAwYMoLi4mNmzZ/P444+7NKa/vz/+/v61bjcYDJ75Yzu+P6kRyQwJa++Tf8y7am9KPmfzywg06LikTxwGg84jz+Oxr0srJmvmGlk358mauabNrFt4HIR2gMKzAOjb9wIXP29fXTNH5+TSVgKPP/44b7zxBv/4xz/YsWMHO3bs4Pnnn+f111936r+CU6ZMYfLkyfTo0YOePXvy97//nZCQEDZu3OjKtDwrfrC6bKSxvj1DrFhKJoUQQgjRvM477zzWrl3r1GP8/PwYNmxYjceZzWbWrl1r7xN7rpKSklr/ANXpVODFYrG4NKZwj9X7VRBybM9oAjwUDBNCCNHCxQ1Ql4FREBTl3bl4kUsZYh9++CHvvfceV111lf22gQMHkpCQwJ///Gf+/ve/Oz2myWTiiy++oLi42Df/ULKVSabvBbMJtHX/gSElk0IIIYTwhtLSUl577TUSEhKcfuzcuXOZMWMGw4cPZ+TIkSxatIji4mL7DpHTp08nISGBBQsWAOqfmgsXLmTIkCH2ksknn3ySKVOm2ANjjY0pPGP1vjQAJvStOxNPCCGEIG4AHFkF0T28PROvcikglpOTQ+/evWvd3rt3b3Jycpwaa8+ePYwePZqysjJCQkL45ptv6Nu3b53nNvfuQzV2TgjrhN4QhMZYgjH9IET3rPMxIX6qwW1JhYmikjL82+B/5nx9xwlfJGvmGlk358mauUbWzXm+vma+Oi9HRUZG1miqb7FYKCwsJCgoiE8++cTp8W666SYyMzN56qmnSEtLY/DgwXz//ff2pvjJyck1MsKeeOIJNBoNTzzxBCkpKcTExDBlypQa/xRtbEzhfqeyizmYVohOq+HS3q2nL5oQQgg36z0ZNr0Nva/09ky8yqWA2KBBg3jjjTd47bXXatz+xhtvMHBg/Q3n69KrVy927txJfn4+X375JTNmzODnn3+uMyjW3LsP2dh2TrjAL4F2xiPs/v4jzkSNqfNcswW06DCj4av/rSKidiuMNsNXd5zwZbJmrpF1c56smWtk3Zznq2vm6O5DvuqVV16pERDTarXExMQwatQoIiMjXRpzzpw5zJkzp8771q1bV+O6Xq/n6aef5umnn3Z5TOF+a6zlkiM7RxEZ7Ofl2QghhPBZCcPg0eR6K9/aCpcCYi+++CJXXHEFP/zwg728ccOGDZw+fZqVTm7X6efnR/fu3QEYNmwYW7Zs4dVXX+Vf//pXrXObe/ehc3dO0OrWw9YjDI7TMnDc5Hof99yen8gpNjJ09IX0jgt1+7x8na/vOOGLZM1cI+vmPFkz18i6Oc/X18zR3Yd81e233+7tKQgftHqfCohN7CdZeEIIIRrRxoNh4GJA7KKLLuLw4cO8+eabHDx4EIBrr72W2bNn87e//Y0LL7zQ5QmZzeYaZZHVNfvuQ+eO32EwALr0PegaeL6oYH9yio0UVph98k1Ac/HVHSd8mayZa2TdnCdr5hpZN+f56pr54pycsXjxYkJCQrjhhhtq3P7FF19QUlLCjBkzvDQz4S1ZReVsPaVal4zvJ/3DhBBCiMa4FBAD6NChQ63m+bt27eL999/nnXfecWiMefPmMWnSJJKSkigsLOSzzz5j3bp1rFq1ytVpeVb8IHWZthssFqhWqlBdZJD6I1t2mhRCCCGEJyxYsKDObPr27dsze/ZsCYi1QWsPpGO2QP+EMBIiAr09HSGEEMLnuRwQc4eMjAymT59Oamoq4eHhDBw4kFWrVjF+/HhvTqt+Mb1B5wdl+ZB3CiI713lahOw0KYQQQggPSk5OpkuXLrVu79SpE8nJyV6YkfA2W7mk7C4phBBCOMarAbH333/fm0/vPL0ftO8DqbvURz0BsShbQKxYAmJCCCGEcL/27duze/duOnfuXOP2Xbt20a5dO+9MSnhNcXklvxzNAmCC9A8TQgghHKJt/BRRg61sMnVXvadEBFtLJkukZFIIIYQQ7jdt2jTuu+8+fvrpJ0wmEyaTiR9//JH777+fm2++2dvTE81s/eFMKirNdGoXRK/YtrehkxBCCOEKpzLErr322gbvz8vLa8pcWgYHAmK2DLE8KZkUQgghhAc899xznDx5kssuuwy9Xv05ZzabmT59Os8//7yXZyea2+r9tnLJWDT19LgVQgghRE1OBcTCw8MbvX/69OlNmpDPix+sLlN31dtYP9IaEMuRgJgQQgghPMDPz49ly5bxt7/9jZ07dxIYGMiAAQPo1KmTt6cmmpnRZGbtAWtATHaXFEIIIRzmVEBs8eLFnppHy9G+L2i0UJwJhWkQFl/rlIggKZkUQgghhOf16NGDHj16eHsawos2Hc+hoKySdsF+DE2K9PZ0hBBCiBZDeog5yy8Ionup43rKJqOCpam+EEIIITznuuuu44UXXqh1+4svvsgNN9zghRkJb1m9Pw2AcX1i0WmlXFIIIYRwlATEXGHrI5a2u867I2y7TErJpBBCCCE8YP369UyePLnW7ZMmTWL9+vVemJHwBovFwup9tnJJ2V1SCCGEcIYExFwRP1BdNpIhVlhWidFkbq5ZCSGEEKKNKCoqws/Pr9btBoOBgoICL8xIeMOelHzSCsoI8tNxfvdob09HCCGEaFEkIOaKRnaaDA802Hvt50kfMSGEEEK42YABA1i2bFmt25cuXUrfvn29MCPhDav2qXLJi3vFEGDQeXk2QgghRMviVFN9YRU3QF3mn4aSHAiKqnG3TqshLMBAfqmRvJIKYkL9vTBJIYQQQrRWTz75JNdeey3Hjh3j0ksvBWDt2rV89tlnfPnll16enWgu9nLJvrK7pBBCCOEsyRBzRUA4RHZRx42UTeZIY30hhBBCuNmUKVNYvnw5R48e5c9//jN/+ctfSElJ4ccff6R79+7enp5oBscziziSUYReq+GSXu29PR0hhBCixZGAmKsaKZuMCDIAkCslk0IIIYTwgCuuuILffvuN4uJijh8/zo033shDDz3EoEGDvD010QzW7FfZYed1bUe49e9OIYQQQjhOAmKuaiQgFmXdaTJPdpoUQgghhIesX7+eGTNm0KFDB15++WUuvfRSNm7c6O1piWaw2hoQmyi7SwohhBAukR5irrIFxNJ213l3hDUgliMBMSGEEEK4UVpaGkuWLOH999+noKCAG2+8kfLycpYvXy4N9duIjMIytifnAjCurwTEhBBCCFdIhpirbAGx7KNQVnt780hr6rrsMimEEEIId5kyZQq9evVi9+7dLFq0iLNnz/L666//f3v3HR5VmfZx/Dsz6SEJCSEkoYZepEkTUXp3WVFcAVHBuiqoyOKyWCiuiivKYlt9dSm6K6K4gigIRBAEpCiKgkDonRB6GkkmM+f945CBQAiZtJkkv891zebMmTNn7rkziyf3PM/9eDosKWXfbkvCMKBljTBiwgI9HY6IiEiZpBFihRUcCaHVIfkIHN8KtW/M9XC4muqLiIhIMfvmm2944oknePTRR2nQoIGnwxEPWbYtEYDezbS6pIiISGFphFhRuPqIXTltMmeVyaSUzNKMSERERMqxNWvWkJKSQps2bejQoQNvv/02J0+e9HRYUopSMuz8sPsUAL01XVJERKTQVBAriugW5s88Gus3rx4GwI/7TpNhd5RmVCIiIlJO3XDDDXzwwQccO3aMP//5z8ydO5fY2FicTifx8fGkpKR4OkQpYat2niDL4SQuMpj6UZU8HY6IiEiZpYJYUeSz0mSz2FCqhfpz3u5g/d5TpRyYiIiIlGfBwcHcf//9rFmzhi1btvCXv/yFV155haioKP74xz96OjwpQct+N1eX7N20GhaLxcPRiIiIlF0qiBVFTkHsxA6wn8/1kMVioXtjcxj7ih1JpR2ZiIiIVBCNGjXi1Vdf5fDhw3zyySeeDkdKUFa2k+8SzOvKXpouKSIiUiQqiBVFaCwERYLhgKRtVzzco3EUAMu3J2EYRmlHJyIiIhWIzWZj4MCBLFy40NOhSAnZsO8UKRnZRFbyo3WtcE+HIyIiUqapIFYUFgvEXL2PWKf6kfj7WDly9jwJx9XTQ0REREQKL36bOV2yR+Nq2KyaLikiIlIUKogVVT59xAL9bNxYrwpgjhITERERESkMwzBcBbHezTRdUkREpKhUECsqV0Hstzwf7tFEfcREREREpGi2Hknm2LkMAn1tdKof6elwREREyjwVxIoq+sKUyeO/g8N+xcPdL/QR+/ngGU6nZZVmZCIiIiJSTizblghAl4ZVCfC1eTgaERGRsk8FsaIKjwP/UHBkwomEKx6OrRxIk5hQDANWJmiUmIiIiIi4L2e6pFaXFBERKR4qiBWV1XpxlFgefcQg92qTIiIiIiLuOHgqnR2JKdisFtfsAxERESkaFcSKQ85Kk4lX6yNmXrh8v/MEWdnO0opKRERERMqBnOmS7eqEEx7s5+FoREREygcVxIpDPitNArSsUZkqwX6kZGbz0/7TpRiYiIiIiJR1rtUlm0Z7OBIREZHyQwWx4pBTEEvcAs4rR4BZrRa65Uyb1GqTIiIi4oXeeecd6tSpQ0BAAB06dGDjxo1XPbZr165YLJYrbrfccovrmBEjRlzxeN++fUvjrZQrp9Oy+PHCF6rqHyYiIlJ8VBArDlUagE8gZKXC6b15HnKxj9hxDMMozehERERE8vXpp58yZswYJk6cyM8//0zLli3p06cPSUl5f5H3xRdfcOzYMddt69at2Gw2/vSnP+U6rm/fvrmO++STT0rj7ZQrK3Yk4TSgcXQINSOCPB2OiIhIuaGCWHGw+UC1Zub2sc15HnJzw6r42izsP5XO3pNppRebiIiIyDVMmzaNhx56iPvuu4+mTZvy3nvvERQUxMyZM/M8PiIigujoaNctPj6eoKCgKwpi/v7+uY4LDw8vjbdTriz73ewf1ruZpkuKiIgUJx9PB1BuxLSEIz+ZfcSa33HFw5X8fbihbhVW7zrJiu1J1KtayQNBioiIiOSWlZXFpk2bGD9+vGuf1WqlZ8+erFu3rkDnmDFjBkOGDCE4ODjX/pUrVxIVFUV4eDjdu3fnxRdfpEqVKnmeIzMzk8zMTNf95ORkAOx2O3a73d23dU055yyJcxeX81kOvt91AoDuDat4RaxlIW/eRjkrHOXNfcpZ4Shv7vP2nBU0LhXEiourj1jeK00CdG8cxepdJ1m+4zgPda5bSoGJiIiIXN3JkydxOBxUq5a7P1W1atXYsWPHNZ+/ceNGtm7dyowZM3Lt79u3L7fffjtxcXHs2bOHZ555hn79+rFu3TpsNtsV55kyZQqTJ0++Yv+yZcsICiq5qYLx8fEldu6i2nLaQobdRmU/g/2/rOHAZk9HdJE3581bKWeFo7y5TzkrHOXNfd6as/T09AIdp4JYcYlpYf489isYBlgsVxzSo3E1Jn+1jR/3n+Fcup2wIN9SDlJERESkeM2YMYPmzZvTvn37XPuHDBni2m7evDktWrSgXr16rFy5kh49elxxnvHjxzNmzBjX/eTkZGrWrEnv3r0JDQ0t9rjtdjvx8fH06tULX1/vvCZbPf934AgDWtfilluaeDocoGzkzdsoZ4WjvLlPOSsc5c193p6znFHm16KCWHGJagpWHzh/Bs4dgsq1rjikVpUgGkRVYldSKqt2neCPLWM9EKiIiIjIRZGRkdhsNo4fP55r//Hjx4mOzr9vVVpaGnPnzuWFF1645uvUrVuXyMhIdu/enWdBzN/fH39//yv2+/r6lujFdkmfv7AcToPvEszpkn2bx3pdjN6aN2+mnBWO8uY+5axwlDf3eWvOChqTmuoXFx9/iLrwzd2xX696WPcm5mqTK7Yfv+oxIiIiIqXFz8+PNm3asHz5ctc+p9PJ8uXL6dixY77PnTdvHpmZmdx9993XfJ3Dhw9z6tQpYmJiihxzRfDzwTOcSssiNMCH9nERng5HRESk3FFBrDjl9BE7dvU+Yj0am/05Vu48QbbDWRpRiYiIiORrzJgxfPDBB3z44Yds376dRx99lLS0NO677z4A7r333lxN93PMmDGDgQMHXtEoPzU1laeffpr169ezf/9+li9fzq233kr9+vXp06dPqbynsi5+m/nlaffGUfjadMkuIiJS3DRlsjhFtwT+m+8IsetrVSYs0Jez6XZ+PnhW3/iJiIiIxw0ePJgTJ04wYcIEEhMTadWqFUuWLHE12j948CBWa+6iTEJCAmvWrGHZsmVXnM9ms/Hbb7/x4YcfcvbsWWJjY+nduzd///vf85wWKbkZhsGy3xMB6NU0/2mrIiIiUjgqiBUn1wixqxfEfGxWujWqyoLNR1m+47gKYiIiIuIVRo0axahRo/J8bOXKlVfsa9SoEYZh5Hl8YGAgS5cuLc7wKpTdSansP5WOn81Kl0ZVPR2OiIhIuaTx18Up+jrAAqmJkHL1HmHdm5jftq7YnlRKgYmIiIhIWbHswnTJG+tXoZK/vr8WEREpCSqIFSe/YIhsYG4nXr2PWJcGVbFZLexKSuXgqfRSCk5EREREyoKcglhvTZcUEREpMSqIFTfXtMnNVz0kLMiXtrXDAVi+Q6tNioiIiIjpeHIGvx46C0DPC6uTi4iISPFTQay4FWClSYCeOdMmd2japIiIiIiYclaXbFWzMlGhAR6ORkREpPxSQay4FaCxPkD3C9/4rd97itTM7JKOSkRERETKgJyCWO9m1TwciYiISPmmglhxi25u/jx7AM6fuephdSODqVMlCLvDYM2uE6UUnIiIiIh4q5QMOz/sOQlA76YqiImIiJQkFcSKW2A4VK5tbuczbdJisdC9sXmhs1yrTYqIiIhUeKt2nsDuMKgbGUy9qpU8HY6IiEi5poJYSciZNpnPSpNwsVHqdwlJOJ1GSUclIiIiIl5s2e/mdMleTathsVg8HI2IiEj5poJYSYhpYf68Rh+xtnUiCPH34WRqFr8ePlvycYmIiIiIV8rKdvJdgjlrQP3DRERESp5HC2JTpkyhXbt2hISEEBUVxcCBA0lISPBkSMUjppX58xoFMT8fK50bVgW02qSIiIhIRbZh3ylSMrKJrORHq5rhng5HRESk3PNoQWzVqlWMHDmS9evXEx8fj91up3fv3qSlpXkyrKLLmTJ5chdk5f9eujc2p02qj5iIiIhIxZWzumTPJtWwWTVdUkREpKT5ePLFlyxZkuv+7NmziYqKYtOmTXTu3NlDURWDSlFQKRpSEyFxK9TqcNVDuzWOwmKBbceSOXr2PLGVA0sxUBERERHxNMMwXAWxXlpdUkREpFR4tCB2uXPnzgEQERGR5+OZmZlkZma67icnJwNgt9ux2+3FHk/OOQtzblt0c6y7E3Ec/hlnzPVXPS7Ez0LrmpX5+eBZ4n8/xl3taxY6Xm9RlLxVVMpZ4Shv7lPOCkd5c5+358xb45KKaeuRZI6dyyDIz0an+pGeDkdERKRC8JqCmNPpZPTo0XTq1Inrrrsuz2OmTJnC5MmTr9i/bNkygoKCSiy2+Ph4t5/TODWIRsCRnxbxy4nYfI+NxcLP2Ph09e9UPrmlkFF6n8LkraJTzgpHeXOfclY4ypv7vDVn6enpng5BxCV+WyIAnRtUJcDX5uFoREREKgavKYiNHDmSrVu3smbNmqseM378eMaMGeO6n5ycTM2aNenduzehoaHFHpPdbic+Pp5evXrh6+vr1nMtu33h0y+pad9DTL9+kM/S2fUSU/j6nXXsSfWhW89uBPqV7QuhouStolLOCkd5c59yVjjKm/u8PWc5o8xFvMEyTZcUEREpdV5REBs1ahRff/0133//PTVq1Ljqcf7+/vj7+1+x39fXt0Qvtgt1/vrdwDcYS8pRfE/+DrGtr3posxrhVK8cyJGz59l44Bw9y8nFUEn/Xsoj5axwlDf3KWeFo7y5z1tz5o0xScV08FQ6OxJTsFktrsWWREREpOR5dJVJwzAYNWoU8+fPZ8WKFcTFxXkynOLlGwj1u5vbOxbne6jFYqFHkwurTe7QapMiIiIiFcWyC9Ml29UJJzzYz8PRiIiIVBweLYiNHDmS//73v8yZM4eQkBASExNJTEzk/Pnzngyr+DS6xfyZkH9BDHB9I7hix3EMwyjJqERERESkCJxOgzkbDrJx3+kinytndcneTaOLfC4REREpOI8WxN59913OnTtH165diYmJcd0+/fRTT4ZVfBr2AYsNjm+FM/vzPfSGulUI8rNxPDmT34+qr4mIiIiIt1q75yTPzN/Cnf+3jkf+s4mDpwq3SMPptCx+3G8W1dQ/TEREpHR5fMpkXrcRI0Z4MqziExQBtTqa2wnf5HtogK+Nmy4ss718u6ZNioiIiHirhMQU1/aS3xPp+c9VvLpkB6mZ2W6dZ8WOJJwGNIkJpWZEya2YLiIiIlfyaEGsQmjc3/y5Y9E1D83pI7Zix/GSjEhEREREimDvyTQABrSMpVP9KmRlO/nXyj10f20ln286jNNZsPYXy343+4dpdJiIiEjpU0GspDW6UBA78AOk599nolsjsyD26+FzJKVklHRkIiIiIlII+06YBbGuDavy3wc68P49bahdJYiklEzGzvuV2/61lk0HzuR7jgy7g9W7TgLQWwUxERGRUqeCWEmLiIOoZmA4YNeyfA+NCg2gRY0wAFbuOFEa0YmIiIiIm/aeTAWgbtVgLBYLvZtFs+ypzvytX2Mq+fvw6+FzDHr3B0bP/YVj5/JeLGrNrpOctzuoXjmQZrGhpRm+iIiIoIJY6XBn2mRj8xvCb7dr2qSIiIiIt0nLzOZ4ciYAcZHBrv3+PjYe6VKPFWO7cGfbGlgssGDzUbq/too3l+8iw+7IdZ5l2y5Ol7RYLKX3BkRERARQQax05Eyb3L0c7PlPhczpI7Zm98krLpxERERExLP2XegfFhHsR+UgvysejwoJ4NU7WrJw5E20rR3OebuDafE76fH6Kr7+7SiGYeBwGq5FlNQ/TERExDNUECsNsa0hJBbsabDv+3wPbRYbSrVQf9KzHGzYl3/PMREREREpXTkFsUtHh+WleY0w5j3SkbeGtiY2LIAjZ88zas4vDP6/9Xy84QCn0rIIDfChfVxEaYQtIiIil1FBrDRYLJdMm/z6Goda6N74wmqTmjYpIiIi4lX2XmioX/caBTEwr+sGtIxl+V+68lTPhgT4Wtm4/zQTvvwdgO6No/C16XJcRETEE/Rf4NKSM21y5xJwOvM99GIfsSQMo2DLdouIiIhIydt3oaF+XNVrF8RyBPrZeLJnA1b8pSu3top17e97XUyxxyciIiIF4+PpACqMOjeDfyikHocjm6Bmu6se2ql+JP4+Vo6cPc8vh85yfa3wUgxURERERK4mZ8pkQUaIXS62ciBvDGnN/Z3iOHg6nT7N1D9MRETEUzRCrLT4+EH9nuZ2Qv6rTQb62fhDC/Pbw3/G7yzpyERERESkAAzDYG9OQaxqpUKfp2XNygxoGavVJUVERDxIBbHS1PgW8+eOxdc8dHTPBvjaLKzedZIf9pws4cBERERE5FpOpmaRkpGNxQK1IoI8HY6IiIgUgQpipalBL7D6wskEOLk730NrRgQxtH0tAKYuTVAvMREREREPy5kuWb1yIAG+Ng9HIyIiIkWhglhpCgiDOjeZ29eYNgkwqnt9Anyt/HLwLMu3J5VwcCIiIiKSH1dD/UL0DxMRERHvooJYaXNj2mRUSAD3dYoD4LVlCTidGiUmIiIiJeOdd96hTp06BAQE0KFDBzZu3HjVY7t27YrFYrnidsstt7iOMQyDCRMmEBMTQ2BgID179mTXrl2l8VZKTE7/sHpF6B8mIiIi3kEFsdLWqJ/589AGSD1xzcMf6VyPkAAfdiSm8NVvR0s4OBEREamIPv30U8aMGcPEiRP5+eefadmyJX369CEpKe8R6l988QXHjh1z3bZu3YrNZuNPf/qT65hXX32VN998k/fee48NGzYQHBxMnz59yMjIKK23Vez2njALYhohJiIiUvapIFbawmpATEvAgJ1Lrn14kC+PdKkHwLT4ndgdzhIOUERERCqaadOm8dBDD3HffffRtGlT3nvvPYKCgpg5c2aex0dERBAdHe26xcfHExQU5CqIGYbB9OnTee6557j11ltp0aIFH330EUePHmXBggWl+M6KV04PMRXEREREyj4fTwdQITW6BY79CjsWwfX3XPPwETfWYdbafRw4lc5nPx1iWIfapRCkiIiIVARZWVls2rSJ8ePHu/ZZrVZ69uzJunXrCnSOGTNmMGTIEIKDzULRvn37SExMpGfPnq5jwsLC6NChA+vWrWPIkCFXnCMzM5PMzEzX/eTkZADsdjt2u71Q7y0/Oecs6LkdToMDp8yCWM3K/iUSU1ngbt5EOSss5c19ylnhKG/u8/acFTQuFcQ8ofEtsPJl2PsdZKWBX/7fMgb7+zCqW30mfbWNN5fvYtD1NbSykYiIiBSLkydP4nA4qFatWq791apVY8eOHdd8/saNG9m6dSszZsxw7UtMTHSd4/Jz5jx2uSlTpjB58uQr9i9btoygoKBrxlFY8fHxBTruZAbYHT74WAw2//Adv1lKLKQyoaB5k4uUs8JR3tynnBWO8uY+b81Zenp6gY5TQcwTqjWDyrXg7EHY8x00+cM1nzK0Qy0+WL2PI2fP89G6/TzcuV4pBCoiIiKSvxkzZtC8eXPat29fpPOMHz+eMWPGuO4nJydTs2ZNevfuTWhoaFHDvILdbic+Pp5evXrh6+t7zeNX7TwBv/xC3aoh/OGWG4s9nrLC3byJclZYypv7lLPCUd7c5+05yxllfi0qiHmCxWJOm9zwLiQsLlBBzN/HxuieDXj689/418o9DG1fi5AA7/vgiYiISNkSGRmJzWbj+PHjufYfP36c6OjofJ+blpbG3LlzeeGFF3Ltz3ne8ePHiYmJyXXOVq1a5Xkuf39//P39r9jv6+tbohfbBT3/wTPmdM66VSt55cV/aSvp30t5pJwVjvLmPuWscJQ393lrzgoak5rqe0rj/ubPnUvA6SjQU25rXZ16VYM5m27ng9X7SjA4ERERqSj8/Pxo06YNy5cvd+1zOp0sX76cjh075vvcefPmkZmZyd13351rf1xcHNHR0bnOmZyczIYNG655Tm/laqhfVQ31RUREygMVxDyl1o0QUBnST8GhDQV6io/NytjejQCYsXovp1Izr/EMERERkWsbM2YMH3zwAR9++CHbt2/n0UcfJS0tjfvuuw+Ae++9N1fT/RwzZsxg4MCBVKlSJdd+i8XC6NGjefHFF1m4cCFbtmzh3nvvJTY2loEDB5bGWyp2OQWxulphUkREpFzQlElPsflAw77w21xztcnaBetF0fe6aJpXD2PLkXP8a+Uenv9D0xIOVERERMq7wYMHc+LECSZMmEBiYiKtWrViyZIlrqb4Bw8exGrN/T1qQkICa9asYdmyZXme869//StpaWk8/PDDnD17lptuuoklS5YQEBBQ4u+nJOw9kQpAXY0QExERKRc0QsyTcqZN7lgEhlGgp1gsFp7uY44S+8/6Axw9e76kohMREZEKZNSoURw4cIDMzEw2bNhAhw4dXI+tXLmS2bNn5zq+UaNGGIZBr1698jyfxWLhhRdeIDExkYyMDL799lsaNmxYkm+hxJzPcnD0XAYAcZGVPByNiIiIFAcVxDypXg+w+cOZfXDi2sua57i5QSQd4iLIynby5vJdJRigiIiIiOw/ZU6XDAv0JTzI+5oHi4iIiPtUEPMk/0pQt4u5vWNRgZ9msVj4a19zlNi8TYddQ/hFREREpPi5+odVDcZisXg4GhERESkOKoh5WqML0yYTFrv1tDa1I+jROAqH0+Cf32qUmIiIiEhJyfnyMU4N9UVERMoNFcQ8rVE/8+eRTZB8zK2n/uXCipNf/XqU34+eK+7IRERERATYqxUmRUREyh0VxDwtJBpqtDO33Rwl1jQ2lD+2jAXg9WU7izsyEREREeHilEk11BcRESk/VBDzBoWcNgnwVK+G2KwWVuxI4qf9p4s5MBERERG5tIeYiIiIlA8qiHmDxreYP/d9D5kpbj01LjKYO9vWBODVJQkYhlHc0YmIiIhUWKfTsjibbgegThUVxERERMoLFcS8QWRDiKgHjizY/a3bT3+iR338fKxs3H+aVTtPlECAIiIiIhXTvpNmQ/3YsAAC/WwejkZERESKiwpi3sBigcYXpk3uWOT202PCAhnesTYAU5cm4HRqlJiIiIhIcdh74kL/ME2XFBERKVdUEPMWjf9g/ty1DBx2t5/+aNf6BPvZ+P1oMkt+Tyzm4EREREQqJlf/MDXUFxERKVdUEPMWNdpBUCRknIMDa91+ekSwHw/eXBeA15YlkO1wFneEIiIiIhWOa4RYpEaIiYiIlCcqiHkLqw0a9TW3d7i/2iTAgzfHER7ky94TaXzxy5FiDE5ERESkYsoZIaYpkyIiIuWLCmLepNGF1SYTFkMhVosMCfDlsa71AXjj211kZjuKMzoRERGRCsXpNNh3yiyI1dOUSRERkXJFBTFvUrcr+ATCuUOQ+FuhTnFPx9pEhwZw5Ox5Pvxhf7GGJyIiIlKRHD13nqxsJ742C9XDAz0djoiIiBQjFcS8iV8Q1O9hbhdy2mSAr40nezYA4B9LEvh22/Hiik5ERESkQsnpH1a7SjA2q8XD0YiIiEhxUkHM2zTqb/5MWFToUwxuW5Pbr6+Ow2kwcs7PbNh7qpiCExEREak4XP3D1FBfRESk3FFBzNs07AsWKyRugbMHC3UKq9XCPwa1oEfjKDKznTz44U9sO5pczIGKiIiIlG85BbG6aqgvIiJS7qgg5m2Cq0DNG8zthG8KfRpfm5V3hl1PuzrhpGRmc+/MjRy40BRWRERERK5tb05BTCPEREREyh0VxLxR4wvTJncUftokmP3E/j28HY2jQziZmsk9MzaSlJxRDAGKiIiIlH97T6QCEKcVJkVERModFcS8UU4fsf1rYNNsyEov9KnCAn356P721IoI4uDpdO6duZFz5+3FE6eIiIhIOZVhd3Dk7HlAPcRERETKIxXEvFGVelD7JjAc8NWTMK0JLHsezhwo1OmiQgP4zwPtiazkz47EFB768Ccy7I5iDlpERESk/Dh4Oh3DgJAAHyIr+Xk6HBERESlmKoh5q6GfQO+XoHJtyDgLP7wJb7aCT+6CvSvBMNw6Xe0qwXx0f3tCAnzYuP80o+b8TLbDWRKRi4iIiJR5e09c7B9msVg8HI2IiIgUNxXEvFVAKNw4Cp74BYbOhbrdwHBCwiL46Fb4V0f4cQZkFbxRftPYUGYMb4e/j5Vvtycx7n9bcDrdK6yJiIiIVAR7T+b0D9N0SRERkfLIowWx77//ngEDBhAbG4vFYmHBggWeDMc7WW3QqB/cuwBGboR2D4JvMJzYDovGwOtNYMkzcHpvgU7XPi6Cd+66HpvVwv9+PsyUb7ZjuDnaTERERKS823dhhJga6ouIiJRPHi2IpaWl0bJlS9555x1PhlF2VG0Et7wOf9kOfV+BiLqQeQ7WvwNvXg9zBsPu5decTtmzaTX+MagFAB+s3sd7qwpWTBMRERGpKPadvDBlsqpGiImIiJRHPp588X79+tGvXz9PhlA2BYTBDY9C+z/D7m9h4/+ZP3cuMW9VGkD7h6H1MPDL+yLujjY1OJOWxUuLt/OPJTuICPZlcLtapfxGRERERLxTTkFMUyZFRETKJ48WxNyVmZlJZmam635ycjIAdrsdu91e7K+Xc86SOHexietm3k7twvrTTKy/fYLl1C745mmM1a/j6PYcRvM7wXLlYMARHWtyIuU876/ez/gvtlDJz0rvptWKHFKZyJuXUc4KR3lzn3JWOMqb+7w9Z94al3iHc+l2TqVlASqIiYiIlFdlqiA2ZcoUJk+efMX+ZcuWERQUVGKvGx8fX2LnLl4349O4LTVPr6Fe0jcEpybi89Uozix/na3V7+J0pUZXPKOpATdEWVmfZOXJuZt5pImTBmHF01Os7OTNeyhnhaO8uU85KxzlzX3emrP09HRPhyBeLKehfrVQf4L9y9TlsoiIiBRQmfov/Pjx4xkzZozrfnJyMjVr1qR3796EhoYW++vZ7Xbi4+Pp1asXvr6+xX7+kjMIsqfg+PF9rGumEZ6+j5t3vYSz8R9x9JgIlWvnOrqPw8kTn/5G/PYkZu3x4+P729EstvD5LLt58xzlrHCUN/cpZ4WjvLnP23OWM8pcJC+u/mFqqC8iIlJulamCmL+/P/7+/lfs9/X1LdGL7ZI+f4nw9YXOf4Hr74HvXoKfP8K6YyHWXUvM/mM3j4WAUNehb911PSNmbWT93tM88NHPzHukI3WrFu0isEzmzcOUs8JR3tynnBWO8uY+b82ZN8Yk3sPVP0wN9UVERMotj64yKaWgUhQMeAMeWQN1u4IjC9a+AW9dDz/NAqcDgABfGx/c25ZmsaGcSsvi7n9vYP3eU56NXURERMQD9p7IGSGmgpiIiEh55dGCWGpqKps3b2bz5s0A7Nu3j82bN3Pw4EFPhlU+VWsG9yyAoZ9ClfqQdgK+Hg3v3Qx7VwIQEuDLh/e3Jy4ymKPnMhjy/nrGff4bZ9OzPBm5iIiISKnaqxUmRUREyj2PFsR++uknWrduTevWrQEYM2YMrVu3ZsKECZ4Mq/yyWKBRX3h0HfR9BQIqQ9Lv8NGtMGcInNxNZCV/FozsxF0dagHw6U+H6DltFV9uPoJhFE+zfRERKSMc2Z6OQKTUOZ0G+3N6iBWxfYSIiIh4L48WxLp27YphGFfcZs+e7cmwyj8fP7OP2BO/QIdHwOoDO7+Bf3WAJeMJI5WXb2vOvEc60iCqEidTs3hy7maGz/qRg6e0KpeISIWw5XN4sSps+D9PRyKl5J133qFOnToEBATQoUMHNm7cmO/xZ8+eZeTIkcTExODv70/Dhg1ZvHix6/FJkyZhsVhy3Ro3blzSb6PIjqdkcN7uwMdqoUZ4oKfDERERkRKiHmIVWVAE9PuHOWKsQR9wZsP6f8GbrWHD+7SrFcaiJ27mL70a4udj5fudJ+g9fRXvrtyD3eH0dPQiIlJSMpJhyd/AcMKKFyH9tKcjkhL26aefMmbMGCZOnMjPP/9My5Yt6dOnD0lJSXken5WVRa9evdi/fz+ff/45CQkJfPDBB1SvXj3Xcc2aNePYsWOu25o1a0rj7RRJTv+wWhFB+Np0qSwiIlJe6b/yAlUbwrDP4J75ENUUzp+Bb56GD/+IX+phHu/RgCVP3kzHulXIsDv5x5IdDHhrDZsPnfV05CIiUhLWTDN7TQJkJsMPb3o2Hilx06ZN46GHHuK+++6jadOmvPfeewQFBTFz5sw8j585cyanT59mwYIFdOrUiTp16tClSxdatmyZ6zgfHx+io6Ndt8jIyNJ4O0Wy1zVdUv3DREREyjMfTwcgXqRed/jzatg0C+InwoE18G4n6PcqdVsOYc5DHfh802FeWrydHYkp3Pavtdx7Q23G9mlESICWrxcRKRfO7Id175jbbUbAptnmtMkOj0JINQ8GJiUlKyuLTZs2MX78eNc+q9VKz549WbduXZ7PWbhwIR07dmTkyJF8+eWXVK1albvuuotx48Zhs9lcx+3atYvY2FgCAgLo2LEjU6ZMoVatWnmeMzMzk8zMTNf95ORkAOx2O3a7vTjeai4557z83HuOm69bOyKwRF63rLta3uTqlLPCUd7cp5wVjvLmPm/PWUHjUkFMcrP5QPuHoH4P+OLPcHgjLHgEEhZj+cN0/tS2Jt0bR/HSou188csRPlx3gKW/H2fSH5vR97poT0cvIiJFFT8RHFkQ1wX+MB0St8CRTeaosX7/8HR0UgJOnjyJw+GgWrXcBc9q1aqxY8eOPJ+zd+9eVqxYwbBhw1i8eDG7d+/msccew263M3HiRAA6dOjA7NmzadSoEceOHWPy5MncfPPNbN26lZCQkCvOOWXKFCZPnnzF/mXLlhEUFFQM7zRv8fHxue5v3G4FrKQe28vixXtK7HXLusvzJtemnBWO8uY+5axwlDf3eWvO0tML1vtcBTHJW0RduO8bWDsdVk6B7Qvh0Aa49R2qNOjFtMGtuP36Gjy7YAsHTqXzyH830btpNSbf2ozIIH2sRETKpAM/wLYFYLFCn5fN1Ym7Pw//GQg/zYSOo6ByTU9HKV7A6XQSFRXF+++/j81mo02bNhw5coSpU6e6CmL9+vVzHd+iRQs6dOhA7dq1+eyzz3jggQeuOOf48eMZM2aM635ycjI1a9akd+/ehIaGFvt7sNvtxMfH06tXL3x9L450fz1hNXCeAV070CEuothft6y7Wt7k6pSzwlHe3KecFY7y5j5vz1nOKPNrUeVCrs7mA53HQv2e8MXDcDIBPr4D2t4PvV/kpgaRLB3dmbdW7OL/Vu1l2bbj/LDnFE/1rE+E4engRUTELU4nLLkwZe76eyH6OnO7bleoczPsXw3fvwp/fMtjIUrJiIyMxGazcfz48Vz7jx8/TnR03qO/Y2Ji8PX1zTU9skmTJiQmJpKVlYWfn98Vz6lcuTINGzZk9+7deZ7T398ff3//K/b7+vqW6MX2pefPynZy+Mx5ABpGh3nlRb63KOnfS3mknBWO8uY+5axwlDf3eWvOChqTmurLtcW2gj+vMvvHgDlK4L2b4fBPBPjaeLpPY75+4iaur1WZ1Mxs/r5oB1N/s7F610mPhi0iIm74bS4c2wx+IdDt2Yv7c0aJAfzyMZzSFLLyxs/PjzZt2rB8+XLXPqfTyfLly+nYsWOez+nUqRO7d+/G6by46vTOnTuJiYnJsxgGkJqayp49e4iJiSneN1CMDp5Ox2lAsJ+NqiFXFudERESk/FBBTArGNxD6vQL3LIDQ6nB6D8zoDd+9DA47jaND+fyRG/n7wOsICfDhaLqF+z/6mXtmbOD3o+c8Hb2IiOQnMxW+vdC7qfNYqBSV+/FaHaBBbzAc5jR6KXfGjBnDBx98wIcffsj27dt59NFHSUtL47777gPg3nvvzdV0/9FHH+X06dM8+eST7Ny5k0WLFvHyyy8zcuRI1zFjx45l1apV7N+/nx9++IHbbrsNm83G0KFDS/39FdS+CytMxlUNxmKxeDgaERERKUmaMinuqdcNHl0Li5+GLfNg1T9g1zK4/QOskQ2454ba9GkSyV9nr2BtkjlKbM3uNdzWqjpjejekRnjJNcUVEZFCWvsGpCZCeB244dG8j+n+nPnv/ZbP4aYxUK1pqYYoJWvw4MGcOHGCCRMmkJiYSKtWrViyZImr0f7BgwexWi9+j1qzZk2WLl3KU089RYsWLahevTpPPvkk48aNcx1z+PBhhg4dyqlTp6hatSo33XQT69evp2rVqqX+/gpq74lUAOIiK3k4EhGRonM4HF67CqA3sdvt+Pj4kJGRgcPh8HQ4ZYKnc3Z524bCUkFM3BcYDoP+DQ37wqIxcPQXcwpl779DuwcJD/LjtjpOJgztzPTle1n461G++OUIX285xn031uGxrvUJC/K+ecYiIhXS2UPww5vmdq8XwOcq08RiWkLTW2Hbl/DdSzDk49KLUUrFqFGjGDVqVJ6PrVy58op9HTt2ZP369Vc939y5c4srtFKTM0KsbmSwhyMRESk8wzA4duwYZ8+e9XQoZYJhGERHR3Po0CGNDi4gb8hZ5cqViY6OLtLrqyAmhdf8Dqh9Iyx4DPZ+B4vHQsI3cMt0AGqGB/Hm0NY8eHMcryzayrZ9h/lm9Tp+3biSe1tXplfdAHztKXD+LGScu3gLrgqdnoCQvBv5irgYWr1BpMiWT4bsDKjdCZr8Mf9juz0L27+CHV/DkU1QvU3pxChSSvbmFMSqqiAmImVXUlISKSkpREVFERQUpCLPNTidTlJTU6lUqVKu0dBydZ7MmWEYpKenk5SUBFCk3qQqiEnRhMbC3V/Ajx9A/ATYsxyf92+mk60aPkdegYxkWmScY05WCgRc8rxfLtyu5uePoNsz0P5hc7VLkcslfIPPgkdpEdwaHL3AC1c3EfF6h340p79jgT4vmw3081O1EbQYDL9+AitehHvml1xsTgdYiz4UXsQdrh5iGiEmImWUxWIhOTmZatWqUaVKFU+HUyY4nU6ysrIICAhQQayAPJ2zwMBAwCz+RkVFFXr6pH7bUnRWK3T4M/x5NcS0wpJxlsi0BCxJ2yD5MGSluA41fINJD6jGHktNfnQ25FtHa1b4deNYo3ug89PmdJ3Y683nLB0P/3cz7F/rwTdXQNsWwgfdYcP/eTqSiuHsIZj/ZyznzxB3cgW2z+6GzJRrP0+ktGWcM0fRfnQrrH8Xzh70dEQXGQYs+Zu53WqYuaJwQXQZB1Yf2LOi5P59PrET/nWDOQpNpJSkZNg5kZIJqCAmImVXTmEgKEi9m6V8y/mMF6VPnobeSPGp2hAe/Jbs7Yv55aeNtO7YFZ9KERBQ+cItFIvNlyAgNsvBkrX7eHflHlKTs+FX6NqoKn/r15jGHR+HXz6CbydB0jaY3d8ckdDrBe+bRnn+LHzzV/jtU/P+kU1w7hD0fMEsFErxc2TDFw9BxjmMKvVxnD6Iz97lMKs/DJvnfZ8RqbiO/QbzhsPpveb9vSvNAlRMS2j8B/MW1eTao7JKypbP4chP4BsMPZ4v+PMi4uD6e+GnmbDi73DfN8X7Hs4cMAuIKUchfiIM/8pzOZIKJWd0WNUQf0ICNOpYRMo2TZOU8q44PuP6i12Kl80Xo1F/joa3x6jb1ewvU6UeBFcB28WLy0A/GyO71WfV010ZcWMdfKwWViacoN8bqxn92a/EB/bj/J9/hDb3ARaz4PRWW1j3L7Mg4g12L4d/dTRjs1ih0S3m/h/egi8fA4dWdCkR378KB9eBXwjZgz9hbYPxGEGRkPgb/LsnJO3wdIRS0RkGbPrQ/Dye3gthNaH782aPLosVjv1qNqV/tyO8dT0sex4ObQSns/RizEo3v3QAuPkp9wvJnZ8GnwDz/4u7lxdfXCmJF4thVRvDnz5UMUxKjaZLioiIVCwqiIlHVankz6Q/NuPbMV24pXkMhgELNh/loY9+otVrP3H/qWF8c+Mcsqq18p5plFlp8PUY+O/t5h9tEfXg/mUwdA4MfBcsNrO/ztxh5h+dUnz2r4Hvp5rbf/gnhMdxNrge2SOWQJX65ui8Gb1h32rPxilXMgz4dS788DZkpno6mpKTlQYLHoWvngBHJjToA3/+HjqPhfsWw9hd8Me3zP02P7Ng9sObMKMXTGsCXz9lFpiys0o2znVvm1Paw2pCx7xXFcxXaCy0e9DcXvH34lngIv00fDQQzuyDyrXhngXmlykipWTvCa0wKSJSntSpU4fp06cX+PiVK1disVi0OmcFooKYeIU6kcG8M+x6vhzZiRE31qFGeCCZ2U5W7Eji0RUGjQ6M5c2gUZz3Cbs4jfKLh83RBKXp4Hp4txP8NMO83/7P8MgaqNnOvN/qLhgyB3wCYddSc6RD+unSjbG8Sj9t/s4Np9nvqMWfLj4WXgceiIeaHSDznFms/G2ex0KVy5w7Yv5O5v8Zlj0Lb7aGH2eUv1GUJ3bCBz3MgrjFCj0mwtC5EBRx8ZjgSHO64bDP4K974Y5ZcN0g8AuB1ERzGuJ/b4ep9eF/D8LvC4q/gJh8DNb809zuOQl8Awt3nk6jzemWxzabK08WRUay+b5PbIeQGLj3Swgt/IpBIoWxVyPEREQ8wmKx5HubNGlSoc77448/8vDDDxf4+BtvvJFjx44RFhZWqNcrjMaNG+Pv709iYin/XSuACmLiZVrWrMykPzZj9V+7sXR0Z57u04jra1UGi5Vpp2+kY+qrfJzdA+eFaZTZb1xP1pq3S34aZXam2ctmVj9z9EJoDfMPtv6vgt9lDSsb9TUfCwiDwxvN55w7UrLxlXeGAV+OguQj5kiwfq9eeUxQhJn3preCIwu+eBBWTyuekStSOIYBv35qTi3es8KcYle5FqQlwaIx5v7tX5eP39GWz+GDbmZBJzgK7l0IN4/Jv5egfwhcdzvcMRP+ugeG/Q/ajDCfn3nOXP1x3nCYWg+WPGM26C8Oy18AezrUaG8W4wqrUlW44VFz+7uXzFUhCyMrHT4ZAkd/gaAq5siwiLjCxyVSSPtOmsXnulUreTgSEZGK5dixY67b9OnTCQ0NzbVv7NixrmMNwyA7u2B/+1WtWtWtxQX8/PyIjo4utf5ra9as4fz589xxxx18+OGHpfKa+SlKc/qySgUx8UoWi4VG0SGM7FafLx7rxI/P9mTqHS24oVkDXrY+zMDMF9jsrItPdhp+3z7LoVfaEv/N/0g8l1H8wRz7Dd7vCmunm6OTWt4Fj/0Adbte/Tm1OsB9S8yRDid2mNP4Tuws/tgqih//DQmLzClmd8wE/6v8seIbCHfMvjgFbPlks/DiLX3nKpLUE/DZPTD/YbO4U72NuRLtqE1mQTOoCpzaBZ8Og5l94OAGT0dcONmZsGgs/O8ByEqFOjebo0bjbnbvPD7+0KAnDHgD/rID7l9qfo7D60B2Bqx/B95qA7/8t2i9xo78DL/OMbf7vlL0/lw3Pm4W/0/sMIuC7srOgs/uhQNrwT8U7v4CohoXLSaRQjAMg30nNEJMRMonwzBIz8ou9ZtRwC89o6OjXbewsDAsFovr/o4dOwgJCeGbb76hTZs2+Pv7s2bNGvbs2cOtt95KtWrVqFSpEu3atePbb7/Ndd7Lp0xaLBb+/e9/c9tttxEUFESDBg1YuHCh6/HLp0zOnj2bypUrs3TpUpo0aUKlSpXo27cvx44dcz0nOzubJ554gsqVK1OlShXGjRvH8OHDGThw4DXf94wZM7jrrru45557mDlz5hWPHz58mKFDhxIREUFwcDBt27Zlw4aL18xfffUV7dq1IyAggMjISG677bZc73XBggW5zle5cmVmz54NwP79+7FYLHz66ad06dKFgIAAPv74Y06dOsXQoUOpXr06QUFBNG/enE8++STXeZxOJ1OnTuX6668nMDCQWrVq8dJLLwHQvXt3Ro3K3Y7jxIkT+Pn5sXx5MfadLSZaZVLKhMhK/vypbU3+1LYmmdkO1u9tw4JtXVmydQ5/tv+HmvZ91NxwP1/8cBM/hN9KnWY30PW62jSLDS18hd+RDWv/CStfAWc2BEWaf6w2+UPBnl+tKTywDP5zu/mH/8w+5iqINdoWLp6K6vjvsPRZc7vnZHOFvvxYrdDnJbM30pK/mVPQzh3Jv5AmxWv7V/DVaEg/CVYf6Po36PQU2C78J6fDn6HlUFj7Bqx7Bw5tgJm9ockA6DEJIut7MvqCO3MA5o2Aoz+b92/+C3R95uL7LCyrDWrdYN56v2j2FFsyDk7thi9Hmp/pflOhRhv3zmsYsPQZc7vFYPefn5fAynDjE2YfsZUvmyPebAVcnc/pMFeM3R1vTjO/6zOIbVX0mEQK4URKJmlZDqwWqBVR8NEEIiJlwXm7g6YTlpb66257oQ9BfsVTcvjb3/7Ga6+9Rt26dQkPD+fQoUP079+fl156CX9/fz766CMGDBhAQkICtWrVuup5Jk+ezKuvvsrUqVN56623GDZsGPv27cPHJ+8409PTee211/jPf/6D1Wrl7rvvZuzYsXz88ccA/OMf/+Djjz9m1qxZNGnShDfeeIMFCxbQrVu3fN9PSkoK8+bNY8OGDTRu3Jhz586xevVqbr7Z/FI1NTWVLl26UL16dRYuXEh0dDQ///wzzgtfjC5atIjbbruNZ599lo8++oisrCwWL15cqLy+/vrrtG7dmoCAADIyMmjTpg3jxo0jNDSURYsWcc8991CvXj3at28PwPjx4/nggw946aWX6NmzJ8ePH2fHDnNhswcffJBRo0bx+uuv4+/vD8B///tfqlevTvfu3d2Or6SpICZljr+PjS4Nq9KlYVWMW5uz68CjHFk6mabHvuB22xpuT16D4wcLu9dWZ7FPfZzRrYht2pFm13ciICikYC9ychfMfwSO/GTeb/wH+MN0c4qQOyrXMkd6fHyH+UfzhwNg8H+gfk/3zlNRZaXDvPsuNCfvfXF6VkHc8AiEVTf7MO1aCrNvMf/gDqlWcvFWdOfPwjfj4Le55v2opnDb/0FMiyuPDQiFHs9Duwdg5RRz5NP2r2DHYnPaYNe/QaWo0ozePQlLzJ5oGWchMBxuex8a9i7+17FYzJFjcetgw3uw6h9wZBP8uzu0uht6Tix4nrYtMFeF9Ak0+5sVlw6PmLGd2W/+Htved+3nOJ2w8AkzJpsfDPkYancsvphE3LTnwuiwmhFB+PloAoWIiLd54YUX6NWrl+t+REQELVte/KL873//O/Pnz2fhwoVXjFC61IgRIxg6dCgAL7/8Mm+++SYbN27kxhtvzPN4u93Oe++9R7169QAYNWoUL7zwguvxt956i/Hjx7tGZ7399tsFKkzNnTuXBg0a0KxZMwCGDBnCjBkzXAWxOXPmcOLECX788UciIsx+tPXrX/zS+KWXXmLIkCFMnjzZte/SfBTU6NGjuf3223Ptu3SK6uOPP87SpUv57LPPaN++PSkpKbzxxhu8+eab3HnnnYSGhtKgQQNuuukmAG6//XZGjRrFl19+yZ133gmYI+1GjBhRalNR3aGCmJRpFouFhnVqw59nwpGRZH43FeehHwnMPEkjy2EaOQ/D0ZVwdDqOeAtH/GqTVa0FkQ1uICSuLUQ3z90DzOmEje/Dt5Mg+zz4h0H/qdDizsJPLQquAsO/MqeP7VkBcwbDwPdyN4WXvC0dDycToFK1Cyt4uvk7aDIAhn8Nnww2G3/P6Gn2aarasETCrdD2rLjY581iNUcNdXvGnAqYn9BYc9XFGx4z/3+3c4m5aMWvc6HTE+a0QW8a2efMhvgXzSnUYE4F/dNss/hdknz8zHy0uNPM06+fwOb/wvaFZvGw/cP5j8yyZ0D8BHO705Nmsbi4+FeCm8aY/3/9fqo5+s834OrHG4Z57Ob/mp+VQTOgfo/ii0ekEPad1AqTIlJ+Bfra2PZCH4+8bnFp2zb3LJvU1FQmTZrEokWLOHbsGNnZ2Zw/f56DBw/me54WLS5+URscHExoaChJSUlXPT4oKMhVDAOIiYlxHX/u3DmOHz/uGjkFYLPZaNOmjWsk19XMnDmTu+++23X/7rvvpkuXLrz11luEhISwefNmWrdu7SqGXW7z5s089NBD+b5GQVyeV4fDwcsvv8xnn33GkSNHyMrKIjMz09WLbfv27WRmZtKjR97XbgEBAa4poHfeeSc///wzW7duzTU11ZuoICblR/U2+N99YWRK8jGyDv3Mke3ryDy4icjkbURazlLdvh8O74fDC+E7cGIlK6IB/jWvxxLTyuxTte978xx1u8Gtb0NYjaLH5l8Jhn4KCx6FrZ+bDd/TT7o34qmi+X0BbJoNWOD2983V+QqjZjtzBcr/DjIXRJjRC4Z+ArXz/hZI3JSVBsuev7jyakRds+Bbq4N754lqAnd9CvvXmOc7+rM5cuzHGdBtPLS+t+hTEYvI334W28e3maOswFxltveLZrGqtIREw23vQdv7YfHTZqF36TOw6UPo9w+od5Xh+ev/BWcPmn0NOz1R/HG1vR/WvW0WRH+aCR0fu/qx371sjigDuPVf0PSPxR+PiJtyGurHRXpRAV5EpJhYLJZim7roKcHBub+wGDt2LPHx8bz22mvUr1+fwMBA7rjjDrKysvI9j69v7i8QLRZLvsWrvI4vaG+0q9m2bRvr169n48aNjBs3zrXf4XAwd+5cHnroIQID818F/FqP5xVnXk3zL8/r1KlTeeONN5g+fTrNmzcnODiY0aNHu/J6rdcFc9pkq1atOHz4MLNmzaJ79+7Url37ms/zBI0Jl/IpNAa/ZrcQd8eLNB7zDVUm7mfHXRtZ2GQanwTexXJHa5KMylhxEnA6Acuvn5g9evZ9j+EbBP1fg3vmF08xLIePH9z+gTm9CMz+Vt9OLh8r7BW3swfhqwt/tN80Ov8FDAqiSj148Fuo3tac4vbRrbD1i8KfzzDAUfFWYbnCwfXwbqeLxbD2D5sN5d0thl2qzk3w0Aq4YxaEx5krUn79FPzrBo+uSGnZ/z1ddzyH9eA68Ktkxtf/1dIthl2qZnszTwPeNBcoOJkA/xkIn95t9ja7VMpxc8VVgJ6TwK8ERsD4BkDnp83t1a9DZmrex619E76/sEps/9eg1dDij0WkEHJGiMVV1QgxEZGyYO3atYwYMYLbbruN5s2bEx0dzf79+0s1hrCwMKpVq8aPP/7o2udwOPj555/zfd6MGTPo3Lkzv/76K5s3b3bdxowZw4wZ5nV1ixYt2Lx5M6dPn87zHC1atMi3SX3VqlVzNf/ftWsX6enp13xPa9eu5dZbb+Xuu++mZcuW1K1bl507Ly4O16BBAwIDA/N97ebNm9O2bVs++OAD5syZw/3333/N1/WUsl0mFikgi8VC44aNaNywEfAAx5Mz+HZ7Epu2/E7agU00MfZwnWUf6fgzPetOKm1sRPsT2+kQV4V2dSIICypgk+hrsVrNld2Cq5pNqNdMg7QT0Hdq8Zy/NBkG7FxqrlgX1wVa31M8xQFHttn3K+OcWcDq9mzRzwnmCLPhX5lNvHd8DZ/fBwd+MPs/2dPBft5czS9nO+eWfT73/Zx9ANWug4Z9oVF/iG1t/n4rAnsGfPcS/PAWYEBoDXM05dVGJ7nLYjGbszf+A2yaZfbNylmRsnItaHabeYtpVfRVEvOTesL8rGz7Etu+VfgYToyoplju/I93NP632qDNcHOE1cpXYOMHZh+2XfHQabQ5NdIvCL57EbJSIPZ6aH5nycXT+m5zoYQz+8wRYB2fzP34T7Mg/nlzu8cEaF/0Yf4ixWXvCU2ZFBEpSxo0aMAXX3zBgAEDsFgsPP/889ecplgSHn/8caZMmUL9+vVp3Lgxb731FmfOnLlqvyy73c5//vMfXnjhBa677rpcjz344INMmzaN33//naFDh/Lyyy8zcOBApkyZQkxMDL/88guxsbF07NiRiRMn0qNHD+rVq8eQIUPIzs5m8eLFrhFn3bt35+2336Zjx444HA7GjRt3xWi3vDRo0IDPP/+cH374gfDwcKZNm8bx48dp2rQpYE6JHDduHH/7299wOp306NGDU6dO8fvvv/PAAw/kei+jRo0iODg41+qX3kYFMamQqoUGcFeHWtzVoRbns3qzZvdJ4rcfZ83ukxw+cx4On+PXw+f4YPU+LBZoHB1Kh7gIOsRF0C4ugshK1+iLlB+LBTqPNYtiX4+GX/6DLe0k1sBBxfb+SpRhmH2eVr5iTtcC2Pal2VOpy9/M1euKMrVt1T/MVQf9Q+GOGQVfsa4g/ILgzo9gyXjY+H/w4wdFO9/xreZt9Wtmn7MGvaFRP3NEW0mMwikO6acJOX/EXDjCz9/8PFpsZi8nq+2ybeuV+5O2mQtOnNhunq/VMOg7BQLCij9WH7/cK1Kuf9ccPbj2DfMWXudicSy6RfEUx1KOw46vzM/0/jVgmBdWFuBAxM3EjvgY36ASeK9FERhuTpe8/l5zUYP9q2HVK7D5Y3PU3s//MY/rO6Vki7Y2X+g6HuY/DD+8Ca1HXHxsy+fmSD+Am54yV+QU8RJ2h5ODp81vzetqhJiISJkwbdo07r//fm688UYiIyMZN24cycnJpR7HuHHjSExM5N5778Vms/Hwww/Tp08fbLa8+6ctXLiQU6dO5VkkatKkCU2aNGHGjBlMmzaNZcuW8Ze//IX+/fuTnZ1N06ZNeeeddwDo2rUr8+bN4+9//zuvvPIKoaGhdO7c2XWu119/nfvuu4+bb76Z2NhY3njjDTZt2nTN9/Pcc8+xd+9e+vTpQ1BQEA8//DADBw7k3LlzrmOef/55bDYbL7/8Mk888QQxMTE88sgjuc4zdOhQRo8ezdChQwkIyKe3rIdZjKJOgPWg5ORkwsLCOHfuHKGhocV+frvdzuLFi+nfv3+BqqliKut5O3L2PBv3nWLjvtNs2HuavRemUVyqflQl2l8okHWIq0J0WCH/T779a/j8fnBkcjawDiEdh2Or28Vcla84C0HFwTAg4RvzD+1jv5r7fIPhutvMESmpx819VeqbfxQ3u939P773rTZX4sSAO2bCdfkXCQv9WTMM2DIP9q0yV9zzvfQWBD4B5k/fgKvsCwKnA/auhJ3fwO4V5gicHD4B5qi5Rn3NEWShse7lobiknjCLlsc2w9HN5u/t3KHiOXdwVXO6XuP+xXO+gshKh93x8Pt8c3Si/ZJh3xF1zcJY04HmYhnuFMeSj5nN6bd9aY4a5JL/LMa0gqa3Ym/Yn8XrE7z/3zXDMFduXPocJB++uL/Z7fCnWSX/+k4HvHsjnNiBo9Nf+Dq9JbfUt+Dz+QgwHNDuQXOqpBesMlTS1xBSdKV1nde0Qxd6TV9LoK+N3yf3wWr1/OfTm5X16zxPUM4KR3lzn91uZ9myZcTFxVG3bl2vLkR4E6fTSXJyMqGhoViL+OWh0+mkSZMm3Hnnnfz9738vpgi9z7Vytn//furVq8ePP/7I9ddfXyIxZGRksG/fPuLi4q74rBf0GkIjxEQuU71yILe1rsFtrc3+YUkpGWzcd9pVIEs4nsLupFR2J6UyZ4O5ikntKkG0rxNBixphNI4JpVF0CKEBBfgPd5M/wD1fYHwyhMrn98OKybACs9BUsz3U6QS1O5kr2V1rtb6SYhiQsNgcEZb4m7nPN9ic7nTj4+ZUxKx0+PHfsOafcGo3/O8Bs49Qt2fMaW8F+eM37ZQ5nRHDnHp1jWJYkVgs5mp9LYo4fazVUPOWnWmOJtq5BBKWwLmDsGupeeMpiGkJDfuZBbKSmuaXknix6JVTAEs5muehmbZK+Pn5YnE6zSKF4TQLGTnbxjWGmze9FW6ZVviFDgrLL8h87aa3ms38dy27UBxbBqf3mp+51a9DRL2LI8eqNcs73+cOw7YLRbBD63M/Vr2NWVhr+kdzFBqA3Q4klPAbLAYWi/m+G/QxR22umW7+29FzUum8vtVmTnP+7B6sP75H9djh2L6YYX62WgyBflO9ohgmcql9J83iep3IYBXDRETELQcOHGDZsmV06dKFzMxM3n77bfbt28ddd93l6dA8wm63c+rUKZ577jluuOGGEiuGFRcVxESuISokgD+0iOUPLcxRPmfSsti4/7SrSPb70XMcOJXOgVPpzNt0cURG9cqBNIkJoVF0CI2jQ2kSE0KdKsH42C6roNe5ieyHvidh/qs0DTqD9dB6s/H73u/MG4DNH2q0M1dGrNPJ3C7pKXmGATsWmVMYcwphfpXMQljHxyG4ysVj/YLMleva3gfr3zN7SyVtMxt8x7SEbs9Bg15X/0PYMGDhKEg5BlUaQL9XS/a9FTcff6jfw7z1e9V87wnfmAWywz9dKFL9ao6uC4kxR43VbA82P7D6mDebr1lMsPqA1feS/T4Xt3NuhgOStpvnPLrZLIDljNDLxQKRDczfQUwriG2FPbIpS5avzv/bVsO4WBi7tFDmdJgx+oeUXC4Lyi/4YtErM9UsPv4+3xyteHqPOY119Wvm5ynnOL/giyPBDv+Y+3w1O5iFtiYDzD5lZZ1fkFmQbv9ncNrN1SlLS5MBENMKy7HNtN3/L3Nf4z/Are9UnD57UqbkNNTXdEkREXGX1Wpl9uzZjB07FsMwuO666/j2229p0qSJp0PziLVr19KtWzcaNmzI559/7ulwrkkFMRE3hQf70adZNH2amX9gJmfY2XTgDD/tP832YynsOJbM0XMZHDl7niNnz/Pt9iTXc/18rDSsVonG0aE0vlAoaxwTQlhYTfZE9aNR//5YbTazP9P+tXBgrTmFKy0JDqwxb99jFkVirzcLZLU7mav6FVcPJ1ch7BVI3HIh8EpmL6KOo3IXwi7nHwJdnob2D8K6d8yeT8d+hTl/ghrtoftzULfLlc/b+IE5Cs3mZ06V9Nb+WwVhsZijkqo1M3vFpSaZ0/t2LoE9K8yi36ZZ5q1YX9cKkQ1dhS9iWppTBy8vXuWx3HKe78FiA2zeN3U3L/6VzBGF1w2CzBQz3znFsVO7zFUNv7+8yGqBWh0vFsHCqnsk9BKX3/9fS4rFAt2fh4/NUZ7OuK5Y75hZtN6CIiVo36kL/cPUUF9ERNxUs2ZN1q5d6+kwvEbXrl0pS125dHUqUkShAb50axRFt0ZRrn3n0u3sSEwm4XiKWSRLTCYhMYX0LAdbjySz9Ujuho+RlfyIsFlZn72NelEhxEVGUqfuXdRs8yB+Nos5DTGnOLZ/rdkb6PBG87Z2OmCB0OoQXhsq1zZHuFy6HRprjuzJj9MJCYtg5T/g+CWFsA5/NgthQREFT0pguFn86vCIGd/GD8xYP/oj1LnZfKzWDeaxiVtg2XPmdq+/m/3TypNKUXD9PebNnmE2PE/4xpzi58w2R105s81RPDn3HZdsu/ZnmytwOrPN0VpV6l8sfMW0gujrynYhsbj4h0DzO8xbRvLF4tjueDN3tTtdLIKV5qipiqZ+Dxzt/szR3VuIvuNDrJ6a8i1SAPsvjBCLU0FMRESkQlFBTKQEhAX50qFuFTrUvTg6w+k0OHQmnR2JKey4UCTbkZjC/lNpnEzN4iRWdv54ONd5bFYLNcIDqVMlmLjIdsRFdyWuWRD1/c8QfWYT1oMXimSn95pFsuTDZuHsclYfCKthFsjCLxTJKte5WDg7tNGcGnl8q3m8XyWzmNVxpHuFsMsFR0LvF82C2upp5qio/athZh+o3xNuGmOutOnINKcRdvhz4V+rLPANMKeONujl6UgqhoBQaPEn85aZahbEAit7OqqKwWLB2fslfs5eTH8VasXL5YwQU0FMRESkYlFBTKSUWK0WalcJpnaVYNd0S4D0rGy2HTnL/G9/ILRGfQ6ezmDfyTT2n0ojPcvh6k+2aueJXOfzs4VTq8qd1KlyH81qZdDI/xQ1LSep5kikcuZR/FIPw5kD5qqCzmw4s9+87csnSL+QCyPCilgIu1xINPR/1WzC//1U2Pwx7P7WvAFUioZb/6Vm21Jy/Ct5OgIR8UKZDjienAlA3Uj9OyEiIlKRqCAm4mFBfj60rBHGkSiD/j0buBqdG4ZBUkqmWRw7mca+C7f9p9LYfyqdrGyna7VLs6zkA0RfuLUixN+H2MqB1KjpR+PgVBr4naaW9QTRziQqZx0lMPUwlnOHIPnIxamRNzxWvIWwy1WuCX98E24aDatehd8+Nfff/r5neh2JiEiFdiLD/Fkl2I+woDLQM1FERESKjQpiIl7KYrFQLTSAaqEB3FA3d7HI4TQ4du78JcWydI6cTefoWbOZ/+m0LFIys0k4nkLCcVgOQPCFWx0AfKwWosMCqFXNh+iwQCLSg6my8QyRldKIDPEnMtifyBA/IoL98Pe5Rv8xd0XUhdvegy7jIDsDoirmKiwiIuJZSefNkcmaLikiIlLxqCAmUgaZvcWCqBEexM0Nql7x+PksB0fOnufohZUuj549z5Ez510rXyaeyyDbaXD4zHkOnwFIyff1QgN8iKzkT2Qlf6pU8rtiOyLYj4hgXyoH+VE50Bcfm7VgbyQizv03LyIiUkxyRoipICYiUvZ17dqVVq1aMX36dADq1KnD6NGjGT169FWfY7FY+N///kf37t2L9NoWi4X58+czcODAIp1HSpcKYiLlUKCfjfpRlagflXc/FIfTICklw1UkO56cwanULE6kZnIqNYuTqZmcvLCd7TRIzsgmOSObvRdW4rqWsEBfIoL9qBzkS0SQH+HBfoQH+RIe7EdEkB+Vg/xcRbSwQD/CAn3x8ylgEU1ERKSYHL8wQqxuVfUPExHxlAEDBmC321myZMkVj61evZrOnTvz66+/0qKFe6vR//jjjwQHF+8XHpMmTWLBggVs3rw51/5jx44RHh5erK91NefPn6d69epYrVaOHDmCv79W8y4sFcREKiCb1UJMWCAxYYG0zec4wzA4d95uroJ5SbHsVGomJy7ZPpNu53RaFufO2wE4d97u2i6oQF8bYYG+rlvoJdvmfZ9c98MCfQnytZDtLEIiRESkQjuhKZMiIh73wAMPMGjQIA4fPkyNGjVyPTZr1izatm3rdjEMoGrVK2fSlJTo6OhrH1RM/ve//9GsWTMMw2DBggUMHjy41F77coZhkJ2djY9P2Swtlc2oRaRUWCwWcxpkkN9VR5tdKtvh5Nx5O2fSs1xFsjNpWZxOz+LsVe7nFM7O2x2ctztITM5wM0ofJvyynMpBfoQH+xJ+Id7wIF/XT3Of+TM8yI/Kwb6E+Ptg0aqWIiIVlmEYrimTdauqICYi4il/+MMfqFq1KrNnz+a5555z7U9NTWXevHlMnTqVU6dOMWrUKL7//nvOnDlDvXr1eOaZZxg6dOhVz3v5lMldu3bxwAMPsHHjRurWrcsbb7xxxXPGjRvH/PnzOXz4MNHR0QwbNowJEybg6+vL7NmzmTx5MoDr74hZs2YxYsSIK6ZMbtmyhSeffJJ169YRFBTEoEGDmDZtGpUqmX9TjRgxgrNnz3LTTTfx+uuvk5WVxZAhQ5g+fbprkbWrmTFjBnfffTeGYTBjxowrCmK///4748aN4/vvv8cwDFq1asXs2bOpV68eADNnzuT1119n9+7dREREMGjQIN5++232799PXFwcv/zyC61atQLg7NmzhIeH891339G1a1dWrlxJt27d+Prrr3n22WfZtm0by5Yto2bNmowZM4b169eTlpZGkyZNmDJlCj179nTFlZmZyYQJE5gzZw5JSUnUrFmT8ePHc//999OgQQMeeeQRxo4d6zp+8+bNtG7dml27dlG/fv18c1JYKoiJSLHxsVmpUsmfKpUKPmzX4TRIybC7RpUln892bV96S778foa5z2lAWpaDtCxz+meBY7VaCPKzYbNasFktWC25f5rbuPb52CzYLBas1os//WxW/HysF3/6XLzv73P1x/x8rPj72Aj0sxHoe+HmZyXQz8d139/HitWqgp2ISEk5lZbFeYcFiwVqRQR5OhwRkZJjGGBPL/3X9Q2CAnwB7ePjw7333svs2bN59tlnXcWmefPm4XA4GDp0KKmpqbRp04Zx48YRGhrKokWLuOeee6hXrx7t27e/5ms4nU5uv/12qlWrxoYNGzh37lyevcVCQkKYPXs2sbGxbNmyhYceeoiQkBD++te/MnjwYLZu3cqSJUv49ttvAQgLC7viHGlpafTp04eOHTvy448/kpSUxIMPPsioUaOYPXu267jvvvuOmJgYvvvuO3bv3s3gwYNp1aoVDz300FXfx549e1i3bh1ffPEFhmHw1FNPceDAAWrXrg3AkSNH6Ny5M127dmXFihWEhoaydu1asrOzAXj33XcZM2YMr7zyCv369ePcuXOsXbv2mvm73DPPPMOkSZO47rrrqFKlCocOHaJ///689NJL+Pv789FHHzFgwAASEhKoVasWAPfeey/r1q3jzTffpGXLluzbt4+TJ09isVi4//77mTVrVq6C2KxZs+jcuXOJFcNABTER8TCb9eIoNHdlZmbxxdff0K5TV1KynJxNvzg67Wx6Vu7ttJx9ds7bHa7eaN4swNfqKpAF5Cqe2fCxWvCxWfG1WfCxWvGxWfDN+Wmz5v24zYIFg52JFtI2HSbAz+zd5mu7WKjzvfCcnOKd7yX7/WxWfH0sWLj6hY2Bke97slos+PtYNTpPRDxu30nzj8PqlQMJ8C3m1ZRFRLyJPR1eji39133mKPgVbATu/fffz9SpU1m1ahVdu3YFzILIoEGDCAsLIywsLFex5PHHH2fp0qV89tlnBSqIffvtt+zYsYOlS5cSG2vm4uWXX6Zfv365jrt0hFqdOnUYO3Ysc+fO5a9//SuBgYFUqlQJHx+ffKdIzpkzh4yMDD766CNXD7O3336bAQMG8I9//INq1aoBEB4ezttvv43NZqNx48bccsstLF++PN+C2MyZM+nXr5+rX1mfPn2YNWsWkyZNAuCdd94hLCyMuXPnukaaNWzY0PX8F198kb/85S88+eSTrn3t2rW7Zv4uN2nSJLp160ZoaChWq5WIiAhatmzpevzvf/878+fPZ+HChYwaNYqdO3fy2WefER8f7xo1VrduXdfxI0aMYMKECWzcuJH27dtjt9uZM2cOr732mtuxuUMFMREps6xWC0E+ULtK0DWHFl8qw+7gbLqdtKxsnE4Dh2HgcBo4nbi2c27OnPuGYR7r2gd2h5OsbCeZF366bg7HJdtOMnM9Zv7MsDvIsJs/c6aLns9ykHlJUzTzcSdncK8f27XZmLdvWzGf0z3mKDlzpJy/jxV/30u2faz4+17cDriwnTPKzt9mPp5r9N1lI/H8LxmJl9cIvZyfNo3CE6mw9p8yF4qJq6LRYSIinta4cWNuvPFGZs6cSdeuXdm9ezerV6/mhRdeAMDhcPDyyy/z2WefceTIEbKyssjMzCQoqGD/hm/fvp2aNWu6imEAHTt2vOK4Tz/9lDfffJM9e/aQmppKdnY2oaGhbr2X7du307Jly1wN/Tt16oTT6SQhIcFVEGvWrBk228UvZGJiYtiyZctVz+twOPjwww9zTfW8++67GTt2LBMmTMBqtbJ582ZuvvnmPP82SkpK4ujRo/To0cOt95OXtm1zd6JOTU1l0qRJLFq0iGPHjpGdnc358+c5ePAgYE5/tNlsdOnSJc/zxcbGcssttzBz5kzat2/PV199RWZmJn/605+KHGt+VBATkQonwNdGdJh3jgZwOA0ys83iWHqW42LBLMv8mXPfnm1gdzrJdhjYHU6yLxTr7I4L+y48lu1wYneaP7Md5rkPHTlKlapRZF9S1LNfOE9O0e7S/TlFvOKUUyBMwbOj9GyXTn3No2CWs+1jhVMnrXx5+hd8bFbXVFprztTaS7dzHrtkGq6vzYK/r40AXysBPjYCcrYv2ZfzuL/PpY+ZxUDzc3Hx95J1YTsz5/d12e8tM+d3l+3EYrk42jAgZ8Sh78UpuzkxBPra8LG5t9qr02m4XvfSz5Dd4eR8ZhZH02DviTSCAvxcoxddow1tZn40WlA8JWeEWB011BeR8s43yByt5YnXdcMDDzzA448/zjvvvMOsWbOoV6+eq4AydepU3njjDaZPn07z5s0JDg5m9OjRZGVlFVu469atY9iwYUyePJk+ffq4Rlq9/vrrxfYal7q8aGWxWHA6r37NvXTpUo4cOXJFzzCHw8Hy5cvp1asXgYGBV31+fo8BWK3mdaBhXJzxYbfn/cX85at3jh07lvj4eF577TXq169PYGAgd9xxh+v3c63XBnjwwQe55557+Oc//8msWbMYPHhwgQuehaWCmIiIF7FZLQT5+RDk50OVEji/3W5n8eLD9O9/vVuj6gzDIPtCwe1a8ptSme28WLAxbw4yL4yUu3yfazvbaR6T7bhsJN7Fc5nbjjxH4+XcMvMo7DmcBuedZpHx2qxsO3uiAMeVXb42i6sQl9PLzmGYv3d79oWC1yUFMIcz/ymy4MM/fsu/L0VOccw3Z8qu9eL2gBaxPNmzQfG9QcnXO++8w9SpU0lMTKRly5a89dZb+U5DOXv2LM8++yxffPEFp0+fpnbt2kyfPp3+/fsX+pylad9JjRATkQrCYinw1EVPuvPOO3nyySeZM2cOH330EY8++qjri7O1a9dy6623cvfddwNmT7CdO3fStGnTAp27SZMmHDp0iGPHjhETEwPA+vXrcx2zbt06ateuzbPPPuvad+DAgVzH+Pn54XDkf93YpEkTZs+eTVpamqtwtHbtWqxWK40aNSpQvHmZMWMGQ4YMyRUfwEsvvcSMGTPo1asXLVq04MMPP8Rut19xrR8SEkKdOnVYvnw53bp1u+L8OatyHjt2jNatWwPmyK6CWLt2LSNGjOC2224DzBFj+/fvdz3evHlznE4nq1atytVo/1L9+/cnODiYd999lyVLlvD9998X6LWLQgUxERG5JsuFUU6+bo4gupJnR+YZhuEa9Wa/vKh22SirS4tt5zOz2Pzrb1x3XXOwWnE6DZwGrim0OdNoc6bYOnOm2BrmcfZss6CXM002w24W+y6dOnvp45l283Xz4ndpnzefi33echZz8L1kdJuvzYph4Bp1mJHz0+7MNfIwhznKK5uUQvbXs1kvfk58bRayMrOw+vhidxhkO80i2uWyHE6yHGD+T26n0jILFYe479NPP2XMmDG89957dOjQgenTp9OnTx8SEhKIioq64visrCx69epFVFQUn3/+OdWrV+fAgQNUrly50OcsbftOmSPE4jRCTETEK1SqVInBgwczfvx4kpOTGTFihOuxBg0a8Pnnn/PDDz8QHh7OtGnTOH78eIELYj179qRhw4YMHz6cqVOnkpycfEVhqX79+hw8eJC5c+fSrl07Fi1axPz583MdU6dOHfbt28fmzZupUaMGISEh+PvnXlBs2LBhTJw4keHDhzNp0iROnDjB448/zj333OOaLumuEydO8NVXX7Fw4UKuu+66XI/de++93HbbbZw+fZpRo0bx1ltvMWTIEMaPH09YWBjr16+nffv2NGrUiEmTJvHII48QFRVFv379SElJYe3atTz++OMEBgZyww038MorrxAXF0dSUlKunmr5adCgAV988QUDBgzAYrHw/PPP5xrtVqdOHYYPH87999/vaqp/4MABkpKSuPPOOwGw2WyMGDGC8ePH06BBgzyntBY3FcRERKTCsFgs+PmYxSQKvhgqdrudgGO/0r9tDbdG1hVFzvTZrGynObXzQtGruKcYGoY5HfPK6blOMu0Os8h1ySILOQWvSxdhyJkKeWlPNnM04mL69+/jyllOQdJ+2TTLvO5nZRtEhbrxS5IimTZtGg899BD33XcfAO+99x6LFi1i5syZ/O1vf7vi+JkzZ3L69Gl++OEH1++3Tp06RTpnaXtnaCs+X/o9zau71xtGRERKzgMPPMCMGTPo379/rn5fzz33HHv37qVPnz4EBQXx8MMPM3DgQM6dO1eg81qtVubPn88DDzxA+/btqVOnDm+++SZ9+/Z1HfPHP/6Rp556ilGjRpGZmcktt9zC888/72pYDzBo0CC++OILunXrxtmzZ5k1a1auwh1AUFAQS5cu5cknn6Rdu3YEBQUxaNAgpk2bVui85DToz6v/V48ePQgMDOS///0vTzzxBCtWrODpp5+mS5cu2Gw2WrVqRadOnQAYPnw4GRkZ/POf/2Ts2LFERkZyxx13uM41c+ZMHnjgAdq0aUOjRo149dVX6d279zXjmzZtGvfffz833ngjkZGRjBs3juTk5FzHvPvuuzzzzDM89thjnDp1ilq1avHMM8/kOuaBBx7g5Zdfdl07lDSLcekE0TImOTmZsLAwzp0753aju4K4eDHfv9T+ACoPlDf3KWeFo7y5TzkrHOXNfd6es5K+hihLsrKyCAoK4vPPP2fgwIGu/cOHD+fs2bN8+eWXVzynf//+REREEBQUxJdffknVqlW56667GDduHDabrVDnvJyu87yT8uY+5axwlDf32e12li1bRlxcHHXr1iUgIMDTIZUJTqeT5ORk14qJcm0llbPVq1fTo0cPDh06dM3RdBkZGezbt4+4uLgrPusFvYbQCDERERGRCuzkyZM4HI4rLjyrVavGjh078nzO3r17WbFiBcOGDWPx4sXs3r2bxx57DLvdzsSJEwt1zszMTDIzL06Tzflm2W63X7Wpb1HknLMkzl2eKW/uU84KR3lzX06uDMPA6XTm26BdLsoZI5STN7m24s5ZZmYmJ06cYNKkSdxxxx1UrVr1mud1Op3m7AO7PddqnVDwfze8oiDmzQ1XRURERCQ3p9NJVFQU77//PjabjTZt2nDkyBGmTp3KxIkTC3XOKVOmMHny5Cv2L1u2rERXmYqPjy+xc5dnypv7lLPCUd7c4+PjQ0ZGBqmpqcW6AmNFkJKS4ukQypziytmcOXN4/PHHad68OW+99dYV0y3zkpWVxfnz5/n+++/Jzs7d/zY9Pb1Ar+vxgpi3N1wVERERKc8iIyOx2WwcP3481/7jx48THR2d53NiYmLw9fXN9Y1skyZNSExMJCsrq1DnHD9+PGPGjHHdT05OpmbNmvTu3bvEpkzGx8fTq1cvTcdyg/LmPuWscJQ399ntdr777jsCAgKoVKmSpkwWkGEYpKSkEBISUuy9Wsur4s7ZI488wiOPPOLWczIyMggMDKRz5855TpksCI8XxLy94aqIiIhIeebn50ebNm1Yvny5q9+X0+lk+fLljBo1Ks/ndOrUiTlz5uB0Ol29Q3bu3ElMTAx+fn4Abp/T39//ipW6AHx9fUv0j+GSPn95pby5TzkrHOXNfRaLBavVqn5YBZQzNS8nb3Jt3pAzq9VcbCqvfyMK+m+GRwtiWVlZbNq0ifHjx7v2Wa1Wevbsybp16644Xr0lygblzX3KWeEob+5TzgpHeXOft+fMW+PylDFjxjB8+HDatm1L+/btmT59Omlpaa4vLO+9916qV6/OlClTAHj00Ud5++23efLJJ3n88cfZtWsXL7/8Mk888USBzykiIiLiSR4tiLnbcFW9JcoW5c19ylnhKG/uU84KR3lzn7fmrKC9JSqKwYMHc+LECSZMmEBiYiKtWrViyZIlrmu0gwcP5voGuGbNmixdupSnnnqKFi1aUL16dZ588knGjRtX4HOKiEjJyWl6LlJeFcdn3ONTJt2h3hJlg/LmPuWscJQ39ylnhaO8uc/bc1bQ3hIVyahRo646nXHlypVX7OvYsSPr168v9DlFRKT4ORwOwPziJzAw0MPRiJScnC83i3Kd6dGCmLsNV9VbomxR3tynnBWO8uY+5axwlDf3eWvOvDEmERGRojIMg9DQUJKSkgAICgpSo/hrcDqdZGVlkZGRoR5iBeTJnBmGQXp6OklJSVSuXDnXAj/u8mhBrDBNXEVEREREREQkb1FRUdhsNldRTPJnGAbnz58nMDBQxcMC8oacVa5c+aorVxeUx6dMquGqiIiIiIiISPGwWCzExMQQFRWlRWQKwG638/3339O5c2eNIC8gT+fM19e3SCPDcni8IKaGqyIiIiIiIiLFy2azFUvRoLyz2WxkZ2cTEBCgglgBlZecebwgBmq4KiIiIiIiIiIipUcd40REREREREREpEJRQUxERERERERERCoUr5gyWViGYQCQnJxcIue32+2kp6eTnJxcpufFljblzX3KWeEob+5TzgpHeXOft+cs59oh51pCvI+u87yT8uY+5axwlDf3KWeFo7y5z9tzVtDrvDJdEEtJSQGgZs2aHo5EREREyqKUlBTCwsI8HYbkQdd5IiIiUhTXus6zGGX4q1Gn08nRo0cJCQnBYrEU+/mTk5OpWbMmhw4dIjQ0tNjPX14pb+5TzgpHeXOfclY4ypv7vD1nhmGQkpJCbGwsVqs6SHgjXed5J+XNfcpZ4Shv7lPOCkd5c5+356yg13lleoSY1WqlRo0aJf46oaGhXvlL9nbKm/uUs8JR3tynnBWO8uY+b86ZRoZ5N13neTflzX3KWeEob+5TzgpHeXOfN+esINd5+kpUREREREREREQqFBXERERERERERESkQlFBLB/+/v5MnDgRf39/T4dSpihv7lPOCkd5c59yVjjKm/uUM/F2+owWjvLmPuWscJQ39ylnhaO8ua+85KxMN9UXERERERERERFxl0aIiYiIiIiIiIhIhaKCmIiIiIiIiIiIVCgqiImIiIiIiIiISIWigpiIiIiIiIiIiFQoKojl45133qFOnToEBATQoUMHNm7c6OmQvNakSZOwWCy5bo0bN/Z0WF7n+++/Z8CAAcTGxmKxWFiwYEGuxw3DYMKECcTExBAYGEjPnj3ZtWuXZ4L1EtfK2YgRI6747PXt29czwXqJKVOm0K5dO0JCQoiKimLgwIEkJCTkOiYjI4ORI0dSpUoVKlWqxKBBgzh+/LiHIvYOBclb165dr/i8PfLIIx6K2PPeffddWrRoQWhoKKGhoXTs2JFvvvnG9bg+Z+LNdJ1XcLrOKxhd57lP13nu03Ve4eg6z30V4TpPBbGr+PTTTxkzZgwTJ07k559/pmXLlvTp04ekpCRPh+a1mjVrxrFjx1y3NWvWeDokr5OWlkbLli1555138nz81Vdf5c033+S9995jw4YNBAcH06dPHzIyMko5Uu9xrZwB9O3bN9dn75NPPinFCL3PqlWrGDlyJOvXryc+Ph673U7v3r1JS0tzHfPUU0/x1VdfMW/ePFatWsXRo0e5/fbbPRi15xUkbwAPPfRQrs/bq6++6qGIPa9GjRq88sorbNq0iZ9++onu3btz66238vvvvwP6nIn30nWe+3Sdd226znOfrvPcp+u8wtF1nvsqxHWeIXlq3769MXLkSNd9h8NhxMbGGlOmTPFgVN5r4sSJRsuWLT0dRpkCGPPnz3fddzqdRnR0tDF16lTXvrNnzxr+/v7GJ5984oEIvc/lOTMMwxg+fLhx6623eiSesiIpKckAjFWrVhmGYX6ufH19jXnz5rmO2b59uwEY69at81SYXufyvBmGYXTp0sV48sknPRdUGRAeHm78+9//1udMvJqu89yj6zz36TrPfbrOKxxd5xWOrvMKp7xd52mEWB6ysrLYtGkTPXv2dO2zWq307NmTdevWeTAy77Zr1y5iY2OpW7cuw4YN4+DBg54OqUzZt28fiYmJuT53YWFhdOjQQZ+7a1i5ciVRUVE0atSIRx99lFOnTnk6JK9y7tw5ACIiIgDYtGkTdrs912etcePG1KpVS5+1S1yetxwff/wxkZGRXHfddYwfP5709HRPhOd1HA4Hc+fOJS0tjY4dO+pzJl5L13mFo+u8otF1XuHpOi9/us4rHF3nuae8Xuf5eDoAb3Ty5EkcDgfVqlXLtb9atWrs2LHDQ1F5tw4dOjB79mwaNWrEsWPHmDx5MjfffDNbt24lJCTE0+GVCYmJiQB5fu5yHpMr9e3bl9tvv524uDj27NnDM888Q79+/Vi3bh02m83T4Xmc0+lk9OjRdOrUieuuuw4wP2t+fn5Urlw517H6rF2UV94A7rrrLmrXrk1sbCy//fYb48aNIyEhgS+++MKD0XrWli1b6NixIxkZGVSqVIn58+fTtGlTNm/erM+ZeCVd57lP13lFp+u8wtF1Xv50nVc4us4ruPJ+naeCmBSLfv36ubZbtGhBhw4dqF27Np999hkPPPCAByOT8m7IkCGu7ebNm9OiRQvq1avHypUr6dGjhwcj8w4jR45k69at6vXipqvl7eGHH3ZtN2/enJiYGHr06MGePXuoV69eaYfpFRo1asTmzZs5d+4cn3/+OcOHD2fVqlWeDktEipGu88RTdJ2XP13nFY6u8wquvF/nacpkHiIjI7HZbFeskHD8+HGio6M9FFXZUrlyZRo2bMju3bs9HUqZkfPZ0ueuaOrWrUtkZKQ+e8CoUaP4+uuv+e6776hRo4Zrf3R0NFlZWZw9ezbX8fqsma6Wt7x06NABoEJ/3vz8/Khfvz5t2rRhypQptGzZkjfeeEOfM/Faus4rOl3nuU/XecVD13kX6TqvcHSd557yfp2nglge/Pz8aNOmDcuXL3ftczqdLF++nI4dO3owsrIjNTWVPXv2EBMT4+lQyoy4uDiio6Nzfe6Sk5PZsGGDPnduOHz4MKdOnarQnz3DMBg1ahTz589nxYoVxMXF5Xq8TZs2+Pr65vqsJSQkcPDgwQr9WbtW3vKyefNmgAr9ebuc0+kkMzNTnzPxWrrOKzpd57lP13nFQ9d5us4rLF3nFY/ydp2nKZNXMWbMGIYPH07btm1p374906dPJy0tjfvuu8/ToXmlsWPHMmDAAGrXrs3Ro0eZOHEiNpuNoUOHejo0r5KamprrG4Z9+/axefNmIiIiqFWrFqNHj+bFF1+kQYMGxMXF8fzzzxMbG8vAgQM9F7SH5ZeziIgIJk+ezKBBg4iOjmbPnj389a9/pX79+vTp08eDUXvWyJEjmTNnDl9++SUhISGuefxhYWEEBgYSFhbGAw88wJgxY4iIiCA0NJTHH3+cjh07csMNN3g4es+5Vt727NnDnDlz6N+/P1WqVOG3337jqaeeonPnzrRo0cLD0XvG+PHj6devH7Vq1SIlJYU5c+awcuVKli5dqs+ZeDVd57lH13kFo+s89+k6z326ziscXee5r0Jc53l2kUvv9tZbbxm1atUy/Pz8jPbt2xvr16/3dEhea/DgwUZMTIzh5+dnVK9e3Rg8eLCxe/duT4fldb777jsDuOI2fPhwwzDMJbmff/55o1q1aoa/v7/Ro0cPIyEhwbNBe1h+OUtPTzd69+5tVK1a1fD19TVq165tPPTQQ0ZiYqKnw/aovPIFGLNmzXIdc/78eeOxxx4zwsPDjaCgIOO2224zjh075rmgvcC18nbw4EGjc+fORkREhOHv72/Ur1/fePrpp41z5855NnAPuv/++43atWsbfn5+RtWqVY0ePXoYy5Ytcz2uz5l4M13nFZyu8wpG13nu03We+3SdVzi6znNfRbjOsxiGYZRMqU1ERERERERERMT7qIeYiIiIiIiIiIhUKCqIiYiIiIiIiIhIhaKCmIiIiIiIiIiIVCgqiImIiIiIiIiISIWigpiIiIiIiIiIiFQoKoiJiIiIiIiIiEiFooKYiIiIiIiIiIhUKCqIiUiFZ7FYWLBggafDEBEREZFipus8EbkaFcRExKNGjBiBxWK54ta3b19PhyYiIiIiRaDrPBHxZj6eDkBEpG/fvsyaNSvXPn9/fw9FIyIiIiLFRdd5IuKtNEJMRDzO39+f6OjoXLfw8HDAHOb+7rvv0q9fPwIDA6lbty6ff/55rudv2bKF7t27ExgYSJUqVXj44YdJTU3NdczMmTNp1qwZ/v7+xMTEMGrUqFyPnzx5kttuu42goCAaNGjAwoULXY+dOXOGYcOGUbVqVQIDA2nQoMEVF3YiIiIiciVd54mIt1JBTES83vPPP8+gQYP49ddfGTZsGEOGDGH79u0ApKWl0adPH8LDw/nxxx+ZN28e3377ba4LoXfffZeRI0fy8MMPs2XLFhYuXEj9+vVzvcbkyZO58847+e233+jfvz/Dhg3j9OnTrtfftm0b33zzDdu3b+fdd98lMjKy9BIgIiIiUk7pOk9EPMYQEfGg4cOHGzabzQgODs51e+mllwzDMAzAeOSRR3I9p0OHDsajjz5qGIZhvP/++0Z4eLiRmprqenzRokWG1Wo1EhMTDcMwjNjYWOPZZ5+9agyA8dxzz7nup6amGoDxzTffGIZhGAMGDDDuu+++4nnDIiIiIhWErvNExJuph5iIeFy3bt149913c+2LiIhwbXfs2DHXYx07dmTz5s0AbN++nZYtWxIcHOx6vFOnTjidThISErBYLBw9epQePXrkG0OLFi1c28HBwYSGhpKUlATAo48+yqBBg/j555/p3bs3AwcO5MYbbyzUexURERGpSHSdJyLeSgUxEfG44ODgK4a2F5fAwMACHefr65vrvsViwel0AtCvXz8OHDjA4sWLiY+Pp0ePHowcOZLXXnut2OMVERERKU90nSci3ko9xETE661fv/6K+02aNAGgSZMm/Prrr6SlpbkeX7t2LVarlUaNGhESEkKdOnVYvnx5kWKoWrUqw4cP57///S/Tp0/n/fffL9L5RERERETXeSLiORohJiIel5mZSWJiYq59Pj4+roam8+bNo23bttx00018/PHHbNy4kRkzZgAwhMgTpAAAAZxJREFUbNgwJk6cyPDhw5k0aRInTpzg8ccf55577qFatWoATJo0iUceeYSoqCj69etHSkoKa9eu5fHHHy9QfBMmTKBNmzY0a9aMzMxMvv76a9eFmoiIiIhcna7zRMRbqSAmIh63ZMkSYmJicu1r1KgRO3bsAMyVgebOnctjjz1GTEwMn3zyCU2bNgUgKCiIpUuX8uSTT9KuXTuCgoIYNGgQ06ZNc51r+PDhZGRk8M9//pOxY8cSGRnJHXfcUeD4/Pz8GD9+PPv37ycwMJCbb76ZuXPnFsM7FxERESnfdJ0nIt7KYhiG4ekgRESuxmKxMH/+fAYOHOjpUERERESkGOk6T0Q8ST3ERERERERERESkQlFBTEREREREREREKhRNmRQRERERERERkQpFI8RERERERERERKRCUUFMREREREREREQqFBXERERERERERESkQlFBTEREREREREREKhQVxEREREREREREpEJRQUxERERERERERCoUFcRERERERERERKRCUUFMREREREREREQqFBXERERERERERESkQvl/0sJpwAsVih4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize = (15, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot( hist.history[\"loss\"], label = \"Training Loss\")\n",
    "plt.plot( hist.history[\"val_loss\"], label = \"Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot( hist.history[\"accuracy\"], label = \"Training Accuracy\")\n",
    "plt.plot( hist.history[\"val_accuracy\"], label = \"Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37b338f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.save('PD_Detection.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65100d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4153d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model= load_model(r'PD_Detection.keras')\n",
    "\n",
    "def model_predict(img_path, model):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(64,64))\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    preds=np.argmax(preds, axis=1)\n",
    "    if preds==0:\n",
    "        preds=\"Control\"\n",
    "    else:\n",
    "        preds=\"PD\"\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb5e12f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 976ms/step\n"
     ]
    }
   ],
   "source": [
    "a = model_predict(r'D:\\Final Year Project\\JPG Dataset\\PD\\17.jpg',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48549e",
   "metadata": {},
   "source": [
    "**Testing Ensemble Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ee8fca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Control', 'PD']\n",
      "(73, 64, 64, 3) (73, 2)\n"
     ]
    }
   ],
   "source": [
    "test_images = \"D:\\Final Year Project\\Test\"\n",
    "\n",
    "test_image_data = []\n",
    "test_labels = []\n",
    "\n",
    "test_folders = os.listdir(test_images)\n",
    "print(test_folders)\n",
    "\n",
    "label_dict = {\n",
    "    'Control':0,\n",
    "    'PD':1\n",
    "}\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "for ix in test_folders:\n",
    "    path = os.path.join(test_images,ix)\n",
    "    for im in os.listdir(path):\n",
    "        img = image.load_img(os.path.join(path,im),target_size = ((64,64)))\n",
    "        img_array = image.img_to_array(img)\n",
    "        test_image_data.append(img_array)\n",
    "        test_labels.append(label_dict[ix])\n",
    "        \n",
    "\n",
    "combined = list(zip(test_image_data,test_labels))\n",
    "test_image_data[:],test_labels[:] = zip(*combined)\n",
    "\n",
    "x_test = np.array(test_image_data)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "'''\n",
    "from keras.utils import np_utils\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(x_test.shape,y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Print the shapes of x_test and y_test\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6558a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 178ms/step - loss: 0.9867 - accuracy: 0.9315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9867314100265503, 0.931506872177124]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13ab3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43bf1c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 216ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = ensemble_model.predict(x_test, batch_size = 32)\n",
    "pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "278ec3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93        37\n",
      "           1       0.88      1.00      0.94        36\n",
      "\n",
      "    accuracy                           0.93        73\n",
      "   macro avg       0.94      0.93      0.93        73\n",
      "weighted avg       0.94      0.93      0.93        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "888154de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  5]\n",
      " [ 0 36]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1bd8d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.save('Parkinson disease.keras')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG-Resnet-Ensembel_Deep_parkinson's.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
